{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd79945",
   "metadata": {},
   "source": [
    "# ClasificaciÃ³n de grafos con redout FSPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b73626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: MUTAG(188):\n",
      "====================\n",
      "Number of graphs: 188\n",
      "Number of features: 7\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 17\n",
      "Number of edges: 38\n",
      "Average node degree: 2.24\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/ahmedbegga/Desktop/TFG-Ahmed/SetXAI/')\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.utils import *\n",
    "from src.fspool import FSPool\n",
    "from torch_scatter import scatter\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv,DenseGraphConv, dense_mincut_pool\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool,global_sort_pool\n",
    "dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "#torch.manual_seed(12345)\n",
    "#print(f'Number of training graphs: {len(train_dataset)}')\n",
    "#print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d75c176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 20\n",
      "DataBatch(edge_index=[2, 774], x=[349, 7], edge_attr=[774, 4], y=[20], batch=[349], ptr=[21])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 20\n",
      "DataBatch(edge_index=[2, 736], x=[339, 7], edge_attr=[736, 4], y=[20], batch=[339], ptr=[21])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 20\n",
      "DataBatch(edge_index=[2, 752], x=[347, 7], edge_attr=[752, 4], y=[20], batch=[347], ptr=[21])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 20\n",
      "DataBatch(edge_index=[2, 816], x=[364, 7], edge_attr=[816, 4], y=[20], batch=[364], ptr=[21])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 20\n",
      "DataBatch(edge_index=[2, 832], x=[378, 7], edge_attr=[832, 4], y=[20], batch=[378], ptr=[21])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 20\n",
      "DataBatch(edge_index=[2, 800], x=[362, 7], edge_attr=[800, 4], y=[20], batch=[362], ptr=[21])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 20\n",
      "DataBatch(edge_index=[2, 826], x=[370, 7], edge_attr=[826, 4], y=[20], batch=[370], ptr=[21])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 10\n",
      "DataBatch(edge_index=[2, 394], x=[175, 7], edge_attr=[394, 4], y=[10], batch=[175], ptr=[11])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(dataset[:150], batch_size=20, shuffle=True)\n",
    "test_loader = DataLoader(dataset[150:], batch_size=20, shuffle=False)\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "917b3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels=32):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # GCN Layer - MLP - Dense GCN Layer\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        num_of_centers =  16 # k\n",
    "        # The degree of the node belonging to any of the centers\n",
    "        self.pool1 = Linear(hidden_channels, num_of_centers) \n",
    "        self.conv2 = DenseGraphConv(hidden_channels, hidden_channels)\n",
    "        # MLPs towards out \n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, out_channels)\n",
    "        self.weight = torch.nn.Parameter(torch.zeros(16,32))\n",
    "        torch.nn.init.normal_(self.weight)\n",
    "        #torch.nn.init.normal_(self.pool1)\n",
    "        # Input: Batch of 20 graphs, each node F=3 features \n",
    "        #        N1 + N2 + ... + N2 = 661\n",
    "        # TSNE here?\n",
    "        self.salidaConv = torch.zeros(0)\n",
    "    def forward(self, x, edge_index, batch):    # x torch.Size([661, 3]),  data.batch  torch.Size([661])  \n",
    "        # CONV1: Expand features from F=3 to F' = 32\n",
    "        x = F.relu(self.conv1(x, edge_index))   # x torch.Size([661, 32]) \n",
    "        \n",
    "        # Make all x_i of size N=MAX(N1,...,N20), e.g. N=40: \n",
    "        x, mask = to_dense_batch(x, batch)      # x torch.Size([20, N, 32]) ; mask torch.Size([20, N]) batch_size=20\n",
    "        #print(\"x size\", x.size())\n",
    "        \n",
    "        # Make all adjacencies of size NxN \n",
    "        adj = to_dense_adj(edge_index, batch)   # adj torch.Size([20, N, N])\n",
    "        #print(\"adj_size\", adj.size())\n",
    "        \n",
    "        # MLP of k=16 outputs s\n",
    "        #print(\"adj_size\", adj.size())\n",
    "        s = self.pool1(x) # s torch.Size([20, N, k])\n",
    "        #print(\"s_size\", s.size())\n",
    "        self.salidaConv = x\n",
    "        # MINCUT_POOL\n",
    "        # Call to dense_cut_mincut_pool to get coarsened x, adj and the losses: k=16\n",
    "        x, adj, mincut_loss, ortho_loss = dense_mincut_pool(x, adj, s, mask) # x torch.Size([20, 16, 32]),  adj torch.Size([20, 16, 16])\n",
    "        #print(\"Coarsened x and adj sizes:\", x.size(), adj.size())\n",
    "\n",
    "        # CONV2: Now on coarsened x and adj: \n",
    "        x = self.conv2(x, adj) #x torch.Size([20, 16, 32])\n",
    "        #print(\"x_2 size\", x.size())\n",
    "        \n",
    "        # Readout for each of the 20 graphs\n",
    "        #x = x.mean(dim=1) # x torch.Size([20, 32])\n",
    "        #x = x.sum(dim=1) # x torch.Size([20, 32])\n",
    "        #x, _ = x.sort(dim=1)\n",
    "        #x = torch.einsum('nlc, lc -> nc', x, self.weight)\n",
    "        #print(x.shape)\n",
    "        x =  x * self.weight\n",
    "        #x = x.max(dim=1)[0]\n",
    "        x = x.sum(dim=1)\n",
    "        #print(\"mean x_2 size\", x.size())\n",
    "        # Final MLP for graph classification: hidden channels = 32\n",
    "        x = F.relu(self.lin1(x)) # x torch.Size([20, 32])\n",
    "        #print(\"final x1 size\", x.size())\n",
    "        x = self.lin2(x) #x torch.Size([20, 2])\n",
    "        #print(\"final x2 size\", x.size())\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4868cc1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.749, Train Acc: 0.707, Test Loss: 0.686, Test Acc: 0.579\n",
      "Epoch: 002, Train Loss: 0.644, Train Acc: 0.660, Test Loss: 0.579, Test Acc: 0.684\n",
      "Epoch: 003, Train Loss: 0.587, Train Acc: 0.660, Test Loss: 0.530, Test Acc: 0.684\n",
      "Epoch: 004, Train Loss: 0.573, Train Acc: 0.660, Test Loss: 0.512, Test Acc: 0.684\n",
      "Epoch: 005, Train Loss: 0.569, Train Acc: 0.660, Test Loss: 0.508, Test Acc: 0.684\n",
      "Epoch: 006, Train Loss: 0.559, Train Acc: 0.660, Test Loss: 0.504, Test Acc: 0.684\n",
      "Epoch: 007, Train Loss: 0.551, Train Acc: 0.660, Test Loss: 0.503, Test Acc: 0.684\n",
      "Epoch: 008, Train Loss: 0.540, Train Acc: 0.660, Test Loss: 0.492, Test Acc: 0.684\n",
      "Epoch: 009, Train Loss: 0.530, Train Acc: 0.660, Test Loss: 0.483, Test Acc: 0.684\n",
      "Epoch: 010, Train Loss: 0.519, Train Acc: 0.667, Test Loss: 0.485, Test Acc: 0.684\n",
      "Epoch: 011, Train Loss: 0.503, Train Acc: 0.700, Test Loss: 0.474, Test Acc: 0.763\n",
      "Epoch: 012, Train Loss: 0.486, Train Acc: 0.740, Test Loss: 0.465, Test Acc: 0.763\n",
      "Epoch: 013, Train Loss: 0.469, Train Acc: 0.787, Test Loss: 0.460, Test Acc: 0.789\n",
      "Epoch: 014, Train Loss: 0.452, Train Acc: 0.813, Test Loss: 0.455, Test Acc: 0.816\n",
      "Epoch: 015, Train Loss: 0.435, Train Acc: 0.827, Test Loss: 0.458, Test Acc: 0.816\n",
      "Epoch: 016, Train Loss: 0.420, Train Acc: 0.853, Test Loss: 0.458, Test Acc: 0.842\n",
      "Epoch: 017, Train Loss: 0.408, Train Acc: 0.860, Test Loss: 0.462, Test Acc: 0.842\n",
      "Epoch: 018, Train Loss: 0.397, Train Acc: 0.860, Test Loss: 0.462, Test Acc: 0.816\n",
      "Epoch: 019, Train Loss: 0.385, Train Acc: 0.840, Test Loss: 0.479, Test Acc: 0.789\n",
      "Epoch: 020, Train Loss: 0.389, Train Acc: 0.847, Test Loss: 0.460, Test Acc: 0.816\n",
      "Epoch: 021, Train Loss: 0.378, Train Acc: 0.847, Test Loss: 0.459, Test Acc: 0.816\n",
      "Epoch: 022, Train Loss: 0.390, Train Acc: 0.833, Test Loss: 0.501, Test Acc: 0.789\n",
      "Epoch: 023, Train Loss: 0.371, Train Acc: 0.847, Test Loss: 0.447, Test Acc: 0.816\n",
      "Epoch: 024, Train Loss: 0.360, Train Acc: 0.847, Test Loss: 0.518, Test Acc: 0.789\n",
      "Epoch: 025, Train Loss: 0.366, Train Acc: 0.847, Test Loss: 0.519, Test Acc: 0.789\n",
      "Epoch: 026, Train Loss: 0.374, Train Acc: 0.847, Test Loss: 0.452, Test Acc: 0.816\n",
      "Epoch: 027, Train Loss: 0.351, Train Acc: 0.840, Test Loss: 0.543, Test Acc: 0.789\n",
      "Epoch: 028, Train Loss: 0.364, Train Acc: 0.867, Test Loss: 0.494, Test Acc: 0.816\n",
      "Epoch: 029, Train Loss: 0.358, Train Acc: 0.853, Test Loss: 0.472, Test Acc: 0.816\n",
      "Epoch: 030, Train Loss: 0.355, Train Acc: 0.867, Test Loss: 0.512, Test Acc: 0.816\n",
      "Epoch: 031, Train Loss: 0.346, Train Acc: 0.853, Test Loss: 0.473, Test Acc: 0.816\n",
      "Epoch: 032, Train Loss: 0.354, Train Acc: 0.867, Test Loss: 0.502, Test Acc: 0.816\n",
      "Epoch: 033, Train Loss: 0.349, Train Acc: 0.867, Test Loss: 0.498, Test Acc: 0.816\n",
      "Epoch: 034, Train Loss: 0.351, Train Acc: 0.867, Test Loss: 0.482, Test Acc: 0.816\n",
      "Epoch: 035, Train Loss: 0.344, Train Acc: 0.860, Test Loss: 0.532, Test Acc: 0.816\n",
      "Epoch: 036, Train Loss: 0.348, Train Acc: 0.867, Test Loss: 0.509, Test Acc: 0.816\n",
      "Epoch: 037, Train Loss: 0.350, Train Acc: 0.867, Test Loss: 0.496, Test Acc: 0.816\n",
      "Epoch: 038, Train Loss: 0.350, Train Acc: 0.867, Test Loss: 0.501, Test Acc: 0.816\n",
      "Epoch: 039, Train Loss: 0.345, Train Acc: 0.867, Test Loss: 0.511, Test Acc: 0.816\n",
      "Epoch: 040, Train Loss: 0.346, Train Acc: 0.867, Test Loss: 0.507, Test Acc: 0.816\n",
      "Epoch: 041, Train Loss: 0.348, Train Acc: 0.867, Test Loss: 0.520, Test Acc: 0.816\n",
      "Epoch: 042, Train Loss: 0.348, Train Acc: 0.867, Test Loss: 0.500, Test Acc: 0.816\n",
      "Epoch: 043, Train Loss: 0.344, Train Acc: 0.867, Test Loss: 0.524, Test Acc: 0.816\n",
      "Epoch: 044, Train Loss: 0.351, Train Acc: 0.867, Test Loss: 0.498, Test Acc: 0.816\n",
      "Epoch: 045, Train Loss: 0.347, Train Acc: 0.867, Test Loss: 0.486, Test Acc: 0.816\n",
      "Epoch: 046, Train Loss: 0.344, Train Acc: 0.867, Test Loss: 0.516, Test Acc: 0.816\n",
      "Epoch: 047, Train Loss: 0.346, Train Acc: 0.867, Test Loss: 0.494, Test Acc: 0.816\n",
      "Epoch: 048, Train Loss: 0.344, Train Acc: 0.880, Test Loss: 0.521, Test Acc: 0.816\n",
      "Epoch: 049, Train Loss: 0.347, Train Acc: 0.867, Test Loss: 0.490, Test Acc: 0.816\n",
      "RUN:0,Test Acc:0.8158\n",
      "Epoch: 001, Train Loss: 0.662, Train Acc: 0.653, Test Loss: 0.578, Test Acc: 0.711\n",
      "Epoch: 002, Train Loss: 0.624, Train Acc: 0.653, Test Loss: 0.490, Test Acc: 0.711\n",
      "Epoch: 003, Train Loss: 0.595, Train Acc: 0.653, Test Loss: 0.429, Test Acc: 0.711\n",
      "Epoch: 004, Train Loss: 0.575, Train Acc: 0.653, Test Loss: 0.395, Test Acc: 0.711\n",
      "Epoch: 005, Train Loss: 0.562, Train Acc: 0.653, Test Loss: 0.367, Test Acc: 0.711\n",
      "Epoch: 006, Train Loss: 0.548, Train Acc: 0.653, Test Loss: 0.362, Test Acc: 0.711\n",
      "Epoch: 007, Train Loss: 0.527, Train Acc: 0.693, Test Loss: 0.333, Test Acc: 0.711\n",
      "Epoch: 008, Train Loss: 0.506, Train Acc: 0.733, Test Loss: 0.298, Test Acc: 0.789\n",
      "Epoch: 009, Train Loss: 0.484, Train Acc: 0.753, Test Loss: 0.288, Test Acc: 0.842\n",
      "Epoch: 010, Train Loss: 0.465, Train Acc: 0.780, Test Loss: 0.252, Test Acc: 0.842\n",
      "Epoch: 011, Train Loss: 0.450, Train Acc: 0.813, Test Loss: 0.224, Test Acc: 0.895\n",
      "Epoch: 012, Train Loss: 0.435, Train Acc: 0.813, Test Loss: 0.198, Test Acc: 0.895\n",
      "Epoch: 013, Train Loss: 0.433, Train Acc: 0.833, Test Loss: 0.184, Test Acc: 0.895\n",
      "Epoch: 014, Train Loss: 0.414, Train Acc: 0.833, Test Loss: 0.162, Test Acc: 0.895\n",
      "Epoch: 015, Train Loss: 0.413, Train Acc: 0.833, Test Loss: 0.193, Test Acc: 0.895\n",
      "Epoch: 016, Train Loss: 0.405, Train Acc: 0.840, Test Loss: 0.170, Test Acc: 0.895\n",
      "Epoch: 017, Train Loss: 0.404, Train Acc: 0.840, Test Loss: 0.154, Test Acc: 0.895\n",
      "Epoch: 018, Train Loss: 0.395, Train Acc: 0.840, Test Loss: 0.169, Test Acc: 0.895\n",
      "Epoch: 019, Train Loss: 0.399, Train Acc: 0.840, Test Loss: 0.138, Test Acc: 0.895\n",
      "Epoch: 020, Train Loss: 0.386, Train Acc: 0.840, Test Loss: 0.167, Test Acc: 0.895\n",
      "Epoch: 021, Train Loss: 0.385, Train Acc: 0.840, Test Loss: 0.140, Test Acc: 0.895\n",
      "Epoch: 022, Train Loss: 0.393, Train Acc: 0.840, Test Loss: 0.128, Test Acc: 0.895\n",
      "Epoch: 023, Train Loss: 0.388, Train Acc: 0.833, Test Loss: 0.137, Test Acc: 0.895\n",
      "Epoch: 024, Train Loss: 0.389, Train Acc: 0.847, Test Loss: 0.151, Test Acc: 0.895\n",
      "Epoch: 025, Train Loss: 0.388, Train Acc: 0.840, Test Loss: 0.127, Test Acc: 0.895\n",
      "Epoch: 026, Train Loss: 0.379, Train Acc: 0.847, Test Loss: 0.156, Test Acc: 0.895\n",
      "Epoch: 027, Train Loss: 0.378, Train Acc: 0.840, Test Loss: 0.120, Test Acc: 0.895\n",
      "Epoch: 028, Train Loss: 0.388, Train Acc: 0.847, Test Loss: 0.137, Test Acc: 0.895\n",
      "Epoch: 029, Train Loss: 0.379, Train Acc: 0.853, Test Loss: 0.116, Test Acc: 0.895\n",
      "Epoch: 030, Train Loss: 0.377, Train Acc: 0.847, Test Loss: 0.132, Test Acc: 0.895\n",
      "Epoch: 031, Train Loss: 0.376, Train Acc: 0.847, Test Loss: 0.136, Test Acc: 0.895\n",
      "Epoch: 032, Train Loss: 0.377, Train Acc: 0.847, Test Loss: 0.132, Test Acc: 0.895\n",
      "Epoch: 033, Train Loss: 0.394, Train Acc: 0.847, Test Loss: 0.141, Test Acc: 0.895\n",
      "Epoch: 034, Train Loss: 0.386, Train Acc: 0.827, Test Loss: 0.103, Test Acc: 0.895\n",
      "Epoch: 035, Train Loss: 0.390, Train Acc: 0.840, Test Loss: 0.185, Test Acc: 0.895\n",
      "Epoch: 036, Train Loss: 0.378, Train Acc: 0.853, Test Loss: 0.112, Test Acc: 0.895\n",
      "Epoch: 037, Train Loss: 0.376, Train Acc: 0.847, Test Loss: 0.147, Test Acc: 0.895\n",
      "Epoch: 038, Train Loss: 0.375, Train Acc: 0.847, Test Loss: 0.132, Test Acc: 0.895\n",
      "Epoch: 039, Train Loss: 0.374, Train Acc: 0.847, Test Loss: 0.130, Test Acc: 0.895\n",
      "Epoch: 040, Train Loss: 0.380, Train Acc: 0.853, Test Loss: 0.116, Test Acc: 0.895\n",
      "Epoch: 041, Train Loss: 0.373, Train Acc: 0.860, Test Loss: 0.153, Test Acc: 0.895\n",
      "Epoch: 042, Train Loss: 0.371, Train Acc: 0.847, Test Loss: 0.125, Test Acc: 0.895\n",
      "Epoch: 043, Train Loss: 0.370, Train Acc: 0.847, Test Loss: 0.129, Test Acc: 0.895\n",
      "Epoch: 044, Train Loss: 0.369, Train Acc: 0.847, Test Loss: 0.122, Test Acc: 0.895\n",
      "Epoch: 045, Train Loss: 0.369, Train Acc: 0.860, Test Loss: 0.146, Test Acc: 0.895\n",
      "Epoch: 046, Train Loss: 0.371, Train Acc: 0.847, Test Loss: 0.119, Test Acc: 0.895\n",
      "Epoch: 047, Train Loss: 0.369, Train Acc: 0.860, Test Loss: 0.140, Test Acc: 0.895\n",
      "Epoch: 048, Train Loss: 0.373, Train Acc: 0.847, Test Loss: 0.119, Test Acc: 0.895\n",
      "Epoch: 049, Train Loss: 0.368, Train Acc: 0.860, Test Loss: 0.150, Test Acc: 0.895\n",
      "RUN:1,Test Acc:0.8947\n",
      "Epoch: 001, Train Loss: 0.636, Train Acc: 0.647, Test Loss: 0.556, Test Acc: 0.737\n",
      "Epoch: 002, Train Loss: 0.607, Train Acc: 0.647, Test Loss: 0.508, Test Acc: 0.737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Loss: 0.584, Train Acc: 0.647, Test Loss: 0.476, Test Acc: 0.737\n",
      "Epoch: 004, Train Loss: 0.567, Train Acc: 0.647, Test Loss: 0.462, Test Acc: 0.737\n",
      "Epoch: 005, Train Loss: 0.547, Train Acc: 0.647, Test Loss: 0.444, Test Acc: 0.737\n",
      "Epoch: 006, Train Loss: 0.529, Train Acc: 0.673, Test Loss: 0.408, Test Acc: 0.789\n",
      "Epoch: 007, Train Loss: 0.504, Train Acc: 0.720, Test Loss: 0.378, Test Acc: 0.816\n",
      "Epoch: 008, Train Loss: 0.483, Train Acc: 0.787, Test Loss: 0.367, Test Acc: 0.868\n",
      "Epoch: 009, Train Loss: 0.459, Train Acc: 0.787, Test Loss: 0.334, Test Acc: 0.868\n",
      "Epoch: 010, Train Loss: 0.448, Train Acc: 0.827, Test Loss: 0.315, Test Acc: 0.895\n",
      "Epoch: 011, Train Loss: 0.441, Train Acc: 0.840, Test Loss: 0.315, Test Acc: 0.895\n",
      "Epoch: 012, Train Loss: 0.417, Train Acc: 0.833, Test Loss: 0.289, Test Acc: 0.895\n",
      "Epoch: 013, Train Loss: 0.415, Train Acc: 0.840, Test Loss: 0.286, Test Acc: 0.895\n",
      "Epoch: 014, Train Loss: 0.405, Train Acc: 0.833, Test Loss: 0.286, Test Acc: 0.895\n",
      "Epoch: 015, Train Loss: 0.407, Train Acc: 0.833, Test Loss: 0.277, Test Acc: 0.895\n",
      "Epoch: 016, Train Loss: 0.414, Train Acc: 0.840, Test Loss: 0.264, Test Acc: 0.895\n",
      "Epoch: 017, Train Loss: 0.412, Train Acc: 0.820, Test Loss: 0.274, Test Acc: 0.947\n",
      "Epoch: 018, Train Loss: 0.390, Train Acc: 0.833, Test Loss: 0.260, Test Acc: 0.895\n",
      "Epoch: 019, Train Loss: 0.409, Train Acc: 0.833, Test Loss: 0.263, Test Acc: 0.947\n",
      "Epoch: 020, Train Loss: 0.400, Train Acc: 0.833, Test Loss: 0.256, Test Acc: 0.895\n",
      "Epoch: 021, Train Loss: 0.394, Train Acc: 0.833, Test Loss: 0.260, Test Acc: 0.947\n",
      "Epoch: 022, Train Loss: 0.389, Train Acc: 0.833, Test Loss: 0.250, Test Acc: 0.895\n",
      "Epoch: 023, Train Loss: 0.392, Train Acc: 0.833, Test Loss: 0.250, Test Acc: 0.947\n",
      "Epoch: 024, Train Loss: 0.390, Train Acc: 0.833, Test Loss: 0.257, Test Acc: 0.947\n",
      "Epoch: 025, Train Loss: 0.387, Train Acc: 0.833, Test Loss: 0.248, Test Acc: 0.947\n",
      "Epoch: 026, Train Loss: 0.390, Train Acc: 0.833, Test Loss: 0.246, Test Acc: 0.947\n",
      "Epoch: 027, Train Loss: 0.387, Train Acc: 0.833, Test Loss: 0.243, Test Acc: 0.947\n",
      "Epoch: 028, Train Loss: 0.388, Train Acc: 0.833, Test Loss: 0.245, Test Acc: 0.947\n",
      "Epoch: 029, Train Loss: 0.386, Train Acc: 0.833, Test Loss: 0.244, Test Acc: 0.947\n",
      "Epoch: 030, Train Loss: 0.387, Train Acc: 0.833, Test Loss: 0.242, Test Acc: 0.947\n",
      "Epoch: 031, Train Loss: 0.386, Train Acc: 0.833, Test Loss: 0.243, Test Acc: 0.947\n",
      "Epoch: 032, Train Loss: 0.395, Train Acc: 0.833, Test Loss: 0.245, Test Acc: 0.947\n",
      "Epoch: 033, Train Loss: 0.403, Train Acc: 0.833, Test Loss: 0.240, Test Acc: 0.895\n",
      "Epoch: 034, Train Loss: 0.386, Train Acc: 0.833, Test Loss: 0.256, Test Acc: 0.947\n",
      "Epoch: 035, Train Loss: 0.393, Train Acc: 0.833, Test Loss: 0.240, Test Acc: 0.947\n",
      "Epoch: 036, Train Loss: 0.401, Train Acc: 0.833, Test Loss: 0.241, Test Acc: 0.947\n",
      "Epoch: 037, Train Loss: 0.397, Train Acc: 0.840, Test Loss: 0.251, Test Acc: 0.947\n",
      "Epoch: 038, Train Loss: 0.411, Train Acc: 0.833, Test Loss: 0.243, Test Acc: 0.895\n",
      "Epoch: 039, Train Loss: 0.400, Train Acc: 0.840, Test Loss: 0.257, Test Acc: 0.947\n",
      "Epoch: 040, Train Loss: 0.383, Train Acc: 0.833, Test Loss: 0.241, Test Acc: 0.947\n",
      "Epoch: 041, Train Loss: 0.386, Train Acc: 0.833, Test Loss: 0.244, Test Acc: 0.947\n",
      "Epoch: 042, Train Loss: 0.384, Train Acc: 0.833, Test Loss: 0.239, Test Acc: 0.947\n",
      "Epoch: 043, Train Loss: 0.382, Train Acc: 0.833, Test Loss: 0.244, Test Acc: 0.947\n",
      "Epoch: 044, Train Loss: 0.385, Train Acc: 0.833, Test Loss: 0.240, Test Acc: 0.947\n",
      "Epoch: 045, Train Loss: 0.383, Train Acc: 0.833, Test Loss: 0.240, Test Acc: 0.947\n",
      "Epoch: 046, Train Loss: 0.384, Train Acc: 0.833, Test Loss: 0.241, Test Acc: 0.947\n",
      "Epoch: 047, Train Loss: 0.388, Train Acc: 0.833, Test Loss: 0.236, Test Acc: 0.947\n",
      "Epoch: 048, Train Loss: 0.381, Train Acc: 0.840, Test Loss: 0.245, Test Acc: 0.947\n",
      "Epoch: 049, Train Loss: 0.387, Train Acc: 0.840, Test Loss: 0.246, Test Acc: 0.947\n",
      "RUN:2,Test Acc:0.9474\n",
      "Epoch: 001, Train Loss: 0.622, Train Acc: 0.660, Test Loss: 0.515, Test Acc: 0.684\n",
      "Epoch: 002, Train Loss: 0.595, Train Acc: 0.660, Test Loss: 0.468, Test Acc: 0.684\n",
      "Epoch: 003, Train Loss: 0.573, Train Acc: 0.660, Test Loss: 0.458, Test Acc: 0.684\n",
      "Epoch: 004, Train Loss: 0.557, Train Acc: 0.660, Test Loss: 0.449, Test Acc: 0.684\n",
      "Epoch: 005, Train Loss: 0.539, Train Acc: 0.660, Test Loss: 0.431, Test Acc: 0.684\n",
      "Epoch: 006, Train Loss: 0.517, Train Acc: 0.687, Test Loss: 0.408, Test Acc: 0.684\n",
      "Epoch: 007, Train Loss: 0.497, Train Acc: 0.753, Test Loss: 0.384, Test Acc: 0.711\n",
      "Epoch: 008, Train Loss: 0.474, Train Acc: 0.773, Test Loss: 0.358, Test Acc: 0.684\n",
      "Epoch: 009, Train Loss: 0.448, Train Acc: 0.840, Test Loss: 0.352, Test Acc: 0.763\n",
      "Epoch: 010, Train Loss: 0.427, Train Acc: 0.847, Test Loss: 0.327, Test Acc: 0.763\n",
      "Epoch: 011, Train Loss: 0.407, Train Acc: 0.847, Test Loss: 0.306, Test Acc: 0.789\n",
      "Epoch: 012, Train Loss: 0.400, Train Acc: 0.847, Test Loss: 0.291, Test Acc: 0.789\n",
      "Epoch: 013, Train Loss: 0.407, Train Acc: 0.847, Test Loss: 0.295, Test Acc: 0.816\n",
      "Epoch: 014, Train Loss: 0.386, Train Acc: 0.847, Test Loss: 0.264, Test Acc: 0.789\n",
      "Epoch: 015, Train Loss: 0.368, Train Acc: 0.860, Test Loss: 0.297, Test Acc: 0.842\n",
      "Epoch: 016, Train Loss: 0.376, Train Acc: 0.847, Test Loss: 0.264, Test Acc: 0.816\n",
      "Epoch: 017, Train Loss: 0.365, Train Acc: 0.860, Test Loss: 0.283, Test Acc: 0.842\n",
      "Epoch: 018, Train Loss: 0.362, Train Acc: 0.860, Test Loss: 0.263, Test Acc: 0.842\n",
      "Epoch: 019, Train Loss: 0.366, Train Acc: 0.860, Test Loss: 0.260, Test Acc: 0.842\n",
      "Epoch: 020, Train Loss: 0.360, Train Acc: 0.860, Test Loss: 0.279, Test Acc: 0.842\n",
      "Epoch: 021, Train Loss: 0.354, Train Acc: 0.860, Test Loss: 0.253, Test Acc: 0.842\n",
      "Epoch: 022, Train Loss: 0.360, Train Acc: 0.860, Test Loss: 0.255, Test Acc: 0.842\n",
      "Epoch: 023, Train Loss: 0.368, Train Acc: 0.860, Test Loss: 0.277, Test Acc: 0.842\n",
      "Epoch: 024, Train Loss: 0.354, Train Acc: 0.860, Test Loss: 0.254, Test Acc: 0.842\n",
      "Epoch: 025, Train Loss: 0.353, Train Acc: 0.860, Test Loss: 0.266, Test Acc: 0.842\n",
      "Epoch: 026, Train Loss: 0.355, Train Acc: 0.860, Test Loss: 0.270, Test Acc: 0.842\n",
      "Epoch: 027, Train Loss: 0.357, Train Acc: 0.860, Test Loss: 0.272, Test Acc: 0.842\n",
      "Epoch: 028, Train Loss: 0.355, Train Acc: 0.860, Test Loss: 0.257, Test Acc: 0.842\n",
      "Epoch: 029, Train Loss: 0.350, Train Acc: 0.860, Test Loss: 0.271, Test Acc: 0.842\n",
      "Epoch: 030, Train Loss: 0.352, Train Acc: 0.867, Test Loss: 0.278, Test Acc: 0.868\n",
      "Epoch: 031, Train Loss: 0.360, Train Acc: 0.860, Test Loss: 0.263, Test Acc: 0.842\n",
      "Epoch: 032, Train Loss: 0.350, Train Acc: 0.860, Test Loss: 0.267, Test Acc: 0.842\n",
      "Epoch: 033, Train Loss: 0.350, Train Acc: 0.860, Test Loss: 0.269, Test Acc: 0.842\n",
      "Epoch: 034, Train Loss: 0.352, Train Acc: 0.860, Test Loss: 0.268, Test Acc: 0.842\n",
      "Epoch: 035, Train Loss: 0.356, Train Acc: 0.867, Test Loss: 0.288, Test Acc: 0.868\n",
      "Epoch: 036, Train Loss: 0.351, Train Acc: 0.860, Test Loss: 0.262, Test Acc: 0.842\n",
      "Epoch: 037, Train Loss: 0.365, Train Acc: 0.860, Test Loss: 0.261, Test Acc: 0.842\n",
      "Epoch: 038, Train Loss: 0.352, Train Acc: 0.860, Test Loss: 0.293, Test Acc: 0.868\n",
      "Epoch: 039, Train Loss: 0.354, Train Acc: 0.860, Test Loss: 0.257, Test Acc: 0.842\n",
      "Epoch: 040, Train Loss: 0.348, Train Acc: 0.867, Test Loss: 0.283, Test Acc: 0.868\n",
      "Epoch: 041, Train Loss: 0.357, Train Acc: 0.860, Test Loss: 0.270, Test Acc: 0.842\n",
      "Epoch: 042, Train Loss: 0.359, Train Acc: 0.860, Test Loss: 0.257, Test Acc: 0.842\n",
      "Epoch: 043, Train Loss: 0.347, Train Acc: 0.860, Test Loss: 0.296, Test Acc: 0.868\n",
      "Epoch: 044, Train Loss: 0.351, Train Acc: 0.860, Test Loss: 0.274, Test Acc: 0.842\n",
      "Epoch: 045, Train Loss: 0.357, Train Acc: 0.860, Test Loss: 0.260, Test Acc: 0.842\n",
      "Epoch: 046, Train Loss: 0.349, Train Acc: 0.867, Test Loss: 0.282, Test Acc: 0.868\n",
      "Epoch: 047, Train Loss: 0.352, Train Acc: 0.860, Test Loss: 0.272, Test Acc: 0.842\n",
      "Epoch: 048, Train Loss: 0.349, Train Acc: 0.860, Test Loss: 0.268, Test Acc: 0.842\n",
      "Epoch: 049, Train Loss: 0.349, Train Acc: 0.860, Test Loss: 0.262, Test Acc: 0.842\n",
      "RUN:3,Test Acc:0.8421\n",
      "Epoch: 001, Train Loss: 0.646, Train Acc: 0.680, Test Loss: 0.611, Test Acc: 0.605\n",
      "Epoch: 002, Train Loss: 0.553, Train Acc: 0.680, Test Loss: 0.629, Test Acc: 0.605\n",
      "Epoch: 003, Train Loss: 0.537, Train Acc: 0.680, Test Loss: 0.602, Test Acc: 0.605\n",
      "Epoch: 004, Train Loss: 0.511, Train Acc: 0.680, Test Loss: 0.583, Test Acc: 0.605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Loss: 0.490, Train Acc: 0.680, Test Loss: 0.579, Test Acc: 0.605\n",
      "Epoch: 006, Train Loss: 0.465, Train Acc: 0.740, Test Loss: 0.572, Test Acc: 0.684\n",
      "Epoch: 007, Train Loss: 0.441, Train Acc: 0.793, Test Loss: 0.562, Test Acc: 0.711\n",
      "Epoch: 008, Train Loss: 0.420, Train Acc: 0.840, Test Loss: 0.558, Test Acc: 0.711\n",
      "Epoch: 009, Train Loss: 0.407, Train Acc: 0.840, Test Loss: 0.560, Test Acc: 0.711\n",
      "Epoch: 010, Train Loss: 0.379, Train Acc: 0.860, Test Loss: 0.555, Test Acc: 0.684\n",
      "Epoch: 011, Train Loss: 0.368, Train Acc: 0.887, Test Loss: 0.554, Test Acc: 0.684\n",
      "Epoch: 012, Train Loss: 0.380, Train Acc: 0.867, Test Loss: 0.584, Test Acc: 0.684\n",
      "Epoch: 013, Train Loss: 0.337, Train Acc: 0.880, Test Loss: 0.562, Test Acc: 0.737\n",
      "Epoch: 014, Train Loss: 0.334, Train Acc: 0.880, Test Loss: 0.596, Test Acc: 0.684\n",
      "Epoch: 015, Train Loss: 0.343, Train Acc: 0.893, Test Loss: 0.588, Test Acc: 0.684\n",
      "Epoch: 016, Train Loss: 0.333, Train Acc: 0.880, Test Loss: 0.581, Test Acc: 0.737\n",
      "Epoch: 017, Train Loss: 0.333, Train Acc: 0.880, Test Loss: 0.645, Test Acc: 0.684\n",
      "Epoch: 018, Train Loss: 0.298, Train Acc: 0.893, Test Loss: 0.591, Test Acc: 0.737\n",
      "Epoch: 019, Train Loss: 0.330, Train Acc: 0.887, Test Loss: 0.599, Test Acc: 0.737\n",
      "Epoch: 020, Train Loss: 0.318, Train Acc: 0.887, Test Loss: 0.635, Test Acc: 0.684\n",
      "Epoch: 021, Train Loss: 0.314, Train Acc: 0.887, Test Loss: 0.605, Test Acc: 0.737\n",
      "Epoch: 022, Train Loss: 0.305, Train Acc: 0.887, Test Loss: 0.633, Test Acc: 0.737\n",
      "Epoch: 023, Train Loss: 0.316, Train Acc: 0.887, Test Loss: 0.614, Test Acc: 0.737\n",
      "Epoch: 024, Train Loss: 0.308, Train Acc: 0.887, Test Loss: 0.615, Test Acc: 0.737\n",
      "Epoch: 025, Train Loss: 0.310, Train Acc: 0.887, Test Loss: 0.633, Test Acc: 0.737\n",
      "Epoch: 026, Train Loss: 0.310, Train Acc: 0.887, Test Loss: 0.619, Test Acc: 0.737\n",
      "Epoch: 027, Train Loss: 0.310, Train Acc: 0.887, Test Loss: 0.644, Test Acc: 0.737\n",
      "Epoch: 028, Train Loss: 0.302, Train Acc: 0.887, Test Loss: 0.622, Test Acc: 0.737\n",
      "Epoch: 029, Train Loss: 0.306, Train Acc: 0.887, Test Loss: 0.629, Test Acc: 0.737\n",
      "Epoch: 030, Train Loss: 0.303, Train Acc: 0.887, Test Loss: 0.625, Test Acc: 0.737\n",
      "Epoch: 031, Train Loss: 0.301, Train Acc: 0.887, Test Loss: 0.636, Test Acc: 0.737\n",
      "Epoch: 032, Train Loss: 0.304, Train Acc: 0.887, Test Loss: 0.644, Test Acc: 0.737\n",
      "Epoch: 033, Train Loss: 0.303, Train Acc: 0.887, Test Loss: 0.640, Test Acc: 0.737\n",
      "Epoch: 034, Train Loss: 0.303, Train Acc: 0.887, Test Loss: 0.649, Test Acc: 0.737\n",
      "Epoch: 035, Train Loss: 0.323, Train Acc: 0.887, Test Loss: 0.641, Test Acc: 0.737\n",
      "Epoch: 036, Train Loss: 0.300, Train Acc: 0.887, Test Loss: 0.670, Test Acc: 0.737\n",
      "Epoch: 037, Train Loss: 0.302, Train Acc: 0.900, Test Loss: 0.633, Test Acc: 0.737\n",
      "Epoch: 038, Train Loss: 0.307, Train Acc: 0.887, Test Loss: 0.642, Test Acc: 0.737\n",
      "Epoch: 039, Train Loss: 0.303, Train Acc: 0.887, Test Loss: 0.664, Test Acc: 0.737\n",
      "Epoch: 040, Train Loss: 0.323, Train Acc: 0.900, Test Loss: 0.637, Test Acc: 0.737\n",
      "Epoch: 041, Train Loss: 0.320, Train Acc: 0.887, Test Loss: 0.678, Test Acc: 0.737\n",
      "Epoch: 042, Train Loss: 0.295, Train Acc: 0.900, Test Loss: 0.635, Test Acc: 0.737\n",
      "Epoch: 043, Train Loss: 0.309, Train Acc: 0.893, Test Loss: 0.636, Test Acc: 0.737\n",
      "Epoch: 044, Train Loss: 0.304, Train Acc: 0.887, Test Loss: 0.658, Test Acc: 0.737\n",
      "Epoch: 045, Train Loss: 0.300, Train Acc: 0.887, Test Loss: 0.645, Test Acc: 0.737\n",
      "Epoch: 046, Train Loss: 0.303, Train Acc: 0.900, Test Loss: 0.641, Test Acc: 0.737\n",
      "Epoch: 047, Train Loss: 0.295, Train Acc: 0.887, Test Loss: 0.664, Test Acc: 0.737\n",
      "Epoch: 048, Train Loss: 0.304, Train Acc: 0.887, Test Loss: 0.648, Test Acc: 0.737\n",
      "Epoch: 049, Train Loss: 0.299, Train Acc: 0.900, Test Loss: 0.648, Test Acc: 0.737\n",
      "RUN:4,Test Acc:0.7368\n",
      "Epoch: 001, Train Loss: 0.670, Train Acc: 0.680, Test Loss: 0.584, Test Acc: 0.605\n",
      "Epoch: 002, Train Loss: 0.593, Train Acc: 0.680, Test Loss: 0.512, Test Acc: 0.605\n",
      "Epoch: 003, Train Loss: 0.559, Train Acc: 0.680, Test Loss: 0.494, Test Acc: 0.605\n",
      "Epoch: 004, Train Loss: 0.550, Train Acc: 0.680, Test Loss: 0.479, Test Acc: 0.605\n",
      "Epoch: 005, Train Loss: 0.540, Train Acc: 0.680, Test Loss: 0.464, Test Acc: 0.605\n",
      "Epoch: 006, Train Loss: 0.524, Train Acc: 0.680, Test Loss: 0.446, Test Acc: 0.605\n",
      "Epoch: 007, Train Loss: 0.514, Train Acc: 0.680, Test Loss: 0.430, Test Acc: 0.605\n",
      "Epoch: 008, Train Loss: 0.497, Train Acc: 0.707, Test Loss: 0.409, Test Acc: 0.632\n",
      "Epoch: 009, Train Loss: 0.484, Train Acc: 0.733, Test Loss: 0.391, Test Acc: 0.684\n",
      "Epoch: 010, Train Loss: 0.468, Train Acc: 0.760, Test Loss: 0.375, Test Acc: 0.842\n",
      "Epoch: 011, Train Loss: 0.456, Train Acc: 0.800, Test Loss: 0.363, Test Acc: 0.921\n",
      "Epoch: 012, Train Loss: 0.441, Train Acc: 0.800, Test Loss: 0.341, Test Acc: 0.921\n",
      "Epoch: 013, Train Loss: 0.429, Train Acc: 0.807, Test Loss: 0.327, Test Acc: 0.921\n",
      "Epoch: 014, Train Loss: 0.443, Train Acc: 0.807, Test Loss: 0.319, Test Acc: 0.921\n",
      "Epoch: 015, Train Loss: 0.415, Train Acc: 0.820, Test Loss: 0.329, Test Acc: 0.947\n",
      "Epoch: 016, Train Loss: 0.416, Train Acc: 0.833, Test Loss: 0.305, Test Acc: 0.921\n",
      "Epoch: 017, Train Loss: 0.407, Train Acc: 0.813, Test Loss: 0.302, Test Acc: 0.947\n",
      "Epoch: 018, Train Loss: 0.409, Train Acc: 0.820, Test Loss: 0.302, Test Acc: 0.947\n",
      "Epoch: 019, Train Loss: 0.395, Train Acc: 0.827, Test Loss: 0.295, Test Acc: 0.947\n",
      "Epoch: 020, Train Loss: 0.400, Train Acc: 0.820, Test Loss: 0.292, Test Acc: 0.947\n",
      "Epoch: 021, Train Loss: 0.395, Train Acc: 0.820, Test Loss: 0.291, Test Acc: 0.947\n",
      "Epoch: 022, Train Loss: 0.393, Train Acc: 0.820, Test Loss: 0.288, Test Acc: 0.947\n",
      "Epoch: 023, Train Loss: 0.397, Train Acc: 0.833, Test Loss: 0.293, Test Acc: 0.947\n",
      "Epoch: 024, Train Loss: 0.390, Train Acc: 0.820, Test Loss: 0.286, Test Acc: 0.947\n",
      "Epoch: 025, Train Loss: 0.388, Train Acc: 0.833, Test Loss: 0.287, Test Acc: 0.947\n",
      "Epoch: 026, Train Loss: 0.385, Train Acc: 0.833, Test Loss: 0.286, Test Acc: 0.947\n",
      "Epoch: 027, Train Loss: 0.387, Train Acc: 0.820, Test Loss: 0.286, Test Acc: 0.947\n",
      "Epoch: 028, Train Loss: 0.391, Train Acc: 0.833, Test Loss: 0.287, Test Acc: 0.947\n",
      "Epoch: 029, Train Loss: 0.396, Train Acc: 0.840, Test Loss: 0.301, Test Acc: 0.947\n",
      "Epoch: 030, Train Loss: 0.381, Train Acc: 0.820, Test Loss: 0.299, Test Acc: 0.921\n",
      "Epoch: 031, Train Loss: 0.390, Train Acc: 0.833, Test Loss: 0.289, Test Acc: 0.947\n",
      "Epoch: 032, Train Loss: 0.386, Train Acc: 0.833, Test Loss: 0.289, Test Acc: 0.947\n",
      "Epoch: 033, Train Loss: 0.388, Train Acc: 0.820, Test Loss: 0.292, Test Acc: 0.947\n",
      "Epoch: 034, Train Loss: 0.384, Train Acc: 0.833, Test Loss: 0.291, Test Acc: 0.947\n",
      "Epoch: 035, Train Loss: 0.385, Train Acc: 0.833, Test Loss: 0.289, Test Acc: 0.947\n",
      "Epoch: 036, Train Loss: 0.385, Train Acc: 0.833, Test Loss: 0.291, Test Acc: 0.947\n",
      "Epoch: 037, Train Loss: 0.383, Train Acc: 0.847, Test Loss: 0.296, Test Acc: 0.947\n",
      "Epoch: 038, Train Loss: 0.390, Train Acc: 0.833, Test Loss: 0.291, Test Acc: 0.947\n",
      "Epoch: 039, Train Loss: 0.378, Train Acc: 0.833, Test Loss: 0.289, Test Acc: 0.947\n",
      "Epoch: 040, Train Loss: 0.377, Train Acc: 0.833, Test Loss: 0.288, Test Acc: 0.947\n",
      "Epoch: 041, Train Loss: 0.379, Train Acc: 0.833, Test Loss: 0.290, Test Acc: 0.947\n",
      "Epoch: 042, Train Loss: 0.388, Train Acc: 0.847, Test Loss: 0.292, Test Acc: 0.947\n",
      "Epoch: 043, Train Loss: 0.380, Train Acc: 0.820, Test Loss: 0.299, Test Acc: 0.947\n",
      "Epoch: 044, Train Loss: 0.378, Train Acc: 0.833, Test Loss: 0.293, Test Acc: 0.947\n",
      "Epoch: 045, Train Loss: 0.387, Train Acc: 0.840, Test Loss: 0.305, Test Acc: 0.947\n",
      "Epoch: 046, Train Loss: 0.379, Train Acc: 0.833, Test Loss: 0.303, Test Acc: 0.947\n",
      "Epoch: 047, Train Loss: 0.388, Train Acc: 0.833, Test Loss: 0.301, Test Acc: 0.947\n",
      "Epoch: 048, Train Loss: 0.381, Train Acc: 0.847, Test Loss: 0.306, Test Acc: 0.947\n",
      "Epoch: 049, Train Loss: 0.377, Train Acc: 0.833, Test Loss: 0.301, Test Acc: 0.947\n",
      "RUN:5,Test Acc:0.9474\n",
      "Epoch: 001, Train Loss: 0.714, Train Acc: 0.733, Test Loss: 0.653, Test Acc: 0.737\n",
      "Epoch: 002, Train Loss: 0.618, Train Acc: 0.687, Test Loss: 0.634, Test Acc: 0.579\n",
      "Epoch: 003, Train Loss: 0.567, Train Acc: 0.687, Test Loss: 0.626, Test Acc: 0.579\n",
      "Epoch: 004, Train Loss: 0.534, Train Acc: 0.687, Test Loss: 0.626, Test Acc: 0.579\n",
      "Epoch: 005, Train Loss: 0.522, Train Acc: 0.687, Test Loss: 0.625, Test Acc: 0.579\n",
      "Epoch: 006, Train Loss: 0.512, Train Acc: 0.687, Test Loss: 0.603, Test Acc: 0.579\n",
      "Epoch: 007, Train Loss: 0.499, Train Acc: 0.693, Test Loss: 0.579, Test Acc: 0.605\n",
      "Epoch: 008, Train Loss: 0.484, Train Acc: 0.707, Test Loss: 0.574, Test Acc: 0.658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Train Loss: 0.468, Train Acc: 0.727, Test Loss: 0.563, Test Acc: 0.763\n",
      "Epoch: 010, Train Loss: 0.451, Train Acc: 0.780, Test Loss: 0.545, Test Acc: 0.763\n",
      "Epoch: 011, Train Loss: 0.433, Train Acc: 0.793, Test Loss: 0.537, Test Acc: 0.763\n",
      "Epoch: 012, Train Loss: 0.425, Train Acc: 0.813, Test Loss: 0.534, Test Acc: 0.789\n",
      "Epoch: 013, Train Loss: 0.418, Train Acc: 0.860, Test Loss: 0.520, Test Acc: 0.816\n",
      "Epoch: 014, Train Loss: 0.402, Train Acc: 0.820, Test Loss: 0.534, Test Acc: 0.789\n",
      "Epoch: 015, Train Loss: 0.382, Train Acc: 0.840, Test Loss: 0.519, Test Acc: 0.789\n",
      "Epoch: 016, Train Loss: 0.377, Train Acc: 0.860, Test Loss: 0.520, Test Acc: 0.816\n",
      "Epoch: 017, Train Loss: 0.368, Train Acc: 0.860, Test Loss: 0.518, Test Acc: 0.816\n",
      "Epoch: 018, Train Loss: 0.367, Train Acc: 0.847, Test Loss: 0.513, Test Acc: 0.816\n",
      "Epoch: 019, Train Loss: 0.364, Train Acc: 0.847, Test Loss: 0.512, Test Acc: 0.816\n",
      "Epoch: 020, Train Loss: 0.352, Train Acc: 0.853, Test Loss: 0.508, Test Acc: 0.816\n",
      "Epoch: 021, Train Loss: 0.360, Train Acc: 0.847, Test Loss: 0.511, Test Acc: 0.816\n",
      "Epoch: 022, Train Loss: 0.348, Train Acc: 0.853, Test Loss: 0.508, Test Acc: 0.816\n",
      "Epoch: 023, Train Loss: 0.357, Train Acc: 0.853, Test Loss: 0.509, Test Acc: 0.816\n",
      "Epoch: 024, Train Loss: 0.355, Train Acc: 0.847, Test Loss: 0.516, Test Acc: 0.816\n",
      "Epoch: 025, Train Loss: 0.346, Train Acc: 0.867, Test Loss: 0.508, Test Acc: 0.816\n",
      "Epoch: 026, Train Loss: 0.340, Train Acc: 0.853, Test Loss: 0.513, Test Acc: 0.816\n",
      "Epoch: 027, Train Loss: 0.355, Train Acc: 0.847, Test Loss: 0.524, Test Acc: 0.816\n",
      "Epoch: 028, Train Loss: 0.328, Train Acc: 0.860, Test Loss: 0.513, Test Acc: 0.789\n",
      "Epoch: 029, Train Loss: 0.358, Train Acc: 0.853, Test Loss: 0.519, Test Acc: 0.816\n",
      "Epoch: 030, Train Loss: 0.348, Train Acc: 0.867, Test Loss: 0.503, Test Acc: 0.789\n",
      "Epoch: 031, Train Loss: 0.342, Train Acc: 0.853, Test Loss: 0.517, Test Acc: 0.816\n",
      "Epoch: 032, Train Loss: 0.338, Train Acc: 0.867, Test Loss: 0.504, Test Acc: 0.816\n",
      "Epoch: 033, Train Loss: 0.336, Train Acc: 0.867, Test Loss: 0.509, Test Acc: 0.816\n",
      "Epoch: 034, Train Loss: 0.338, Train Acc: 0.867, Test Loss: 0.507, Test Acc: 0.816\n",
      "Epoch: 035, Train Loss: 0.337, Train Acc: 0.853, Test Loss: 0.519, Test Acc: 0.816\n",
      "Epoch: 036, Train Loss: 0.332, Train Acc: 0.867, Test Loss: 0.509, Test Acc: 0.816\n",
      "Epoch: 037, Train Loss: 0.334, Train Acc: 0.867, Test Loss: 0.514, Test Acc: 0.816\n",
      "Epoch: 038, Train Loss: 0.333, Train Acc: 0.867, Test Loss: 0.522, Test Acc: 0.816\n",
      "Epoch: 039, Train Loss: 0.337, Train Acc: 0.867, Test Loss: 0.518, Test Acc: 0.816\n",
      "Epoch: 040, Train Loss: 0.330, Train Acc: 0.867, Test Loss: 0.521, Test Acc: 0.816\n",
      "Epoch: 041, Train Loss: 0.329, Train Acc: 0.867, Test Loss: 0.525, Test Acc: 0.816\n",
      "Epoch: 042, Train Loss: 0.330, Train Acc: 0.867, Test Loss: 0.527, Test Acc: 0.816\n",
      "Epoch: 043, Train Loss: 0.335, Train Acc: 0.873, Test Loss: 0.534, Test Acc: 0.816\n",
      "Epoch: 044, Train Loss: 0.363, Train Acc: 0.880, Test Loss: 0.513, Test Acc: 0.789\n",
      "Epoch: 045, Train Loss: 0.325, Train Acc: 0.853, Test Loss: 0.542, Test Acc: 0.789\n",
      "Epoch: 046, Train Loss: 0.341, Train Acc: 0.867, Test Loss: 0.520, Test Acc: 0.816\n",
      "Epoch: 047, Train Loss: 0.332, Train Acc: 0.867, Test Loss: 0.518, Test Acc: 0.816\n",
      "Epoch: 048, Train Loss: 0.326, Train Acc: 0.867, Test Loss: 0.525, Test Acc: 0.816\n",
      "Epoch: 049, Train Loss: 0.325, Train Acc: 0.867, Test Loss: 0.529, Test Acc: 0.816\n",
      "RUN:6,Test Acc:0.8158\n",
      "Epoch: 001, Train Loss: 0.611, Train Acc: 0.680, Test Loss: 0.638, Test Acc: 0.605\n",
      "Epoch: 002, Train Loss: 0.585, Train Acc: 0.680, Test Loss: 0.641, Test Acc: 0.605\n",
      "Epoch: 003, Train Loss: 0.566, Train Acc: 0.680, Test Loss: 0.627, Test Acc: 0.605\n",
      "Epoch: 004, Train Loss: 0.548, Train Acc: 0.680, Test Loss: 0.607, Test Acc: 0.605\n",
      "Epoch: 005, Train Loss: 0.528, Train Acc: 0.680, Test Loss: 0.579, Test Acc: 0.605\n",
      "Epoch: 006, Train Loss: 0.507, Train Acc: 0.680, Test Loss: 0.554, Test Acc: 0.605\n",
      "Epoch: 007, Train Loss: 0.486, Train Acc: 0.727, Test Loss: 0.537, Test Acc: 0.684\n",
      "Epoch: 008, Train Loss: 0.461, Train Acc: 0.767, Test Loss: 0.542, Test Acc: 0.658\n",
      "Epoch: 009, Train Loss: 0.446, Train Acc: 0.833, Test Loss: 0.485, Test Acc: 0.737\n",
      "Epoch: 010, Train Loss: 0.413, Train Acc: 0.813, Test Loss: 0.515, Test Acc: 0.711\n",
      "Epoch: 011, Train Loss: 0.394, Train Acc: 0.833, Test Loss: 0.494, Test Acc: 0.737\n",
      "Epoch: 012, Train Loss: 0.380, Train Acc: 0.867, Test Loss: 0.470, Test Acc: 0.737\n",
      "Epoch: 013, Train Loss: 0.373, Train Acc: 0.873, Test Loss: 0.513, Test Acc: 0.737\n",
      "Epoch: 014, Train Loss: 0.356, Train Acc: 0.867, Test Loss: 0.476, Test Acc: 0.763\n",
      "Epoch: 015, Train Loss: 0.348, Train Acc: 0.880, Test Loss: 0.523, Test Acc: 0.737\n",
      "Epoch: 016, Train Loss: 0.341, Train Acc: 0.867, Test Loss: 0.490, Test Acc: 0.763\n",
      "Epoch: 017, Train Loss: 0.341, Train Acc: 0.867, Test Loss: 0.527, Test Acc: 0.737\n",
      "Epoch: 018, Train Loss: 0.339, Train Acc: 0.867, Test Loss: 0.517, Test Acc: 0.763\n",
      "Epoch: 019, Train Loss: 0.332, Train Acc: 0.867, Test Loss: 0.547, Test Acc: 0.737\n",
      "Epoch: 020, Train Loss: 0.345, Train Acc: 0.867, Test Loss: 0.533, Test Acc: 0.763\n",
      "Epoch: 021, Train Loss: 0.341, Train Acc: 0.860, Test Loss: 0.571, Test Acc: 0.737\n",
      "Epoch: 022, Train Loss: 0.332, Train Acc: 0.873, Test Loss: 0.497, Test Acc: 0.789\n",
      "Epoch: 023, Train Loss: 0.336, Train Acc: 0.867, Test Loss: 0.553, Test Acc: 0.737\n",
      "Epoch: 024, Train Loss: 0.324, Train Acc: 0.873, Test Loss: 0.500, Test Acc: 0.789\n",
      "Epoch: 025, Train Loss: 0.338, Train Acc: 0.867, Test Loss: 0.540, Test Acc: 0.763\n",
      "Epoch: 026, Train Loss: 0.345, Train Acc: 0.867, Test Loss: 0.546, Test Acc: 0.763\n",
      "Epoch: 027, Train Loss: 0.326, Train Acc: 0.867, Test Loss: 0.519, Test Acc: 0.763\n",
      "Epoch: 028, Train Loss: 0.325, Train Acc: 0.867, Test Loss: 0.527, Test Acc: 0.763\n",
      "Epoch: 029, Train Loss: 0.331, Train Acc: 0.860, Test Loss: 0.565, Test Acc: 0.737\n",
      "Epoch: 030, Train Loss: 0.329, Train Acc: 0.873, Test Loss: 0.516, Test Acc: 0.789\n",
      "Epoch: 031, Train Loss: 0.342, Train Acc: 0.867, Test Loss: 0.542, Test Acc: 0.763\n",
      "Epoch: 032, Train Loss: 0.326, Train Acc: 0.873, Test Loss: 0.523, Test Acc: 0.789\n",
      "Epoch: 033, Train Loss: 0.325, Train Acc: 0.867, Test Loss: 0.534, Test Acc: 0.763\n",
      "Epoch: 034, Train Loss: 0.326, Train Acc: 0.873, Test Loss: 0.536, Test Acc: 0.789\n",
      "Epoch: 035, Train Loss: 0.327, Train Acc: 0.873, Test Loss: 0.525, Test Acc: 0.789\n",
      "Epoch: 036, Train Loss: 0.323, Train Acc: 0.873, Test Loss: 0.509, Test Acc: 0.789\n",
      "Epoch: 037, Train Loss: 0.330, Train Acc: 0.867, Test Loss: 0.547, Test Acc: 0.763\n",
      "Epoch: 038, Train Loss: 0.326, Train Acc: 0.867, Test Loss: 0.572, Test Acc: 0.737\n",
      "Epoch: 039, Train Loss: 0.325, Train Acc: 0.873, Test Loss: 0.524, Test Acc: 0.789\n",
      "Epoch: 040, Train Loss: 0.333, Train Acc: 0.867, Test Loss: 0.552, Test Acc: 0.763\n",
      "Epoch: 041, Train Loss: 0.334, Train Acc: 0.860, Test Loss: 0.591, Test Acc: 0.737\n",
      "Epoch: 042, Train Loss: 0.324, Train Acc: 0.873, Test Loss: 0.511, Test Acc: 0.789\n",
      "Epoch: 043, Train Loss: 0.351, Train Acc: 0.873, Test Loss: 0.520, Test Acc: 0.789\n",
      "Epoch: 044, Train Loss: 0.337, Train Acc: 0.867, Test Loss: 0.623, Test Acc: 0.737\n",
      "Epoch: 045, Train Loss: 0.327, Train Acc: 0.873, Test Loss: 0.527, Test Acc: 0.789\n",
      "Epoch: 046, Train Loss: 0.344, Train Acc: 0.873, Test Loss: 0.504, Test Acc: 0.789\n",
      "Epoch: 047, Train Loss: 0.317, Train Acc: 0.867, Test Loss: 0.609, Test Acc: 0.737\n",
      "Epoch: 048, Train Loss: 0.336, Train Acc: 0.867, Test Loss: 0.556, Test Acc: 0.763\n",
      "Epoch: 049, Train Loss: 0.325, Train Acc: 0.873, Test Loss: 0.504, Test Acc: 0.789\n",
      "RUN:7,Test Acc:0.7895\n",
      "Epoch: 001, Train Loss: 0.633, Train Acc: 0.653, Test Loss: 0.558, Test Acc: 0.711\n",
      "Epoch: 002, Train Loss: 0.582, Train Acc: 0.653, Test Loss: 0.544, Test Acc: 0.711\n",
      "Epoch: 003, Train Loss: 0.568, Train Acc: 0.653, Test Loss: 0.538, Test Acc: 0.711\n",
      "Epoch: 004, Train Loss: 0.555, Train Acc: 0.653, Test Loss: 0.534, Test Acc: 0.711\n",
      "Epoch: 005, Train Loss: 0.542, Train Acc: 0.653, Test Loss: 0.523, Test Acc: 0.711\n",
      "Epoch: 006, Train Loss: 0.524, Train Acc: 0.653, Test Loss: 0.511, Test Acc: 0.711\n",
      "Epoch: 007, Train Loss: 0.506, Train Acc: 0.653, Test Loss: 0.503, Test Acc: 0.711\n",
      "Epoch: 008, Train Loss: 0.489, Train Acc: 0.720, Test Loss: 0.490, Test Acc: 0.763\n",
      "Epoch: 009, Train Loss: 0.464, Train Acc: 0.813, Test Loss: 0.501, Test Acc: 0.816\n",
      "Epoch: 010, Train Loss: 0.443, Train Acc: 0.780, Test Loss: 0.478, Test Acc: 0.763\n",
      "Epoch: 011, Train Loss: 0.428, Train Acc: 0.847, Test Loss: 0.486, Test Acc: 0.816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Train Loss: 0.400, Train Acc: 0.813, Test Loss: 0.480, Test Acc: 0.816\n",
      "Epoch: 013, Train Loss: 0.379, Train Acc: 0.860, Test Loss: 0.492, Test Acc: 0.816\n",
      "Epoch: 014, Train Loss: 0.379, Train Acc: 0.847, Test Loss: 0.497, Test Acc: 0.816\n",
      "Epoch: 015, Train Loss: 0.351, Train Acc: 0.860, Test Loss: 0.509, Test Acc: 0.816\n",
      "Epoch: 016, Train Loss: 0.333, Train Acc: 0.867, Test Loss: 0.522, Test Acc: 0.816\n",
      "Epoch: 017, Train Loss: 0.327, Train Acc: 0.867, Test Loss: 0.543, Test Acc: 0.816\n",
      "Epoch: 018, Train Loss: 0.318, Train Acc: 0.867, Test Loss: 0.558, Test Acc: 0.816\n",
      "Epoch: 019, Train Loss: 0.321, Train Acc: 0.867, Test Loss: 0.589, Test Acc: 0.816\n",
      "Epoch: 020, Train Loss: 0.320, Train Acc: 0.867, Test Loss: 0.595, Test Acc: 0.816\n",
      "Epoch: 021, Train Loss: 0.305, Train Acc: 0.867, Test Loss: 0.607, Test Acc: 0.816\n",
      "Epoch: 022, Train Loss: 0.314, Train Acc: 0.873, Test Loss: 0.621, Test Acc: 0.816\n",
      "Epoch: 023, Train Loss: 0.300, Train Acc: 0.867, Test Loss: 0.636, Test Acc: 0.816\n",
      "Epoch: 024, Train Loss: 0.300, Train Acc: 0.867, Test Loss: 0.649, Test Acc: 0.816\n",
      "Epoch: 025, Train Loss: 0.297, Train Acc: 0.867, Test Loss: 0.656, Test Acc: 0.816\n",
      "Epoch: 026, Train Loss: 0.290, Train Acc: 0.873, Test Loss: 0.658, Test Acc: 0.763\n",
      "Epoch: 027, Train Loss: 0.296, Train Acc: 0.867, Test Loss: 0.666, Test Acc: 0.816\n",
      "Epoch: 028, Train Loss: 0.296, Train Acc: 0.873, Test Loss: 0.668, Test Acc: 0.763\n",
      "Epoch: 029, Train Loss: 0.294, Train Acc: 0.873, Test Loss: 0.676, Test Acc: 0.816\n",
      "Epoch: 030, Train Loss: 0.291, Train Acc: 0.873, Test Loss: 0.685, Test Acc: 0.763\n",
      "Epoch: 031, Train Loss: 0.292, Train Acc: 0.873, Test Loss: 0.694, Test Acc: 0.763\n",
      "Epoch: 032, Train Loss: 0.285, Train Acc: 0.873, Test Loss: 0.705, Test Acc: 0.763\n",
      "Epoch: 033, Train Loss: 0.291, Train Acc: 0.873, Test Loss: 0.713, Test Acc: 0.763\n",
      "Epoch: 034, Train Loss: 0.282, Train Acc: 0.880, Test Loss: 0.714, Test Acc: 0.737\n",
      "Epoch: 035, Train Loss: 0.289, Train Acc: 0.880, Test Loss: 0.728, Test Acc: 0.816\n",
      "Epoch: 036, Train Loss: 0.282, Train Acc: 0.880, Test Loss: 0.724, Test Acc: 0.737\n",
      "Epoch: 037, Train Loss: 0.290, Train Acc: 0.880, Test Loss: 0.734, Test Acc: 0.737\n",
      "Epoch: 038, Train Loss: 0.314, Train Acc: 0.873, Test Loss: 0.735, Test Acc: 0.789\n",
      "Epoch: 039, Train Loss: 0.298, Train Acc: 0.880, Test Loss: 0.732, Test Acc: 0.816\n",
      "Epoch: 040, Train Loss: 0.293, Train Acc: 0.880, Test Loss: 0.723, Test Acc: 0.684\n",
      "Epoch: 041, Train Loss: 0.291, Train Acc: 0.873, Test Loss: 0.744, Test Acc: 0.789\n",
      "Epoch: 042, Train Loss: 0.287, Train Acc: 0.880, Test Loss: 0.718, Test Acc: 0.684\n",
      "Epoch: 043, Train Loss: 0.277, Train Acc: 0.893, Test Loss: 0.734, Test Acc: 0.789\n",
      "Epoch: 044, Train Loss: 0.284, Train Acc: 0.873, Test Loss: 0.725, Test Acc: 0.763\n",
      "Epoch: 045, Train Loss: 0.279, Train Acc: 0.900, Test Loss: 0.725, Test Acc: 0.711\n",
      "Epoch: 046, Train Loss: 0.312, Train Acc: 0.873, Test Loss: 0.729, Test Acc: 0.763\n",
      "Epoch: 047, Train Loss: 0.313, Train Acc: 0.893, Test Loss: 0.743, Test Acc: 0.789\n",
      "Epoch: 048, Train Loss: 0.287, Train Acc: 0.880, Test Loss: 0.723, Test Acc: 0.684\n",
      "Epoch: 049, Train Loss: 0.282, Train Acc: 0.880, Test Loss: 0.737, Test Acc: 0.816\n",
      "RUN:8,Test Acc:0.8158\n",
      "Epoch: 001, Train Loss: 0.646, Train Acc: 0.640, Test Loss: 0.555, Test Acc: 0.763\n",
      "Epoch: 002, Train Loss: 0.608, Train Acc: 0.640, Test Loss: 0.501, Test Acc: 0.763\n",
      "Epoch: 003, Train Loss: 0.605, Train Acc: 0.640, Test Loss: 0.483, Test Acc: 0.763\n",
      "Epoch: 004, Train Loss: 0.601, Train Acc: 0.640, Test Loss: 0.471, Test Acc: 0.763\n",
      "Epoch: 005, Train Loss: 0.589, Train Acc: 0.640, Test Loss: 0.474, Test Acc: 0.763\n",
      "Epoch: 006, Train Loss: 0.579, Train Acc: 0.640, Test Loss: 0.472, Test Acc: 0.763\n",
      "Epoch: 007, Train Loss: 0.573, Train Acc: 0.640, Test Loss: 0.441, Test Acc: 0.763\n",
      "Epoch: 008, Train Loss: 0.555, Train Acc: 0.640, Test Loss: 0.417, Test Acc: 0.763\n",
      "Epoch: 009, Train Loss: 0.546, Train Acc: 0.640, Test Loss: 0.380, Test Acc: 0.763\n",
      "Epoch: 010, Train Loss: 0.529, Train Acc: 0.747, Test Loss: 0.387, Test Acc: 0.816\n",
      "Epoch: 011, Train Loss: 0.509, Train Acc: 0.720, Test Loss: 0.325, Test Acc: 0.789\n",
      "Epoch: 012, Train Loss: 0.487, Train Acc: 0.800, Test Loss: 0.313, Test Acc: 0.895\n",
      "Epoch: 013, Train Loss: 0.472, Train Acc: 0.813, Test Loss: 0.281, Test Acc: 0.895\n",
      "Epoch: 014, Train Loss: 0.451, Train Acc: 0.813, Test Loss: 0.231, Test Acc: 0.895\n",
      "Epoch: 015, Train Loss: 0.433, Train Acc: 0.827, Test Loss: 0.228, Test Acc: 0.842\n",
      "Epoch: 016, Train Loss: 0.433, Train Acc: 0.833, Test Loss: 0.189, Test Acc: 0.895\n",
      "Epoch: 017, Train Loss: 0.435, Train Acc: 0.833, Test Loss: 0.175, Test Acc: 0.868\n",
      "Epoch: 018, Train Loss: 0.415, Train Acc: 0.827, Test Loss: 0.190, Test Acc: 0.842\n",
      "Epoch: 019, Train Loss: 0.406, Train Acc: 0.833, Test Loss: 0.151, Test Acc: 0.895\n",
      "Epoch: 020, Train Loss: 0.409, Train Acc: 0.833, Test Loss: 0.184, Test Acc: 0.868\n",
      "Epoch: 021, Train Loss: 0.397, Train Acc: 0.833, Test Loss: 0.146, Test Acc: 0.868\n",
      "Epoch: 022, Train Loss: 0.395, Train Acc: 0.840, Test Loss: 0.150, Test Acc: 0.868\n",
      "Epoch: 023, Train Loss: 0.388, Train Acc: 0.847, Test Loss: 0.161, Test Acc: 0.895\n",
      "Epoch: 024, Train Loss: 0.385, Train Acc: 0.847, Test Loss: 0.148, Test Acc: 0.895\n",
      "Epoch: 025, Train Loss: 0.383, Train Acc: 0.847, Test Loss: 0.136, Test Acc: 0.895\n",
      "Epoch: 026, Train Loss: 0.383, Train Acc: 0.847, Test Loss: 0.128, Test Acc: 0.895\n",
      "Epoch: 027, Train Loss: 0.379, Train Acc: 0.847, Test Loss: 0.162, Test Acc: 0.921\n",
      "Epoch: 028, Train Loss: 0.376, Train Acc: 0.847, Test Loss: 0.126, Test Acc: 0.895\n",
      "Epoch: 029, Train Loss: 0.381, Train Acc: 0.847, Test Loss: 0.134, Test Acc: 0.895\n",
      "Epoch: 030, Train Loss: 0.378, Train Acc: 0.847, Test Loss: 0.136, Test Acc: 0.895\n",
      "Epoch: 031, Train Loss: 0.373, Train Acc: 0.847, Test Loss: 0.127, Test Acc: 0.895\n",
      "Epoch: 032, Train Loss: 0.381, Train Acc: 0.847, Test Loss: 0.127, Test Acc: 0.895\n",
      "Epoch: 033, Train Loss: 0.400, Train Acc: 0.853, Test Loss: 0.139, Test Acc: 0.921\n",
      "Epoch: 034, Train Loss: 0.373, Train Acc: 0.847, Test Loss: 0.109, Test Acc: 0.895\n",
      "Epoch: 035, Train Loss: 0.385, Train Acc: 0.847, Test Loss: 0.159, Test Acc: 0.921\n",
      "Epoch: 036, Train Loss: 0.384, Train Acc: 0.847, Test Loss: 0.117, Test Acc: 0.895\n",
      "Epoch: 037, Train Loss: 0.375, Train Acc: 0.847, Test Loss: 0.154, Test Acc: 0.921\n",
      "Epoch: 038, Train Loss: 0.374, Train Acc: 0.847, Test Loss: 0.126, Test Acc: 0.895\n",
      "Epoch: 039, Train Loss: 0.368, Train Acc: 0.853, Test Loss: 0.149, Test Acc: 0.921\n",
      "Epoch: 040, Train Loss: 0.373, Train Acc: 0.847, Test Loss: 0.127, Test Acc: 0.895\n",
      "Epoch: 041, Train Loss: 0.383, Train Acc: 0.847, Test Loss: 0.120, Test Acc: 0.895\n",
      "Epoch: 042, Train Loss: 0.377, Train Acc: 0.847, Test Loss: 0.160, Test Acc: 0.921\n",
      "Epoch: 043, Train Loss: 0.365, Train Acc: 0.847, Test Loss: 0.115, Test Acc: 0.895\n",
      "Epoch: 044, Train Loss: 0.384, Train Acc: 0.853, Test Loss: 0.123, Test Acc: 0.921\n",
      "Epoch: 045, Train Loss: 0.374, Train Acc: 0.847, Test Loss: 0.113, Test Acc: 0.895\n",
      "Epoch: 046, Train Loss: 0.365, Train Acc: 0.827, Test Loss: 0.167, Test Acc: 0.842\n",
      "Epoch: 047, Train Loss: 0.369, Train Acc: 0.847, Test Loss: 0.117, Test Acc: 0.921\n",
      "Epoch: 048, Train Loss: 0.375, Train Acc: 0.853, Test Loss: 0.122, Test Acc: 0.921\n",
      "Epoch: 049, Train Loss: 0.368, Train Acc: 0.853, Test Loss: 0.127, Test Acc: 0.921\n",
      "RUN:9,Test Acc:0.9211\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    k = 0\n",
    "    nG = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        #print(data.x.size(), data.edge_index.size(),data.batch.size(), k)\n",
    "        data\n",
    "        nG += data.num_graphs\n",
    "        optimizer.zero_grad()\n",
    "        out= model(data.x, data.edge_index, data.batch) # data.batch  torch.Size([783])\n",
    "        loss = F.nll_loss(out, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        loss_all += data.y.size(0) * loss.item()\n",
    "        optimizer.step()\n",
    "        k = k + 1\n",
    "    #print(\"Training graphs per epoch\", nG)\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(pred, data.y.view(-1))\n",
    "        correct += pred.max(dim=1)[1].eq(data.y.view(-1)).sum().item()\n",
    "\n",
    "    return loss, correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = start_patience = 50\n",
    "resultados = []\n",
    "for i in range(10):\n",
    "    dataset = dataset.shuffle()\n",
    "    train_dataset = dataset[:150]\n",
    "    test_dataset = dataset[150:]\n",
    "    train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = Net(dataset.num_features, dataset.num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    for epoch in range(1, 50):\n",
    "        train_loss = train(epoch)\n",
    "        _, train_acc = test(train_loader)\n",
    "        test_loss, test_acc = test(test_loader)\n",
    "        print('Epoch: {:03d}, '\n",
    "              'Train Loss: {:.3f}, Train Acc: {:.3f}, '\n",
    "              'Test Loss: {:.3f}, Test Acc: {:.3f}'.format(epoch, train_loss,\n",
    "                                                           train_acc,\n",
    "                                                            test_loss,\n",
    "                                                           test_acc))\n",
    "    print(f'RUN:{i},Test Acc:{test_acc:.4f}')\n",
    "    resultados.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93558f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8526)\n",
      "tensor(0.0715)\n"
     ]
    }
   ],
   "source": [
    "res= torch.Tensor(resultados)\n",
    "print(torch.mean(res))\n",
    "print(torch.std(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da0a9d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 62], x=[28, 7], edge_attr=[62, 4], y=[1], batch=[28], ptr=[2])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "Accuracy:  100.0\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset[3:], batch_size=1, shuffle=False)\n",
    "sample = next(iter(test_loader))\n",
    "#sample.batch =torch.tensor(1)\n",
    "print(sample)\n",
    "print(sample.y)\n",
    "out = model(sample.x,sample.edge_index, sample.batch)  # Perform a single forward pass.\n",
    "pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "print(pred)\n",
    "correct = 0\n",
    "correct += int((pred[0] == sample[0].y).sum())  # Check against ground-truth labels.\n",
    "print(\"Accuracy: \",(correct/1)*100)#Batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80db837b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 32])\n",
      "torch.Size([1, 28, 32])\n",
      "[0, 2, 3, 6, 16, 17]\n",
      "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0]\n"
     ]
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/network-centrality-measures-in-a-graph-using-networkx-python/\n",
    "#Nodos criticos\n",
    "import networkx as nx\n",
    "Conv_out= model.salidaConv\n",
    "print(model.salidaConv.shape)\n",
    "critical_nodes = Conv_out.argmax(1).unique().tolist()\n",
    "#Pool_out = model.salidaPooling\n",
    "print(Conv_out.shape)\n",
    "#print(Pool_out.shape)\n",
    "print(critical_nodes)\n",
    "#print(Conv_out)\n",
    "grafo_init = sample\n",
    "A = to_networkx(grafo_init, to_undirected=True)\n",
    "deg_centrality = list(nx.closeness_centrality(A))\n",
    "print(torch.Tensor(deg_centrality).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff40bae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 62], x=[28, 7], edge_attr=[62, 4], y=[1], batch=[28], ptr=[2])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#loader =  DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "grafo_init = sample\n",
    "print(grafo_init)\n",
    "A = to_networkx(grafo_init, to_undirected=True)\n",
    "l=[]\n",
    "for a in A.nodes:\n",
    "    l.append(a)\n",
    "ed= []\n",
    "for e in A.edges:\n",
    "    ed.append(e)\n",
    "import igraph as ig\n",
    "import chart_studio.plotly\n",
    "Edges= ed\n",
    "G=ig.Graph(Edges, directed=False)\n",
    "labels= l\n",
    "#groups = A.node_attr_dict_factory\n",
    "N = len(A.nodes)\n",
    "#print(N)\n",
    "layt=G.layout('kk', dim=3)\n",
    "#print(layt)\n",
    "Xn=[layt[k][0] for k in range(N)]# x-coordinates of nodes\n",
    "Yn=[layt[k][1] for k in range(N)]# y-coordinates\n",
    "Zn=[layt[k][2] for k in range(N)]# z-coordinates\n",
    "Xe=[]\n",
    "Ye=[]\n",
    "Ze=[]\n",
    "#print(Edges)\n",
    "for e in Edges:\n",
    "    Xe+=[layt[e[0]][0],layt[e[1]][0], None]# x-coordinates of edge ends\n",
    "    Ye+=[layt[e[0]][1],layt[e[1]][1], None]\n",
    "    Ze+=[layt[e[0]][2],layt[e[1]][2], None]\n",
    "nx.draw(A)\n",
    "\n",
    "\n",
    "node_adjacencies = []\n",
    "node_text = []\n",
    "for node, adjacencies in enumerate(A.nodes()):\n",
    "    #print(adjacencies,critical_nodes)\n",
    "    if adjacencies in critical_nodes :\n",
    "        node_adjacencies.append('rgb(256,0,0)')\n",
    "    else:\n",
    "        node_adjacencies.append('rgb(0,0,0)')\n",
    "    #node_text.append('# of connections: '+str(len(adjacencies[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81331e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chart_studio import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1=go.Scatter3d(x=Xe,\n",
    "               y=Ye,\n",
    "               z=Ze,\n",
    "               mode='lines',\n",
    "               line=dict(color='rgb(125,125,125)', width=1),\n",
    "               hoverinfo='none'\n",
    "               )\n",
    "\n",
    "trace2=go.Scatter3d(x=Xn,\n",
    "               y=Yn,\n",
    "               z=Zn,\n",
    "               mode='markers',\n",
    "               name='actors',\n",
    "               marker=dict(symbol='circle',\n",
    "                             size=6,\n",
    "                             #color='#ff7f0e',\n",
    "                             colorscale='Viridis',\n",
    "                             line=dict(color='rgb(50,50,50)', width=0.5)\n",
    "                             ),\n",
    "               text=labels,\n",
    "               hoverinfo='text'\n",
    "               )\n",
    "trace2.marker.color = node_adjacencies\n",
    "#print(trace2)\n",
    "axis=dict(showbackground=False,\n",
    "          showline=False,\n",
    "          zeroline=False,\n",
    "          showgrid=False,\n",
    "          showticklabels=False,\n",
    "          title=''\n",
    "          )\n",
    "\n",
    "layout = go.Layout(\n",
    "         title=\"3D graph visualization of Mutag dataset  by : Ahmed\",\n",
    "         width=1000,\n",
    "         height=1000,\n",
    "         showlegend=False,\n",
    "         scene=dict(\n",
    "             xaxis=dict(axis),\n",
    "             yaxis=dict(axis),\n",
    "             zaxis=dict(axis),\n",
    "        ),\n",
    "     margin=dict(\n",
    "        t=100\n",
    "    ),\n",
    "    hovermode='closest',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7781d695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "hoverinfo": "none",
         "line": {
          "color": "rgb(125,125,125)",
          "width": 1
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          -0.7936653802184988,
          -0.16607972609720684,
          null,
          -0.7936653802184988,
          -1.0214585290414118,
          null,
          -0.16607972609720684,
          0.32958427424582526,
          null,
          0.32958427424582526,
          0.9973512636792449,
          null,
          0.32958427424582526,
          0.1454703489823745,
          null,
          0.9973512636792449,
          1.474924740100846,
          null,
          0.9973512636792449,
          1.268830377303513,
          null,
          1.474924740100846,
          1.3656151841855533,
          null,
          1.3656151841855533,
          0.6769250729334987,
          null,
          1.3656151841855533,
          1.9483033324033745,
          null,
          0.6769250729334987,
          0.1454703489823745,
          null,
          0.6769250729334987,
          0.40317417488697027,
          null,
          0.1454703489823745,
          -0.5525535927811269,
          null,
          -0.5525535927811269,
          -1.0214585290414118,
          null,
          -0.5525535927811269,
          -0.7991708358771488,
          null,
          -1.0214585290414118,
          -1.6795690088483504,
          null,
          -1.6795690088483504,
          -1.8818236959666035,
          null,
          -1.6795690088483504,
          -2.147655461088201,
          null,
          -1.8818236959666035,
          -1.4973446568684163,
          null,
          -1.4973446568684163,
          -0.7991708358771488,
          null,
          -1.4973446568684163,
          -1.8834357753417785,
          null,
          -0.7991708358771488,
          -0.25778082878514835,
          null,
          -0.25778082878514835,
          0.40317417488697027,
          null,
          -1.8834357753417785,
          -2.2289873702204615,
          null,
          -1.8834357753417785,
          -2.1215266685752545,
          null,
          -2.147655461088201,
          -2.6891502735057733,
          null,
          -2.147655461088201,
          -2.3210915332507356,
          null,
          1.9483033324033745,
          2.3283067525625514,
          null,
          1.9483033324033745,
          2.422331907499936,
          null,
          1.268830377303513,
          1.5744907634482948,
          null,
          1.268830377303513,
          1.4079446088881342,
          null
         ],
         "y": [
          -1.0053310898705736,
          -1.0127008587619903,
          null,
          -1.0053310898705736,
          -0.5893873004388738,
          null,
          -1.0127008587619903,
          -0.5154572284762107,
          null,
          -0.5154572284762107,
          -0.5152974151667046,
          null,
          -0.5154572284762107,
          -0.10161405952960971,
          null,
          -0.5152974151667046,
          -0.2370766714669428,
          null,
          -0.5152974151667046,
          -0.6951494800595663,
          null,
          -0.2370766714669428,
          0.10137252456504,
          null,
          0.10137252456504,
          0.23964517589672668,
          null,
          0.10137252456504,
          0.1944368341803802,
          null,
          0.23964517589672668,
          -0.10161405952960971,
          null,
          0.23964517589672668,
          0.8155404822610596,
          null,
          -0.10161405952960971,
          -0.030667247006197405,
          null,
          -0.030667247006197405,
          -0.5893873004388738,
          null,
          -0.030667247006197405,
          0.6008152960523366,
          null,
          -0.5893873004388738,
          -0.5576262416148129,
          null,
          -0.5576262416148129,
          0.10413891053283346,
          null,
          -0.5576262416148129,
          -1.0495229579561054,
          null,
          0.10413891053283346,
          0.706429662944918,
          null,
          0.706429662944918,
          0.6008152960523366,
          null,
          0.706429662944918,
          1.2850489194387262,
          null,
          0.6008152960523366,
          0.9390424106923294,
          null,
          0.9390424106923294,
          0.8155404822610596,
          null,
          1.2850489194387262,
          1.7297428055810258,
          null,
          1.2850489194387262,
          1.609710374873259,
          null,
          -1.0495229579561054,
          -1.2950389158840878,
          null,
          -1.0495229579561054,
          -1.441584176136759,
          null,
          0.1944368341803802,
          -0.13185668106794138,
          null,
          0.1944368341803802,
          0.6747550158386183,
          null,
          -0.6951494800595663,
          -1.2549937459672147,
          null,
          -0.6951494800595663,
          -0.4215256752398171,
          null
         ],
         "z": [
          -0.8592797766408564,
          -1.1221891463720743,
          null,
          -0.8592797766408564,
          -0.33401938695142774,
          null,
          -1.1221891463720743,
          -1.0339027047750349,
          null,
          -1.0339027047750349,
          -1.2885210199431156,
          null,
          -1.0339027047750349,
          -0.4571548242683999,
          null,
          -1.2885210199431156,
          -0.8355049912248632,
          null,
          -1.2885210199431156,
          -1.9077225759511514,
          null,
          -0.8355049912248632,
          -0.21569088598799713,
          null,
          -0.21569088598799713,
          -0.08432269705775103,
          null,
          -0.21569088598799713,
          0.16018304779486722,
          null,
          -0.08432269705775103,
          -0.4571548242683999,
          null,
          -0.08432269705775103,
          0.22258798253292833,
          null,
          -0.4571548242683999,
          -0.25808809406661054,
          null,
          -0.25808809406661054,
          -0.33401938695142774,
          null,
          -0.25808809406661054,
          0.02172237594901751,
          null,
          -0.33401938695142774,
          -0.05732096830244517,
          null,
          -0.05732096830244517,
          0.12111530870375466,
          null,
          -0.05732096830244517,
          0.11116872107813901,
          null,
          0.12111530870375466,
          0.13194571020386248,
          null,
          0.13194571020386248,
          0.02172237594901751,
          null,
          0.13194571020386248,
          0.20682521565137896,
          null,
          0.02172237594901751,
          0.32701850510744745,
          null,
          0.32701850510744745,
          0.22258798253292833,
          null,
          0.20682521565137896,
          -0.16970862999145422,
          null,
          0.20682521565137896,
          0.7485836510652598,
          null,
          0.11116872107813901,
          -0.20807269078731944,
          null,
          0.11116872107813901,
          0.6358737213425906,
          null,
          0.16018304779486722,
          0.616316445037395,
          null,
          0.16018304779486722,
          0.1589301535968042,
          null,
          -1.9077225759511514,
          -2.1285006798769,
          null,
          -1.9077225759511514,
          -2.511621324782713,
          null
         ]
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": [
           "rgb(256,0,0)",
           "rgb(0,0,0)",
           "rgb(256,0,0)",
           "rgb(256,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(256,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(256,0,0)",
           "rgb(256,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)"
          ],
          "colorscale": [
           [
            0,
            "#440154"
           ],
           [
            0.1111111111111111,
            "#482878"
           ],
           [
            0.2222222222222222,
            "#3e4989"
           ],
           [
            0.3333333333333333,
            "#31688e"
           ],
           [
            0.4444444444444444,
            "#26828e"
           ],
           [
            0.5555555555555556,
            "#1f9e89"
           ],
           [
            0.6666666666666666,
            "#35b779"
           ],
           [
            0.7777777777777778,
            "#6ece58"
           ],
           [
            0.8888888888888888,
            "#b5de2b"
           ],
           [
            1,
            "#fde725"
           ]
          ],
          "line": {
           "color": "rgb(50,50,50)",
           "width": 0.5
          },
          "size": 6,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "actors",
         "text": [
          "0",
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27"
         ],
         "type": "scatter3d",
         "x": [
          -0.7936653802184988,
          -0.16607972609720684,
          0.32958427424582526,
          0.9973512636792449,
          1.474924740100846,
          1.3656151841855533,
          0.6769250729334987,
          0.1454703489823745,
          -0.5525535927811269,
          -1.0214585290414118,
          -1.6795690088483504,
          -1.8818236959666035,
          -1.4973446568684163,
          -0.7991708358771488,
          -0.25778082878514835,
          0.40317417488697027,
          -1.8834357753417785,
          -2.2289873702204615,
          -2.1215266685752545,
          -2.147655461088201,
          -2.6891502735057733,
          -2.3210915332507356,
          1.9483033324033745,
          2.3283067525625514,
          2.422331907499936,
          1.268830377303513,
          1.5744907634482948,
          1.4079446088881342
         ],
         "y": [
          -1.0053310898705736,
          -1.0127008587619903,
          -0.5154572284762107,
          -0.5152974151667046,
          -0.2370766714669428,
          0.10137252456504,
          0.23964517589672668,
          -0.10161405952960971,
          -0.030667247006197405,
          -0.5893873004388738,
          -0.5576262416148129,
          0.10413891053283346,
          0.706429662944918,
          0.6008152960523366,
          0.9390424106923294,
          0.8155404822610596,
          1.2850489194387262,
          1.7297428055810258,
          1.609710374873259,
          -1.0495229579561054,
          -1.2950389158840878,
          -1.441584176136759,
          0.1944368341803802,
          -0.13185668106794138,
          0.6747550158386183,
          -0.6951494800595663,
          -1.2549937459672147,
          -0.4215256752398171
         ],
         "z": [
          -0.8592797766408564,
          -1.1221891463720743,
          -1.0339027047750349,
          -1.2885210199431156,
          -0.8355049912248632,
          -0.21569088598799713,
          -0.08432269705775103,
          -0.4571548242683999,
          -0.25808809406661054,
          -0.33401938695142774,
          -0.05732096830244517,
          0.12111530870375466,
          0.13194571020386248,
          0.02172237594901751,
          0.32701850510744745,
          0.22258798253292833,
          0.20682521565137896,
          -0.16970862999145422,
          0.7485836510652598,
          0.11116872107813901,
          -0.20807269078731944,
          0.6358737213425906,
          0.16018304779486722,
          0.616316445037395,
          0.1589301535968042,
          -1.9077225759511514,
          -2.1285006798769,
          -2.511621324782713
         ]
        }
       ],
       "layout": {
        "height": 1000,
        "hovermode": "closest",
        "margin": {
         "t": 100
        },
        "scene": {
         "xaxis": {
          "showbackground": false,
          "showgrid": false,
          "showline": false,
          "showticklabels": false,
          "title": {
           "text": ""
          },
          "zeroline": false
         },
         "yaxis": {
          "showbackground": false,
          "showgrid": false,
          "showline": false,
          "showticklabels": false,
          "title": {
           "text": ""
          },
          "zeroline": false
         },
         "zaxis": {
          "showbackground": false,
          "showgrid": false,
          "showline": false,
          "showticklabels": false,
          "title": {
           "text": ""
          },
          "zeroline": false
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D graph visualization of Mutag dataset  by : Ahmed"
        },
        "width": 1000
       }
      },
      "text/html": [
       "<div>                            <div id=\"3fa8eda2-c9fe-4abf-b39f-66c20458bee9\" class=\"plotly-graph-div\" style=\"height:1000px; width:1000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3fa8eda2-c9fe-4abf-b39f-66c20458bee9\")) {                    Plotly.newPlot(                        \"3fa8eda2-c9fe-4abf-b39f-66c20458bee9\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"rgb(125,125,125)\",\"width\":1},\"mode\":\"lines\",\"x\":[-0.7936653802184988,-0.16607972609720684,null,-0.7936653802184988,-1.0214585290414118,null,-0.16607972609720684,0.32958427424582526,null,0.32958427424582526,0.9973512636792449,null,0.32958427424582526,0.1454703489823745,null,0.9973512636792449,1.474924740100846,null,0.9973512636792449,1.268830377303513,null,1.474924740100846,1.3656151841855533,null,1.3656151841855533,0.6769250729334987,null,1.3656151841855533,1.9483033324033745,null,0.6769250729334987,0.1454703489823745,null,0.6769250729334987,0.40317417488697027,null,0.1454703489823745,-0.5525535927811269,null,-0.5525535927811269,-1.0214585290414118,null,-0.5525535927811269,-0.7991708358771488,null,-1.0214585290414118,-1.6795690088483504,null,-1.6795690088483504,-1.8818236959666035,null,-1.6795690088483504,-2.147655461088201,null,-1.8818236959666035,-1.4973446568684163,null,-1.4973446568684163,-0.7991708358771488,null,-1.4973446568684163,-1.8834357753417785,null,-0.7991708358771488,-0.25778082878514835,null,-0.25778082878514835,0.40317417488697027,null,-1.8834357753417785,-2.2289873702204615,null,-1.8834357753417785,-2.1215266685752545,null,-2.147655461088201,-2.6891502735057733,null,-2.147655461088201,-2.3210915332507356,null,1.9483033324033745,2.3283067525625514,null,1.9483033324033745,2.422331907499936,null,1.268830377303513,1.5744907634482948,null,1.268830377303513,1.4079446088881342,null],\"y\":[-1.0053310898705736,-1.0127008587619903,null,-1.0053310898705736,-0.5893873004388738,null,-1.0127008587619903,-0.5154572284762107,null,-0.5154572284762107,-0.5152974151667046,null,-0.5154572284762107,-0.10161405952960971,null,-0.5152974151667046,-0.2370766714669428,null,-0.5152974151667046,-0.6951494800595663,null,-0.2370766714669428,0.10137252456504,null,0.10137252456504,0.23964517589672668,null,0.10137252456504,0.1944368341803802,null,0.23964517589672668,-0.10161405952960971,null,0.23964517589672668,0.8155404822610596,null,-0.10161405952960971,-0.030667247006197405,null,-0.030667247006197405,-0.5893873004388738,null,-0.030667247006197405,0.6008152960523366,null,-0.5893873004388738,-0.5576262416148129,null,-0.5576262416148129,0.10413891053283346,null,-0.5576262416148129,-1.0495229579561054,null,0.10413891053283346,0.706429662944918,null,0.706429662944918,0.6008152960523366,null,0.706429662944918,1.2850489194387262,null,0.6008152960523366,0.9390424106923294,null,0.9390424106923294,0.8155404822610596,null,1.2850489194387262,1.7297428055810258,null,1.2850489194387262,1.609710374873259,null,-1.0495229579561054,-1.2950389158840878,null,-1.0495229579561054,-1.441584176136759,null,0.1944368341803802,-0.13185668106794138,null,0.1944368341803802,0.6747550158386183,null,-0.6951494800595663,-1.2549937459672147,null,-0.6951494800595663,-0.4215256752398171,null],\"z\":[-0.8592797766408564,-1.1221891463720743,null,-0.8592797766408564,-0.33401938695142774,null,-1.1221891463720743,-1.0339027047750349,null,-1.0339027047750349,-1.2885210199431156,null,-1.0339027047750349,-0.4571548242683999,null,-1.2885210199431156,-0.8355049912248632,null,-1.2885210199431156,-1.9077225759511514,null,-0.8355049912248632,-0.21569088598799713,null,-0.21569088598799713,-0.08432269705775103,null,-0.21569088598799713,0.16018304779486722,null,-0.08432269705775103,-0.4571548242683999,null,-0.08432269705775103,0.22258798253292833,null,-0.4571548242683999,-0.25808809406661054,null,-0.25808809406661054,-0.33401938695142774,null,-0.25808809406661054,0.02172237594901751,null,-0.33401938695142774,-0.05732096830244517,null,-0.05732096830244517,0.12111530870375466,null,-0.05732096830244517,0.11116872107813901,null,0.12111530870375466,0.13194571020386248,null,0.13194571020386248,0.02172237594901751,null,0.13194571020386248,0.20682521565137896,null,0.02172237594901751,0.32701850510744745,null,0.32701850510744745,0.22258798253292833,null,0.20682521565137896,-0.16970862999145422,null,0.20682521565137896,0.7485836510652598,null,0.11116872107813901,-0.20807269078731944,null,0.11116872107813901,0.6358737213425906,null,0.16018304779486722,0.616316445037395,null,0.16018304779486722,0.1589301535968042,null,-1.9077225759511514,-2.1285006798769,null,-1.9077225759511514,-2.511621324782713,null],\"type\":\"scatter3d\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":[\"rgb(256,0,0)\",\"rgb(0,0,0)\",\"rgb(256,0,0)\",\"rgb(256,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(256,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(256,0,0)\",\"rgb(256,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\"],\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"line\":{\"color\":\"rgb(50,50,50)\",\"width\":0.5},\"size\":6,\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"actors\",\"text\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\"],\"x\":[-0.7936653802184988,-0.16607972609720684,0.32958427424582526,0.9973512636792449,1.474924740100846,1.3656151841855533,0.6769250729334987,0.1454703489823745,-0.5525535927811269,-1.0214585290414118,-1.6795690088483504,-1.8818236959666035,-1.4973446568684163,-0.7991708358771488,-0.25778082878514835,0.40317417488697027,-1.8834357753417785,-2.2289873702204615,-2.1215266685752545,-2.147655461088201,-2.6891502735057733,-2.3210915332507356,1.9483033324033745,2.3283067525625514,2.422331907499936,1.268830377303513,1.5744907634482948,1.4079446088881342],\"y\":[-1.0053310898705736,-1.0127008587619903,-0.5154572284762107,-0.5152974151667046,-0.2370766714669428,0.10137252456504,0.23964517589672668,-0.10161405952960971,-0.030667247006197405,-0.5893873004388738,-0.5576262416148129,0.10413891053283346,0.706429662944918,0.6008152960523366,0.9390424106923294,0.8155404822610596,1.2850489194387262,1.7297428055810258,1.609710374873259,-1.0495229579561054,-1.2950389158840878,-1.441584176136759,0.1944368341803802,-0.13185668106794138,0.6747550158386183,-0.6951494800595663,-1.2549937459672147,-0.4215256752398171],\"z\":[-0.8592797766408564,-1.1221891463720743,-1.0339027047750349,-1.2885210199431156,-0.8355049912248632,-0.21569088598799713,-0.08432269705775103,-0.4571548242683999,-0.25808809406661054,-0.33401938695142774,-0.05732096830244517,0.12111530870375466,0.13194571020386248,0.02172237594901751,0.32701850510744745,0.22258798253292833,0.20682521565137896,-0.16970862999145422,0.7485836510652598,0.11116872107813901,-0.20807269078731944,0.6358737213425906,0.16018304779486722,0.616316445037395,0.1589301535968042,-1.9077225759511514,-2.1285006798769,-2.511621324782713],\"type\":\"scatter3d\"}],                        {\"height\":1000,\"hovermode\":\"closest\",\"margin\":{\"t\":100},\"scene\":{\"xaxis\":{\"showbackground\":false,\"showgrid\":false,\"showline\":false,\"showticklabels\":false,\"title\":{\"text\":\"\"},\"zeroline\":false},\"yaxis\":{\"showbackground\":false,\"showgrid\":false,\"showline\":false,\"showticklabels\":false,\"title\":{\"text\":\"\"},\"zeroline\":false},\"zaxis\":{\"showbackground\":false,\"showgrid\":false,\"showline\":false,\"showticklabels\":false,\"title\":{\"text\":\"\"},\"zeroline\":false}},\"showlegend\":false,\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"3D graph visualization of Mutag dataset  by : Ahmed\"},\"width\":1000},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3fa8eda2-c9fe-4abf-b39f-66c20458bee9');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import plotly.graph_objs as go\n",
    "from  plotly.offline import plot\n",
    "import chart_studio.plotly as py\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot\n",
    "init_notebook_mode(connected='true')\n",
    "data=[trace1, trace2]\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='Les-Miserables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c537632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: PROTEINS(1113):\n",
      "====================\n",
      "Number of graphs: 1113\n",
      "Number of features: 3\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_index=[2, 162], x=[42, 3], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 42\n",
      "Number of edges: 162\n",
      "Average node degree: 3.86\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(root='data/TUDataset', name='PROTEINS')\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3449bf4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 890\n",
      "Number of test graphs: 223\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:890]\n",
    "test_dataset = dataset[890:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4d0635a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 8734], x=[2375, 3], y=[64], batch=[2375], ptr=[65])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 7820], x=[1997, 3], y=[64], batch=[1997], ptr=[65])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 13182], x=[3552, 3], y=[64], batch=[3552], ptr=[65])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 9062], x=[2394, 3], y=[64], batch=[2394], ptr=[65])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 7222], x=[1856, 3], y=[64], batch=[1856], ptr=[65])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 9230], x=[2503, 3], y=[64], batch=[2503], ptr=[65])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 12968], x=[3516, 3], y=[64], batch=[3516], ptr=[65])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 10094], x=[2764, 3], y=[64], batch=[2764], ptr=[65])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 9934], x=[2732, 3], y=[64], batch=[2732], ptr=[65])\n",
      "\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 8704], x=[2440, 3], y=[64], batch=[2440], ptr=[65])\n",
      "\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 9010], x=[2390, 3], y=[64], batch=[2390], ptr=[65])\n",
      "\n",
      "Step 12:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 7822], x=[2069, 3], y=[64], batch=[2069], ptr=[65])\n",
      "\n",
      "Step 13:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 9336], x=[2495, 3], y=[64], batch=[2495], ptr=[65])\n",
      "\n",
      "Step 14:\n",
      "=======\n",
      "Number of graphs in the current batch: 58\n",
      "DataBatch(edge_index=[2, 8564], x=[2235, 3], y=[58], batch=[2235], ptr=[59])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "545de6e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.639, Train Acc: 0.596, Test Loss: 0.552, Test Acc: 0.596\n",
      "Epoch: 002, Train Loss: 0.605, Train Acc: 0.670, Test Loss: 0.545, Test Acc: 0.691\n",
      "Epoch: 003, Train Loss: 0.585, Train Acc: 0.730, Test Loss: 0.525, Test Acc: 0.762\n",
      "Epoch: 004, Train Loss: 0.570, Train Acc: 0.736, Test Loss: 0.510, Test Acc: 0.776\n",
      "Epoch: 005, Train Loss: 0.558, Train Acc: 0.734, Test Loss: 0.497, Test Acc: 0.780\n",
      "Epoch: 006, Train Loss: 0.548, Train Acc: 0.735, Test Loss: 0.491, Test Acc: 0.780\n",
      "Epoch: 007, Train Loss: 0.544, Train Acc: 0.743, Test Loss: 0.474, Test Acc: 0.785\n",
      "Epoch: 008, Train Loss: 0.536, Train Acc: 0.745, Test Loss: 0.482, Test Acc: 0.776\n",
      "Epoch: 009, Train Loss: 0.541, Train Acc: 0.735, Test Loss: 0.485, Test Acc: 0.771\n",
      "Epoch: 010, Train Loss: 0.533, Train Acc: 0.747, Test Loss: 0.471, Test Acc: 0.776\n",
      "Epoch: 011, Train Loss: 0.523, Train Acc: 0.748, Test Loss: 0.463, Test Acc: 0.789\n",
      "Epoch: 012, Train Loss: 0.523, Train Acc: 0.744, Test Loss: 0.463, Test Acc: 0.776\n",
      "Epoch: 013, Train Loss: 0.518, Train Acc: 0.751, Test Loss: 0.453, Test Acc: 0.771\n",
      "Epoch: 014, Train Loss: 0.518, Train Acc: 0.749, Test Loss: 0.458, Test Acc: 0.780\n",
      "Epoch: 015, Train Loss: 0.517, Train Acc: 0.751, Test Loss: 0.458, Test Acc: 0.785\n",
      "Epoch: 016, Train Loss: 0.514, Train Acc: 0.748, Test Loss: 0.452, Test Acc: 0.767\n",
      "Epoch: 017, Train Loss: 0.511, Train Acc: 0.757, Test Loss: 0.458, Test Acc: 0.780\n",
      "Epoch: 018, Train Loss: 0.511, Train Acc: 0.757, Test Loss: 0.459, Test Acc: 0.780\n",
      "Epoch: 019, Train Loss: 0.509, Train Acc: 0.754, Test Loss: 0.448, Test Acc: 0.776\n",
      "Epoch: 020, Train Loss: 0.508, Train Acc: 0.753, Test Loss: 0.462, Test Acc: 0.789\n",
      "Epoch: 021, Train Loss: 0.505, Train Acc: 0.754, Test Loss: 0.450, Test Acc: 0.776\n",
      "Epoch: 022, Train Loss: 0.507, Train Acc: 0.755, Test Loss: 0.457, Test Acc: 0.767\n",
      "Epoch: 023, Train Loss: 0.509, Train Acc: 0.754, Test Loss: 0.452, Test Acc: 0.771\n",
      "Epoch: 024, Train Loss: 0.507, Train Acc: 0.753, Test Loss: 0.463, Test Acc: 0.794\n",
      "Epoch: 025, Train Loss: 0.506, Train Acc: 0.754, Test Loss: 0.452, Test Acc: 0.762\n",
      "Epoch: 026, Train Loss: 0.505, Train Acc: 0.756, Test Loss: 0.451, Test Acc: 0.767\n",
      "Epoch: 027, Train Loss: 0.501, Train Acc: 0.755, Test Loss: 0.461, Test Acc: 0.794\n",
      "Epoch: 028, Train Loss: 0.503, Train Acc: 0.753, Test Loss: 0.455, Test Acc: 0.767\n",
      "Epoch: 029, Train Loss: 0.509, Train Acc: 0.762, Test Loss: 0.453, Test Acc: 0.758\n",
      "Epoch: 030, Train Loss: 0.503, Train Acc: 0.760, Test Loss: 0.449, Test Acc: 0.749\n",
      "Epoch: 031, Train Loss: 0.501, Train Acc: 0.761, Test Loss: 0.454, Test Acc: 0.776\n",
      "Epoch: 032, Train Loss: 0.501, Train Acc: 0.756, Test Loss: 0.456, Test Acc: 0.785\n",
      "Epoch: 033, Train Loss: 0.501, Train Acc: 0.758, Test Loss: 0.450, Test Acc: 0.771\n",
      "Epoch: 034, Train Loss: 0.504, Train Acc: 0.756, Test Loss: 0.459, Test Acc: 0.789\n",
      "Epoch: 035, Train Loss: 0.507, Train Acc: 0.760, Test Loss: 0.465, Test Acc: 0.794\n",
      "Epoch: 036, Train Loss: 0.516, Train Acc: 0.755, Test Loss: 0.450, Test Acc: 0.753\n",
      "Epoch: 037, Train Loss: 0.523, Train Acc: 0.754, Test Loss: 0.461, Test Acc: 0.776\n",
      "Epoch: 038, Train Loss: 0.505, Train Acc: 0.758, Test Loss: 0.458, Test Acc: 0.767\n",
      "Epoch: 039, Train Loss: 0.502, Train Acc: 0.758, Test Loss: 0.455, Test Acc: 0.771\n",
      "Epoch: 040, Train Loss: 0.501, Train Acc: 0.762, Test Loss: 0.454, Test Acc: 0.785\n",
      "Epoch: 041, Train Loss: 0.498, Train Acc: 0.760, Test Loss: 0.458, Test Acc: 0.789\n",
      "Epoch: 042, Train Loss: 0.499, Train Acc: 0.766, Test Loss: 0.455, Test Acc: 0.785\n",
      "Epoch: 043, Train Loss: 0.498, Train Acc: 0.764, Test Loss: 0.453, Test Acc: 0.767\n",
      "Epoch: 044, Train Loss: 0.498, Train Acc: 0.762, Test Loss: 0.454, Test Acc: 0.753\n",
      "Epoch: 045, Train Loss: 0.499, Train Acc: 0.762, Test Loss: 0.453, Test Acc: 0.780\n",
      "Epoch: 046, Train Loss: 0.498, Train Acc: 0.764, Test Loss: 0.449, Test Acc: 0.767\n",
      "Epoch: 047, Train Loss: 0.508, Train Acc: 0.755, Test Loss: 0.463, Test Acc: 0.780\n",
      "Epoch: 048, Train Loss: 0.500, Train Acc: 0.754, Test Loss: 0.451, Test Acc: 0.762\n",
      "Epoch: 049, Train Loss: 0.501, Train Acc: 0.758, Test Loss: 0.461, Test Acc: 0.776\n",
      "RUN:0,Test Acc:0.7758\n",
      "Epoch: 001, Train Loss: 0.602, Train Acc: 0.692, Test Loss: 0.600, Test Acc: 0.713\n",
      "Epoch: 002, Train Loss: 0.567, Train Acc: 0.731, Test Loss: 0.601, Test Acc: 0.744\n",
      "Epoch: 003, Train Loss: 0.555, Train Acc: 0.734, Test Loss: 0.589, Test Acc: 0.735\n",
      "Epoch: 004, Train Loss: 0.549, Train Acc: 0.737, Test Loss: 0.583, Test Acc: 0.717\n",
      "Epoch: 005, Train Loss: 0.542, Train Acc: 0.740, Test Loss: 0.574, Test Acc: 0.735\n",
      "Epoch: 006, Train Loss: 0.540, Train Acc: 0.744, Test Loss: 0.566, Test Acc: 0.735\n",
      "Epoch: 007, Train Loss: 0.539, Train Acc: 0.742, Test Loss: 0.567, Test Acc: 0.717\n",
      "Epoch: 008, Train Loss: 0.534, Train Acc: 0.740, Test Loss: 0.559, Test Acc: 0.726\n",
      "Epoch: 009, Train Loss: 0.526, Train Acc: 0.743, Test Loss: 0.560, Test Acc: 0.722\n",
      "Epoch: 010, Train Loss: 0.524, Train Acc: 0.747, Test Loss: 0.558, Test Acc: 0.749\n",
      "Epoch: 011, Train Loss: 0.522, Train Acc: 0.747, Test Loss: 0.553, Test Acc: 0.731\n",
      "Epoch: 012, Train Loss: 0.514, Train Acc: 0.749, Test Loss: 0.558, Test Acc: 0.735\n",
      "Epoch: 013, Train Loss: 0.507, Train Acc: 0.758, Test Loss: 0.560, Test Acc: 0.740\n",
      "Epoch: 014, Train Loss: 0.507, Train Acc: 0.756, Test Loss: 0.573, Test Acc: 0.749\n",
      "Epoch: 015, Train Loss: 0.511, Train Acc: 0.761, Test Loss: 0.574, Test Acc: 0.735\n",
      "Epoch: 016, Train Loss: 0.498, Train Acc: 0.762, Test Loss: 0.562, Test Acc: 0.744\n",
      "Epoch: 017, Train Loss: 0.496, Train Acc: 0.764, Test Loss: 0.572, Test Acc: 0.744\n",
      "Epoch: 018, Train Loss: 0.494, Train Acc: 0.755, Test Loss: 0.570, Test Acc: 0.740\n",
      "Epoch: 019, Train Loss: 0.496, Train Acc: 0.755, Test Loss: 0.564, Test Acc: 0.740\n",
      "Epoch: 020, Train Loss: 0.496, Train Acc: 0.767, Test Loss: 0.568, Test Acc: 0.749\n",
      "Epoch: 021, Train Loss: 0.493, Train Acc: 0.764, Test Loss: 0.567, Test Acc: 0.758\n",
      "Epoch: 022, Train Loss: 0.492, Train Acc: 0.765, Test Loss: 0.550, Test Acc: 0.758\n",
      "Epoch: 023, Train Loss: 0.492, Train Acc: 0.763, Test Loss: 0.561, Test Acc: 0.753\n",
      "Epoch: 024, Train Loss: 0.490, Train Acc: 0.769, Test Loss: 0.560, Test Acc: 0.749\n",
      "Epoch: 025, Train Loss: 0.492, Train Acc: 0.761, Test Loss: 0.571, Test Acc: 0.762\n",
      "Epoch: 026, Train Loss: 0.490, Train Acc: 0.766, Test Loss: 0.568, Test Acc: 0.758\n",
      "Epoch: 027, Train Loss: 0.494, Train Acc: 0.763, Test Loss: 0.551, Test Acc: 0.749\n",
      "Epoch: 028, Train Loss: 0.490, Train Acc: 0.765, Test Loss: 0.567, Test Acc: 0.758\n",
      "Epoch: 029, Train Loss: 0.490, Train Acc: 0.766, Test Loss: 0.548, Test Acc: 0.767\n",
      "Epoch: 030, Train Loss: 0.490, Train Acc: 0.761, Test Loss: 0.556, Test Acc: 0.758\n",
      "Epoch: 031, Train Loss: 0.489, Train Acc: 0.769, Test Loss: 0.558, Test Acc: 0.740\n",
      "Epoch: 032, Train Loss: 0.488, Train Acc: 0.763, Test Loss: 0.549, Test Acc: 0.753\n",
      "Epoch: 033, Train Loss: 0.489, Train Acc: 0.769, Test Loss: 0.549, Test Acc: 0.753\n",
      "Epoch: 034, Train Loss: 0.488, Train Acc: 0.758, Test Loss: 0.565, Test Acc: 0.753\n",
      "Epoch: 035, Train Loss: 0.493, Train Acc: 0.766, Test Loss: 0.566, Test Acc: 0.762\n",
      "Epoch: 036, Train Loss: 0.491, Train Acc: 0.769, Test Loss: 0.555, Test Acc: 0.762\n",
      "Epoch: 037, Train Loss: 0.489, Train Acc: 0.764, Test Loss: 0.555, Test Acc: 0.762\n",
      "Epoch: 038, Train Loss: 0.486, Train Acc: 0.767, Test Loss: 0.554, Test Acc: 0.762\n",
      "Epoch: 039, Train Loss: 0.492, Train Acc: 0.765, Test Loss: 0.549, Test Acc: 0.767\n",
      "Epoch: 040, Train Loss: 0.494, Train Acc: 0.771, Test Loss: 0.576, Test Acc: 0.758\n",
      "Epoch: 041, Train Loss: 0.488, Train Acc: 0.764, Test Loss: 0.560, Test Acc: 0.762\n",
      "Epoch: 042, Train Loss: 0.485, Train Acc: 0.771, Test Loss: 0.544, Test Acc: 0.762\n",
      "Epoch: 043, Train Loss: 0.488, Train Acc: 0.771, Test Loss: 0.553, Test Acc: 0.762\n",
      "Epoch: 044, Train Loss: 0.490, Train Acc: 0.767, Test Loss: 0.559, Test Acc: 0.767\n",
      "Epoch: 045, Train Loss: 0.488, Train Acc: 0.767, Test Loss: 0.549, Test Acc: 0.753\n",
      "Epoch: 046, Train Loss: 0.492, Train Acc: 0.763, Test Loss: 0.547, Test Acc: 0.749\n",
      "Epoch: 047, Train Loss: 0.493, Train Acc: 0.763, Test Loss: 0.551, Test Acc: 0.753\n",
      "Epoch: 048, Train Loss: 0.488, Train Acc: 0.766, Test Loss: 0.559, Test Acc: 0.767\n",
      "Epoch: 049, Train Loss: 0.486, Train Acc: 0.770, Test Loss: 0.556, Test Acc: 0.758\n",
      "RUN:1,Test Acc:0.7578\n",
      "Epoch: 001, Train Loss: 0.639, Train Acc: 0.596, Test Loss: 0.779, Test Acc: 0.596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Loss: 0.605, Train Acc: 0.649, Test Loss: 0.726, Test Acc: 0.628\n",
      "Epoch: 003, Train Loss: 0.583, Train Acc: 0.718, Test Loss: 0.710, Test Acc: 0.704\n",
      "Epoch: 004, Train Loss: 0.571, Train Acc: 0.739, Test Loss: 0.646, Test Acc: 0.744\n",
      "Epoch: 005, Train Loss: 0.554, Train Acc: 0.749, Test Loss: 0.645, Test Acc: 0.726\n",
      "Epoch: 006, Train Loss: 0.539, Train Acc: 0.747, Test Loss: 0.589, Test Acc: 0.758\n",
      "Epoch: 007, Train Loss: 0.529, Train Acc: 0.763, Test Loss: 0.570, Test Acc: 0.758\n",
      "Epoch: 008, Train Loss: 0.524, Train Acc: 0.760, Test Loss: 0.549, Test Acc: 0.717\n",
      "Epoch: 009, Train Loss: 0.518, Train Acc: 0.758, Test Loss: 0.573, Test Acc: 0.758\n",
      "Epoch: 010, Train Loss: 0.522, Train Acc: 0.764, Test Loss: 0.545, Test Acc: 0.726\n",
      "Epoch: 011, Train Loss: 0.515, Train Acc: 0.756, Test Loss: 0.576, Test Acc: 0.749\n",
      "Epoch: 012, Train Loss: 0.514, Train Acc: 0.760, Test Loss: 0.529, Test Acc: 0.735\n",
      "Epoch: 013, Train Loss: 0.512, Train Acc: 0.751, Test Loss: 0.597, Test Acc: 0.744\n",
      "Epoch: 014, Train Loss: 0.505, Train Acc: 0.757, Test Loss: 0.528, Test Acc: 0.740\n",
      "Epoch: 015, Train Loss: 0.501, Train Acc: 0.753, Test Loss: 0.572, Test Acc: 0.740\n",
      "Epoch: 016, Train Loss: 0.505, Train Acc: 0.762, Test Loss: 0.528, Test Acc: 0.749\n",
      "Epoch: 017, Train Loss: 0.499, Train Acc: 0.757, Test Loss: 0.549, Test Acc: 0.740\n",
      "Epoch: 018, Train Loss: 0.497, Train Acc: 0.763, Test Loss: 0.545, Test Acc: 0.758\n",
      "Epoch: 019, Train Loss: 0.496, Train Acc: 0.758, Test Loss: 0.531, Test Acc: 0.744\n",
      "Epoch: 020, Train Loss: 0.497, Train Acc: 0.765, Test Loss: 0.530, Test Acc: 0.758\n",
      "Epoch: 021, Train Loss: 0.495, Train Acc: 0.754, Test Loss: 0.546, Test Acc: 0.753\n",
      "Epoch: 022, Train Loss: 0.493, Train Acc: 0.761, Test Loss: 0.529, Test Acc: 0.753\n",
      "Epoch: 023, Train Loss: 0.492, Train Acc: 0.763, Test Loss: 0.530, Test Acc: 0.753\n",
      "Epoch: 024, Train Loss: 0.494, Train Acc: 0.761, Test Loss: 0.540, Test Acc: 0.749\n",
      "Epoch: 025, Train Loss: 0.490, Train Acc: 0.763, Test Loss: 0.529, Test Acc: 0.762\n",
      "Epoch: 026, Train Loss: 0.493, Train Acc: 0.755, Test Loss: 0.561, Test Acc: 0.740\n",
      "Epoch: 027, Train Loss: 0.499, Train Acc: 0.762, Test Loss: 0.526, Test Acc: 0.753\n",
      "Epoch: 028, Train Loss: 0.494, Train Acc: 0.767, Test Loss: 0.522, Test Acc: 0.758\n",
      "Epoch: 029, Train Loss: 0.500, Train Acc: 0.754, Test Loss: 0.537, Test Acc: 0.740\n",
      "Epoch: 030, Train Loss: 0.493, Train Acc: 0.763, Test Loss: 0.548, Test Acc: 0.753\n",
      "Epoch: 031, Train Loss: 0.494, Train Acc: 0.756, Test Loss: 0.516, Test Acc: 0.753\n",
      "Epoch: 032, Train Loss: 0.494, Train Acc: 0.771, Test Loss: 0.526, Test Acc: 0.758\n",
      "Epoch: 033, Train Loss: 0.488, Train Acc: 0.757, Test Loss: 0.511, Test Acc: 0.749\n",
      "Epoch: 034, Train Loss: 0.487, Train Acc: 0.766, Test Loss: 0.535, Test Acc: 0.762\n",
      "Epoch: 035, Train Loss: 0.487, Train Acc: 0.761, Test Loss: 0.534, Test Acc: 0.753\n",
      "Epoch: 036, Train Loss: 0.490, Train Acc: 0.754, Test Loss: 0.527, Test Acc: 0.758\n",
      "Epoch: 037, Train Loss: 0.494, Train Acc: 0.754, Test Loss: 0.543, Test Acc: 0.753\n",
      "Epoch: 038, Train Loss: 0.497, Train Acc: 0.758, Test Loss: 0.517, Test Acc: 0.749\n",
      "Epoch: 039, Train Loss: 0.488, Train Acc: 0.764, Test Loss: 0.529, Test Acc: 0.758\n",
      "Epoch: 040, Train Loss: 0.488, Train Acc: 0.762, Test Loss: 0.529, Test Acc: 0.762\n",
      "Epoch: 041, Train Loss: 0.489, Train Acc: 0.757, Test Loss: 0.546, Test Acc: 0.731\n",
      "Epoch: 042, Train Loss: 0.492, Train Acc: 0.762, Test Loss: 0.520, Test Acc: 0.762\n",
      "Epoch: 043, Train Loss: 0.490, Train Acc: 0.760, Test Loss: 0.520, Test Acc: 0.753\n",
      "Epoch: 044, Train Loss: 0.489, Train Acc: 0.762, Test Loss: 0.548, Test Acc: 0.767\n",
      "Epoch: 045, Train Loss: 0.486, Train Acc: 0.762, Test Loss: 0.523, Test Acc: 0.749\n",
      "Epoch: 046, Train Loss: 0.486, Train Acc: 0.766, Test Loss: 0.524, Test Acc: 0.758\n",
      "Epoch: 047, Train Loss: 0.484, Train Acc: 0.769, Test Loss: 0.532, Test Acc: 0.762\n",
      "Epoch: 048, Train Loss: 0.485, Train Acc: 0.762, Test Loss: 0.525, Test Acc: 0.749\n",
      "Epoch: 049, Train Loss: 0.484, Train Acc: 0.769, Test Loss: 0.529, Test Acc: 0.758\n",
      "RUN:2,Test Acc:0.7578\n",
      "Epoch: 001, Train Loss: 0.649, Train Acc: 0.602, Test Loss: 0.600, Test Acc: 0.570\n",
      "Epoch: 002, Train Loss: 0.607, Train Acc: 0.604, Test Loss: 0.590, Test Acc: 0.574\n",
      "Epoch: 003, Train Loss: 0.591, Train Acc: 0.661, Test Loss: 0.577, Test Acc: 0.655\n",
      "Epoch: 004, Train Loss: 0.574, Train Acc: 0.727, Test Loss: 0.563, Test Acc: 0.704\n",
      "Epoch: 005, Train Loss: 0.558, Train Acc: 0.757, Test Loss: 0.549, Test Acc: 0.740\n",
      "Epoch: 006, Train Loss: 0.546, Train Acc: 0.770, Test Loss: 0.531, Test Acc: 0.740\n",
      "Epoch: 007, Train Loss: 0.534, Train Acc: 0.766, Test Loss: 0.519, Test Acc: 0.744\n",
      "Epoch: 008, Train Loss: 0.526, Train Acc: 0.770, Test Loss: 0.517, Test Acc: 0.740\n",
      "Epoch: 009, Train Loss: 0.521, Train Acc: 0.765, Test Loss: 0.516, Test Acc: 0.735\n",
      "Epoch: 010, Train Loss: 0.519, Train Acc: 0.762, Test Loss: 0.497, Test Acc: 0.767\n",
      "Epoch: 011, Train Loss: 0.518, Train Acc: 0.763, Test Loss: 0.506, Test Acc: 0.735\n",
      "Epoch: 012, Train Loss: 0.517, Train Acc: 0.765, Test Loss: 0.504, Test Acc: 0.744\n",
      "Epoch: 013, Train Loss: 0.511, Train Acc: 0.767, Test Loss: 0.496, Test Acc: 0.758\n",
      "Epoch: 014, Train Loss: 0.510, Train Acc: 0.770, Test Loss: 0.503, Test Acc: 0.735\n",
      "Epoch: 015, Train Loss: 0.513, Train Acc: 0.762, Test Loss: 0.488, Test Acc: 0.762\n",
      "Epoch: 016, Train Loss: 0.506, Train Acc: 0.771, Test Loss: 0.505, Test Acc: 0.740\n",
      "Epoch: 017, Train Loss: 0.506, Train Acc: 0.761, Test Loss: 0.488, Test Acc: 0.753\n",
      "Epoch: 018, Train Loss: 0.505, Train Acc: 0.774, Test Loss: 0.493, Test Acc: 0.749\n",
      "Epoch: 019, Train Loss: 0.509, Train Acc: 0.770, Test Loss: 0.504, Test Acc: 0.731\n",
      "Epoch: 020, Train Loss: 0.501, Train Acc: 0.758, Test Loss: 0.492, Test Acc: 0.749\n",
      "Epoch: 021, Train Loss: 0.501, Train Acc: 0.772, Test Loss: 0.496, Test Acc: 0.749\n",
      "Epoch: 022, Train Loss: 0.503, Train Acc: 0.761, Test Loss: 0.514, Test Acc: 0.722\n",
      "Epoch: 023, Train Loss: 0.507, Train Acc: 0.760, Test Loss: 0.484, Test Acc: 0.753\n",
      "Epoch: 024, Train Loss: 0.505, Train Acc: 0.778, Test Loss: 0.487, Test Acc: 0.749\n",
      "Epoch: 025, Train Loss: 0.500, Train Acc: 0.771, Test Loss: 0.500, Test Acc: 0.740\n",
      "Epoch: 026, Train Loss: 0.500, Train Acc: 0.778, Test Loss: 0.493, Test Acc: 0.753\n",
      "Epoch: 027, Train Loss: 0.503, Train Acc: 0.773, Test Loss: 0.491, Test Acc: 0.758\n",
      "Epoch: 028, Train Loss: 0.495, Train Acc: 0.769, Test Loss: 0.498, Test Acc: 0.740\n",
      "Epoch: 029, Train Loss: 0.497, Train Acc: 0.773, Test Loss: 0.503, Test Acc: 0.722\n",
      "Epoch: 030, Train Loss: 0.498, Train Acc: 0.766, Test Loss: 0.489, Test Acc: 0.762\n",
      "Epoch: 031, Train Loss: 0.499, Train Acc: 0.758, Test Loss: 0.525, Test Acc: 0.726\n",
      "Epoch: 032, Train Loss: 0.502, Train Acc: 0.765, Test Loss: 0.487, Test Acc: 0.767\n",
      "Epoch: 033, Train Loss: 0.497, Train Acc: 0.771, Test Loss: 0.504, Test Acc: 0.740\n",
      "Epoch: 034, Train Loss: 0.494, Train Acc: 0.772, Test Loss: 0.500, Test Acc: 0.731\n",
      "Epoch: 035, Train Loss: 0.492, Train Acc: 0.773, Test Loss: 0.495, Test Acc: 0.753\n",
      "Epoch: 036, Train Loss: 0.493, Train Acc: 0.770, Test Loss: 0.501, Test Acc: 0.717\n",
      "Epoch: 037, Train Loss: 0.492, Train Acc: 0.776, Test Loss: 0.501, Test Acc: 0.740\n",
      "Epoch: 038, Train Loss: 0.491, Train Acc: 0.776, Test Loss: 0.503, Test Acc: 0.726\n",
      "Epoch: 039, Train Loss: 0.492, Train Acc: 0.772, Test Loss: 0.504, Test Acc: 0.731\n",
      "Epoch: 040, Train Loss: 0.495, Train Acc: 0.771, Test Loss: 0.514, Test Acc: 0.722\n",
      "Epoch: 041, Train Loss: 0.495, Train Acc: 0.774, Test Loss: 0.497, Test Acc: 0.717\n",
      "Epoch: 042, Train Loss: 0.494, Train Acc: 0.772, Test Loss: 0.515, Test Acc: 0.722\n",
      "Epoch: 043, Train Loss: 0.495, Train Acc: 0.775, Test Loss: 0.494, Test Acc: 0.735\n",
      "Epoch: 044, Train Loss: 0.493, Train Acc: 0.770, Test Loss: 0.504, Test Acc: 0.717\n",
      "Epoch: 045, Train Loss: 0.492, Train Acc: 0.773, Test Loss: 0.512, Test Acc: 0.717\n",
      "Epoch: 046, Train Loss: 0.490, Train Acc: 0.780, Test Loss: 0.502, Test Acc: 0.731\n",
      "Epoch: 047, Train Loss: 0.489, Train Acc: 0.770, Test Loss: 0.512, Test Acc: 0.717\n",
      "Epoch: 048, Train Loss: 0.489, Train Acc: 0.780, Test Loss: 0.494, Test Acc: 0.731\n",
      "Epoch: 049, Train Loss: 0.488, Train Acc: 0.782, Test Loss: 0.504, Test Acc: 0.740\n",
      "RUN:3,Test Acc:0.7399\n",
      "Epoch: 001, Train Loss: 0.723, Train Acc: 0.672, Test Loss: 0.511, Test Acc: 0.682\n",
      "Epoch: 002, Train Loss: 0.600, Train Acc: 0.729, Test Loss: 0.569, Test Acc: 0.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Loss: 0.570, Train Acc: 0.743, Test Loss: 0.511, Test Acc: 0.771\n",
      "Epoch: 004, Train Loss: 0.557, Train Acc: 0.744, Test Loss: 0.508, Test Acc: 0.762\n",
      "Epoch: 005, Train Loss: 0.544, Train Acc: 0.748, Test Loss: 0.476, Test Acc: 0.762\n",
      "Epoch: 006, Train Loss: 0.535, Train Acc: 0.752, Test Loss: 0.451, Test Acc: 0.762\n",
      "Epoch: 007, Train Loss: 0.529, Train Acc: 0.754, Test Loss: 0.437, Test Acc: 0.758\n",
      "Epoch: 008, Train Loss: 0.522, Train Acc: 0.753, Test Loss: 0.426, Test Acc: 0.767\n",
      "Epoch: 009, Train Loss: 0.517, Train Acc: 0.758, Test Loss: 0.408, Test Acc: 0.771\n",
      "Epoch: 010, Train Loss: 0.519, Train Acc: 0.756, Test Loss: 0.421, Test Acc: 0.776\n",
      "Epoch: 011, Train Loss: 0.514, Train Acc: 0.746, Test Loss: 0.398, Test Acc: 0.767\n",
      "Epoch: 012, Train Loss: 0.511, Train Acc: 0.755, Test Loss: 0.419, Test Acc: 0.771\n",
      "Epoch: 013, Train Loss: 0.510, Train Acc: 0.761, Test Loss: 0.401, Test Acc: 0.767\n",
      "Epoch: 014, Train Loss: 0.507, Train Acc: 0.753, Test Loss: 0.389, Test Acc: 0.762\n",
      "Epoch: 015, Train Loss: 0.511, Train Acc: 0.757, Test Loss: 0.397, Test Acc: 0.767\n",
      "Epoch: 016, Train Loss: 0.505, Train Acc: 0.753, Test Loss: 0.406, Test Acc: 0.771\n",
      "Epoch: 017, Train Loss: 0.507, Train Acc: 0.764, Test Loss: 0.402, Test Acc: 0.771\n",
      "Epoch: 018, Train Loss: 0.506, Train Acc: 0.763, Test Loss: 0.414, Test Acc: 0.771\n",
      "Epoch: 019, Train Loss: 0.502, Train Acc: 0.752, Test Loss: 0.400, Test Acc: 0.767\n",
      "Epoch: 020, Train Loss: 0.501, Train Acc: 0.767, Test Loss: 0.400, Test Acc: 0.771\n",
      "Epoch: 021, Train Loss: 0.498, Train Acc: 0.764, Test Loss: 0.411, Test Acc: 0.776\n",
      "Epoch: 022, Train Loss: 0.498, Train Acc: 0.754, Test Loss: 0.392, Test Acc: 0.767\n",
      "Epoch: 023, Train Loss: 0.502, Train Acc: 0.762, Test Loss: 0.391, Test Acc: 0.776\n",
      "Epoch: 024, Train Loss: 0.497, Train Acc: 0.770, Test Loss: 0.396, Test Acc: 0.771\n",
      "Epoch: 025, Train Loss: 0.496, Train Acc: 0.765, Test Loss: 0.394, Test Acc: 0.771\n",
      "Epoch: 026, Train Loss: 0.500, Train Acc: 0.747, Test Loss: 0.384, Test Acc: 0.749\n",
      "Epoch: 027, Train Loss: 0.501, Train Acc: 0.764, Test Loss: 0.405, Test Acc: 0.771\n",
      "Epoch: 028, Train Loss: 0.494, Train Acc: 0.762, Test Loss: 0.383, Test Acc: 0.767\n",
      "Epoch: 029, Train Loss: 0.496, Train Acc: 0.767, Test Loss: 0.410, Test Acc: 0.771\n",
      "Epoch: 030, Train Loss: 0.497, Train Acc: 0.771, Test Loss: 0.396, Test Acc: 0.767\n",
      "Epoch: 031, Train Loss: 0.497, Train Acc: 0.758, Test Loss: 0.392, Test Acc: 0.767\n",
      "Epoch: 032, Train Loss: 0.498, Train Acc: 0.772, Test Loss: 0.388, Test Acc: 0.776\n",
      "Epoch: 033, Train Loss: 0.494, Train Acc: 0.773, Test Loss: 0.403, Test Acc: 0.771\n",
      "Epoch: 034, Train Loss: 0.497, Train Acc: 0.770, Test Loss: 0.387, Test Acc: 0.776\n",
      "Epoch: 035, Train Loss: 0.494, Train Acc: 0.748, Test Loss: 0.375, Test Acc: 0.762\n",
      "Epoch: 036, Train Loss: 0.499, Train Acc: 0.770, Test Loss: 0.417, Test Acc: 0.767\n",
      "Epoch: 037, Train Loss: 0.494, Train Acc: 0.765, Test Loss: 0.389, Test Acc: 0.762\n",
      "Epoch: 038, Train Loss: 0.496, Train Acc: 0.772, Test Loss: 0.392, Test Acc: 0.767\n",
      "Epoch: 039, Train Loss: 0.495, Train Acc: 0.765, Test Loss: 0.401, Test Acc: 0.771\n",
      "Epoch: 040, Train Loss: 0.495, Train Acc: 0.771, Test Loss: 0.391, Test Acc: 0.771\n",
      "Epoch: 041, Train Loss: 0.500, Train Acc: 0.755, Test Loss: 0.376, Test Acc: 0.753\n",
      "Epoch: 042, Train Loss: 0.494, Train Acc: 0.772, Test Loss: 0.400, Test Acc: 0.776\n",
      "Epoch: 043, Train Loss: 0.491, Train Acc: 0.775, Test Loss: 0.394, Test Acc: 0.767\n",
      "Epoch: 044, Train Loss: 0.492, Train Acc: 0.764, Test Loss: 0.386, Test Acc: 0.762\n",
      "Epoch: 045, Train Loss: 0.491, Train Acc: 0.766, Test Loss: 0.399, Test Acc: 0.776\n",
      "Epoch: 046, Train Loss: 0.491, Train Acc: 0.755, Test Loss: 0.379, Test Acc: 0.753\n",
      "Epoch: 047, Train Loss: 0.493, Train Acc: 0.771, Test Loss: 0.395, Test Acc: 0.767\n",
      "Epoch: 048, Train Loss: 0.493, Train Acc: 0.772, Test Loss: 0.401, Test Acc: 0.776\n",
      "Epoch: 049, Train Loss: 0.490, Train Acc: 0.770, Test Loss: 0.386, Test Acc: 0.762\n",
      "RUN:4,Test Acc:0.7623\n",
      "Epoch: 001, Train Loss: 0.615, Train Acc: 0.702, Test Loss: 0.539, Test Acc: 0.704\n",
      "Epoch: 002, Train Loss: 0.588, Train Acc: 0.734, Test Loss: 0.525, Test Acc: 0.744\n",
      "Epoch: 003, Train Loss: 0.576, Train Acc: 0.745, Test Loss: 0.514, Test Acc: 0.735\n",
      "Epoch: 004, Train Loss: 0.568, Train Acc: 0.743, Test Loss: 0.504, Test Acc: 0.731\n",
      "Epoch: 005, Train Loss: 0.559, Train Acc: 0.745, Test Loss: 0.498, Test Acc: 0.740\n",
      "Epoch: 006, Train Loss: 0.550, Train Acc: 0.751, Test Loss: 0.495, Test Acc: 0.749\n",
      "Epoch: 007, Train Loss: 0.544, Train Acc: 0.757, Test Loss: 0.492, Test Acc: 0.758\n",
      "Epoch: 008, Train Loss: 0.540, Train Acc: 0.735, Test Loss: 0.504, Test Acc: 0.740\n",
      "Epoch: 009, Train Loss: 0.540, Train Acc: 0.746, Test Loss: 0.500, Test Acc: 0.762\n",
      "Epoch: 010, Train Loss: 0.531, Train Acc: 0.756, Test Loss: 0.490, Test Acc: 0.789\n",
      "Epoch: 011, Train Loss: 0.528, Train Acc: 0.753, Test Loss: 0.487, Test Acc: 0.771\n",
      "Epoch: 012, Train Loss: 0.527, Train Acc: 0.754, Test Loss: 0.479, Test Acc: 0.762\n",
      "Epoch: 013, Train Loss: 0.532, Train Acc: 0.743, Test Loss: 0.520, Test Acc: 0.749\n",
      "Epoch: 014, Train Loss: 0.525, Train Acc: 0.758, Test Loss: 0.490, Test Acc: 0.776\n",
      "Epoch: 015, Train Loss: 0.516, Train Acc: 0.758, Test Loss: 0.496, Test Acc: 0.780\n",
      "Epoch: 016, Train Loss: 0.516, Train Acc: 0.755, Test Loss: 0.494, Test Acc: 0.776\n",
      "Epoch: 017, Train Loss: 0.516, Train Acc: 0.755, Test Loss: 0.488, Test Acc: 0.776\n",
      "Epoch: 018, Train Loss: 0.512, Train Acc: 0.755, Test Loss: 0.492, Test Acc: 0.780\n",
      "Epoch: 019, Train Loss: 0.511, Train Acc: 0.756, Test Loss: 0.497, Test Acc: 0.785\n",
      "Epoch: 020, Train Loss: 0.511, Train Acc: 0.756, Test Loss: 0.475, Test Acc: 0.767\n",
      "Epoch: 021, Train Loss: 0.514, Train Acc: 0.756, Test Loss: 0.510, Test Acc: 0.785\n",
      "Epoch: 022, Train Loss: 0.505, Train Acc: 0.760, Test Loss: 0.486, Test Acc: 0.776\n",
      "Epoch: 023, Train Loss: 0.506, Train Acc: 0.758, Test Loss: 0.493, Test Acc: 0.780\n",
      "Epoch: 024, Train Loss: 0.504, Train Acc: 0.757, Test Loss: 0.492, Test Acc: 0.771\n",
      "Epoch: 025, Train Loss: 0.507, Train Acc: 0.760, Test Loss: 0.488, Test Acc: 0.776\n",
      "Epoch: 026, Train Loss: 0.504, Train Acc: 0.756, Test Loss: 0.504, Test Acc: 0.780\n",
      "Epoch: 027, Train Loss: 0.503, Train Acc: 0.758, Test Loss: 0.489, Test Acc: 0.776\n",
      "Epoch: 028, Train Loss: 0.508, Train Acc: 0.757, Test Loss: 0.484, Test Acc: 0.771\n",
      "Epoch: 029, Train Loss: 0.506, Train Acc: 0.760, Test Loss: 0.484, Test Acc: 0.776\n",
      "Epoch: 030, Train Loss: 0.501, Train Acc: 0.761, Test Loss: 0.491, Test Acc: 0.771\n",
      "Epoch: 031, Train Loss: 0.504, Train Acc: 0.761, Test Loss: 0.486, Test Acc: 0.780\n",
      "Epoch: 032, Train Loss: 0.501, Train Acc: 0.761, Test Loss: 0.498, Test Acc: 0.780\n",
      "Epoch: 033, Train Loss: 0.501, Train Acc: 0.761, Test Loss: 0.476, Test Acc: 0.776\n",
      "Epoch: 034, Train Loss: 0.505, Train Acc: 0.757, Test Loss: 0.478, Test Acc: 0.771\n",
      "Epoch: 035, Train Loss: 0.507, Train Acc: 0.756, Test Loss: 0.522, Test Acc: 0.780\n",
      "Epoch: 036, Train Loss: 0.500, Train Acc: 0.756, Test Loss: 0.481, Test Acc: 0.767\n",
      "Epoch: 037, Train Loss: 0.506, Train Acc: 0.763, Test Loss: 0.486, Test Acc: 0.780\n",
      "Epoch: 038, Train Loss: 0.499, Train Acc: 0.758, Test Loss: 0.501, Test Acc: 0.785\n",
      "Epoch: 039, Train Loss: 0.502, Train Acc: 0.757, Test Loss: 0.472, Test Acc: 0.776\n",
      "Epoch: 040, Train Loss: 0.502, Train Acc: 0.760, Test Loss: 0.502, Test Acc: 0.785\n",
      "Epoch: 041, Train Loss: 0.499, Train Acc: 0.763, Test Loss: 0.484, Test Acc: 0.771\n",
      "Epoch: 042, Train Loss: 0.499, Train Acc: 0.764, Test Loss: 0.494, Test Acc: 0.780\n",
      "Epoch: 043, Train Loss: 0.498, Train Acc: 0.763, Test Loss: 0.478, Test Acc: 0.780\n",
      "Epoch: 044, Train Loss: 0.504, Train Acc: 0.762, Test Loss: 0.480, Test Acc: 0.776\n",
      "Epoch: 045, Train Loss: 0.503, Train Acc: 0.764, Test Loss: 0.495, Test Acc: 0.785\n",
      "Epoch: 046, Train Loss: 0.500, Train Acc: 0.764, Test Loss: 0.471, Test Acc: 0.776\n",
      "Epoch: 047, Train Loss: 0.498, Train Acc: 0.761, Test Loss: 0.500, Test Acc: 0.780\n",
      "Epoch: 048, Train Loss: 0.499, Train Acc: 0.764, Test Loss: 0.495, Test Acc: 0.785\n",
      "Epoch: 049, Train Loss: 0.499, Train Acc: 0.760, Test Loss: 0.489, Test Acc: 0.780\n",
      "RUN:5,Test Acc:0.7803\n",
      "Epoch: 001, Train Loss: 0.611, Train Acc: 0.658, Test Loss: 0.569, Test Acc: 0.646\n",
      "Epoch: 002, Train Loss: 0.586, Train Acc: 0.733, Test Loss: 0.543, Test Acc: 0.722\n",
      "Epoch: 003, Train Loss: 0.572, Train Acc: 0.742, Test Loss: 0.522, Test Acc: 0.753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Loss: 0.563, Train Acc: 0.737, Test Loss: 0.515, Test Acc: 0.744\n",
      "Epoch: 005, Train Loss: 0.561, Train Acc: 0.737, Test Loss: 0.493, Test Acc: 0.731\n",
      "Epoch: 006, Train Loss: 0.552, Train Acc: 0.742, Test Loss: 0.489, Test Acc: 0.762\n",
      "Epoch: 007, Train Loss: 0.545, Train Acc: 0.739, Test Loss: 0.476, Test Acc: 0.740\n",
      "Epoch: 008, Train Loss: 0.541, Train Acc: 0.740, Test Loss: 0.475, Test Acc: 0.749\n",
      "Epoch: 009, Train Loss: 0.538, Train Acc: 0.740, Test Loss: 0.472, Test Acc: 0.762\n",
      "Epoch: 010, Train Loss: 0.531, Train Acc: 0.742, Test Loss: 0.461, Test Acc: 0.740\n",
      "Epoch: 011, Train Loss: 0.527, Train Acc: 0.740, Test Loss: 0.468, Test Acc: 0.762\n",
      "Epoch: 012, Train Loss: 0.520, Train Acc: 0.744, Test Loss: 0.459, Test Acc: 0.753\n",
      "Epoch: 013, Train Loss: 0.519, Train Acc: 0.746, Test Loss: 0.466, Test Acc: 0.749\n",
      "Epoch: 014, Train Loss: 0.521, Train Acc: 0.748, Test Loss: 0.460, Test Acc: 0.762\n",
      "Epoch: 015, Train Loss: 0.512, Train Acc: 0.747, Test Loss: 0.454, Test Acc: 0.753\n",
      "Epoch: 016, Train Loss: 0.513, Train Acc: 0.749, Test Loss: 0.466, Test Acc: 0.735\n",
      "Epoch: 017, Train Loss: 0.510, Train Acc: 0.747, Test Loss: 0.449, Test Acc: 0.762\n",
      "Epoch: 018, Train Loss: 0.506, Train Acc: 0.755, Test Loss: 0.461, Test Acc: 0.744\n",
      "Epoch: 019, Train Loss: 0.507, Train Acc: 0.744, Test Loss: 0.455, Test Acc: 0.744\n",
      "Epoch: 020, Train Loss: 0.504, Train Acc: 0.758, Test Loss: 0.460, Test Acc: 0.744\n",
      "Epoch: 021, Train Loss: 0.503, Train Acc: 0.755, Test Loss: 0.457, Test Acc: 0.744\n",
      "Epoch: 022, Train Loss: 0.501, Train Acc: 0.757, Test Loss: 0.458, Test Acc: 0.744\n",
      "Epoch: 023, Train Loss: 0.504, Train Acc: 0.752, Test Loss: 0.457, Test Acc: 0.744\n",
      "Epoch: 024, Train Loss: 0.510, Train Acc: 0.760, Test Loss: 0.468, Test Acc: 0.740\n",
      "Epoch: 025, Train Loss: 0.506, Train Acc: 0.755, Test Loss: 0.482, Test Acc: 0.726\n",
      "Epoch: 026, Train Loss: 0.505, Train Acc: 0.756, Test Loss: 0.463, Test Acc: 0.753\n",
      "Epoch: 027, Train Loss: 0.506, Train Acc: 0.764, Test Loss: 0.457, Test Acc: 0.749\n",
      "Epoch: 028, Train Loss: 0.498, Train Acc: 0.765, Test Loss: 0.460, Test Acc: 0.740\n",
      "Epoch: 029, Train Loss: 0.498, Train Acc: 0.760, Test Loss: 0.453, Test Acc: 0.744\n",
      "Epoch: 030, Train Loss: 0.502, Train Acc: 0.762, Test Loss: 0.469, Test Acc: 0.749\n",
      "Epoch: 031, Train Loss: 0.501, Train Acc: 0.762, Test Loss: 0.453, Test Acc: 0.744\n",
      "Epoch: 032, Train Loss: 0.496, Train Acc: 0.758, Test Loss: 0.462, Test Acc: 0.744\n",
      "Epoch: 033, Train Loss: 0.492, Train Acc: 0.763, Test Loss: 0.453, Test Acc: 0.740\n",
      "Epoch: 034, Train Loss: 0.496, Train Acc: 0.760, Test Loss: 0.467, Test Acc: 0.740\n",
      "Epoch: 035, Train Loss: 0.505, Train Acc: 0.761, Test Loss: 0.456, Test Acc: 0.731\n",
      "Epoch: 036, Train Loss: 0.497, Train Acc: 0.761, Test Loss: 0.452, Test Acc: 0.735\n",
      "Epoch: 037, Train Loss: 0.498, Train Acc: 0.766, Test Loss: 0.456, Test Acc: 0.753\n",
      "Epoch: 038, Train Loss: 0.493, Train Acc: 0.766, Test Loss: 0.447, Test Acc: 0.735\n",
      "Epoch: 039, Train Loss: 0.493, Train Acc: 0.767, Test Loss: 0.447, Test Acc: 0.740\n",
      "Epoch: 040, Train Loss: 0.493, Train Acc: 0.761, Test Loss: 0.449, Test Acc: 0.735\n",
      "Epoch: 041, Train Loss: 0.490, Train Acc: 0.770, Test Loss: 0.452, Test Acc: 0.744\n",
      "Epoch: 042, Train Loss: 0.491, Train Acc: 0.767, Test Loss: 0.447, Test Acc: 0.749\n",
      "Epoch: 043, Train Loss: 0.486, Train Acc: 0.771, Test Loss: 0.445, Test Acc: 0.735\n",
      "Epoch: 044, Train Loss: 0.490, Train Acc: 0.769, Test Loss: 0.441, Test Acc: 0.740\n",
      "Epoch: 045, Train Loss: 0.491, Train Acc: 0.764, Test Loss: 0.439, Test Acc: 0.744\n",
      "Epoch: 046, Train Loss: 0.490, Train Acc: 0.771, Test Loss: 0.445, Test Acc: 0.753\n",
      "Epoch: 047, Train Loss: 0.488, Train Acc: 0.766, Test Loss: 0.436, Test Acc: 0.753\n",
      "Epoch: 048, Train Loss: 0.487, Train Acc: 0.770, Test Loss: 0.451, Test Acc: 0.762\n",
      "Epoch: 049, Train Loss: 0.483, Train Acc: 0.764, Test Loss: 0.433, Test Acc: 0.744\n",
      "RUN:6,Test Acc:0.7444\n",
      "Epoch: 001, Train Loss: 0.648, Train Acc: 0.655, Test Loss: 0.527, Test Acc: 0.637\n",
      "Epoch: 002, Train Loss: 0.603, Train Acc: 0.678, Test Loss: 0.490, Test Acc: 0.691\n",
      "Epoch: 003, Train Loss: 0.576, Train Acc: 0.749, Test Loss: 0.445, Test Acc: 0.704\n",
      "Epoch: 004, Train Loss: 0.560, Train Acc: 0.749, Test Loss: 0.428, Test Acc: 0.700\n",
      "Epoch: 005, Train Loss: 0.554, Train Acc: 0.754, Test Loss: 0.410, Test Acc: 0.740\n",
      "Epoch: 006, Train Loss: 0.549, Train Acc: 0.749, Test Loss: 0.405, Test Acc: 0.717\n",
      "Epoch: 007, Train Loss: 0.544, Train Acc: 0.754, Test Loss: 0.412, Test Acc: 0.722\n",
      "Epoch: 008, Train Loss: 0.537, Train Acc: 0.747, Test Loss: 0.402, Test Acc: 0.731\n",
      "Epoch: 009, Train Loss: 0.536, Train Acc: 0.749, Test Loss: 0.405, Test Acc: 0.722\n",
      "Epoch: 010, Train Loss: 0.532, Train Acc: 0.751, Test Loss: 0.390, Test Acc: 0.726\n",
      "Epoch: 011, Train Loss: 0.523, Train Acc: 0.753, Test Loss: 0.402, Test Acc: 0.726\n",
      "Epoch: 012, Train Loss: 0.520, Train Acc: 0.755, Test Loss: 0.396, Test Acc: 0.731\n",
      "Epoch: 013, Train Loss: 0.515, Train Acc: 0.757, Test Loss: 0.395, Test Acc: 0.731\n",
      "Epoch: 014, Train Loss: 0.511, Train Acc: 0.756, Test Loss: 0.411, Test Acc: 0.717\n",
      "Epoch: 015, Train Loss: 0.513, Train Acc: 0.761, Test Loss: 0.387, Test Acc: 0.735\n",
      "Epoch: 016, Train Loss: 0.512, Train Acc: 0.762, Test Loss: 0.388, Test Acc: 0.735\n",
      "Epoch: 017, Train Loss: 0.505, Train Acc: 0.762, Test Loss: 0.425, Test Acc: 0.731\n",
      "Epoch: 018, Train Loss: 0.503, Train Acc: 0.763, Test Loss: 0.386, Test Acc: 0.740\n",
      "Epoch: 019, Train Loss: 0.501, Train Acc: 0.766, Test Loss: 0.392, Test Acc: 0.735\n",
      "Epoch: 020, Train Loss: 0.499, Train Acc: 0.767, Test Loss: 0.414, Test Acc: 0.731\n",
      "Epoch: 021, Train Loss: 0.500, Train Acc: 0.769, Test Loss: 0.403, Test Acc: 0.740\n",
      "Epoch: 022, Train Loss: 0.500, Train Acc: 0.761, Test Loss: 0.377, Test Acc: 0.731\n",
      "Epoch: 023, Train Loss: 0.500, Train Acc: 0.766, Test Loss: 0.419, Test Acc: 0.722\n",
      "Epoch: 024, Train Loss: 0.506, Train Acc: 0.774, Test Loss: 0.392, Test Acc: 0.740\n",
      "Epoch: 025, Train Loss: 0.499, Train Acc: 0.766, Test Loss: 0.400, Test Acc: 0.731\n",
      "Epoch: 026, Train Loss: 0.496, Train Acc: 0.773, Test Loss: 0.416, Test Acc: 0.744\n",
      "Epoch: 027, Train Loss: 0.493, Train Acc: 0.778, Test Loss: 0.385, Test Acc: 0.744\n",
      "Epoch: 028, Train Loss: 0.491, Train Acc: 0.771, Test Loss: 0.414, Test Acc: 0.744\n",
      "Epoch: 029, Train Loss: 0.491, Train Acc: 0.769, Test Loss: 0.397, Test Acc: 0.735\n",
      "Epoch: 030, Train Loss: 0.492, Train Acc: 0.766, Test Loss: 0.411, Test Acc: 0.735\n",
      "Epoch: 031, Train Loss: 0.490, Train Acc: 0.771, Test Loss: 0.399, Test Acc: 0.744\n",
      "Epoch: 032, Train Loss: 0.490, Train Acc: 0.770, Test Loss: 0.410, Test Acc: 0.744\n",
      "Epoch: 033, Train Loss: 0.488, Train Acc: 0.776, Test Loss: 0.392, Test Acc: 0.744\n",
      "Epoch: 034, Train Loss: 0.489, Train Acc: 0.772, Test Loss: 0.411, Test Acc: 0.749\n",
      "Epoch: 035, Train Loss: 0.490, Train Acc: 0.776, Test Loss: 0.387, Test Acc: 0.744\n",
      "Epoch: 036, Train Loss: 0.487, Train Acc: 0.776, Test Loss: 0.406, Test Acc: 0.744\n",
      "Epoch: 037, Train Loss: 0.487, Train Acc: 0.776, Test Loss: 0.400, Test Acc: 0.740\n",
      "Epoch: 038, Train Loss: 0.492, Train Acc: 0.773, Test Loss: 0.389, Test Acc: 0.749\n",
      "Epoch: 039, Train Loss: 0.491, Train Acc: 0.770, Test Loss: 0.414, Test Acc: 0.735\n",
      "Epoch: 040, Train Loss: 0.485, Train Acc: 0.770, Test Loss: 0.403, Test Acc: 0.735\n",
      "Epoch: 041, Train Loss: 0.485, Train Acc: 0.773, Test Loss: 0.407, Test Acc: 0.740\n",
      "Epoch: 042, Train Loss: 0.488, Train Acc: 0.775, Test Loss: 0.390, Test Acc: 0.749\n",
      "Epoch: 043, Train Loss: 0.485, Train Acc: 0.769, Test Loss: 0.412, Test Acc: 0.744\n",
      "Epoch: 044, Train Loss: 0.484, Train Acc: 0.783, Test Loss: 0.394, Test Acc: 0.744\n",
      "Epoch: 045, Train Loss: 0.487, Train Acc: 0.778, Test Loss: 0.404, Test Acc: 0.740\n",
      "Epoch: 046, Train Loss: 0.485, Train Acc: 0.772, Test Loss: 0.412, Test Acc: 0.749\n",
      "Epoch: 047, Train Loss: 0.483, Train Acc: 0.778, Test Loss: 0.391, Test Acc: 0.749\n",
      "Epoch: 048, Train Loss: 0.486, Train Acc: 0.774, Test Loss: 0.406, Test Acc: 0.740\n",
      "Epoch: 049, Train Loss: 0.483, Train Acc: 0.775, Test Loss: 0.388, Test Acc: 0.758\n",
      "RUN:7,Test Acc:0.7578\n",
      "Epoch: 001, Train Loss: 0.614, Train Acc: 0.712, Test Loss: 0.488, Test Acc: 0.682\n",
      "Epoch: 002, Train Loss: 0.578, Train Acc: 0.729, Test Loss: 0.566, Test Acc: 0.735\n",
      "Epoch: 003, Train Loss: 0.581, Train Acc: 0.734, Test Loss: 0.501, Test Acc: 0.735\n",
      "Epoch: 004, Train Loss: 0.563, Train Acc: 0.734, Test Loss: 0.532, Test Acc: 0.749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Loss: 0.551, Train Acc: 0.736, Test Loss: 0.517, Test Acc: 0.744\n",
      "Epoch: 006, Train Loss: 0.544, Train Acc: 0.738, Test Loss: 0.505, Test Acc: 0.744\n",
      "Epoch: 007, Train Loss: 0.536, Train Acc: 0.745, Test Loss: 0.480, Test Acc: 0.753\n",
      "Epoch: 008, Train Loss: 0.528, Train Acc: 0.748, Test Loss: 0.531, Test Acc: 0.749\n",
      "Epoch: 009, Train Loss: 0.522, Train Acc: 0.754, Test Loss: 0.459, Test Acc: 0.749\n",
      "Epoch: 010, Train Loss: 0.516, Train Acc: 0.753, Test Loss: 0.502, Test Acc: 0.762\n",
      "Epoch: 011, Train Loss: 0.516, Train Acc: 0.752, Test Loss: 0.531, Test Acc: 0.749\n",
      "Epoch: 012, Train Loss: 0.510, Train Acc: 0.757, Test Loss: 0.500, Test Acc: 0.758\n",
      "Epoch: 013, Train Loss: 0.507, Train Acc: 0.755, Test Loss: 0.510, Test Acc: 0.762\n",
      "Epoch: 014, Train Loss: 0.507, Train Acc: 0.761, Test Loss: 0.435, Test Acc: 0.740\n",
      "Epoch: 015, Train Loss: 0.507, Train Acc: 0.754, Test Loss: 0.456, Test Acc: 0.740\n",
      "Epoch: 016, Train Loss: 0.509, Train Acc: 0.760, Test Loss: 0.470, Test Acc: 0.758\n",
      "Epoch: 017, Train Loss: 0.514, Train Acc: 0.751, Test Loss: 0.536, Test Acc: 0.771\n",
      "Epoch: 018, Train Loss: 0.506, Train Acc: 0.755, Test Loss: 0.463, Test Acc: 0.762\n",
      "Epoch: 019, Train Loss: 0.502, Train Acc: 0.758, Test Loss: 0.482, Test Acc: 0.758\n",
      "Epoch: 020, Train Loss: 0.501, Train Acc: 0.762, Test Loss: 0.478, Test Acc: 0.753\n",
      "Epoch: 021, Train Loss: 0.501, Train Acc: 0.764, Test Loss: 0.437, Test Acc: 0.740\n",
      "Epoch: 022, Train Loss: 0.502, Train Acc: 0.756, Test Loss: 0.510, Test Acc: 0.758\n",
      "Epoch: 023, Train Loss: 0.500, Train Acc: 0.763, Test Loss: 0.470, Test Acc: 0.753\n",
      "Epoch: 024, Train Loss: 0.499, Train Acc: 0.758, Test Loss: 0.449, Test Acc: 0.753\n",
      "Epoch: 025, Train Loss: 0.499, Train Acc: 0.762, Test Loss: 0.495, Test Acc: 0.762\n",
      "Epoch: 026, Train Loss: 0.503, Train Acc: 0.762, Test Loss: 0.458, Test Acc: 0.749\n",
      "Epoch: 027, Train Loss: 0.500, Train Acc: 0.761, Test Loss: 0.489, Test Acc: 0.762\n",
      "Epoch: 028, Train Loss: 0.499, Train Acc: 0.761, Test Loss: 0.467, Test Acc: 0.758\n",
      "Epoch: 029, Train Loss: 0.497, Train Acc: 0.761, Test Loss: 0.522, Test Acc: 0.767\n",
      "Epoch: 030, Train Loss: 0.502, Train Acc: 0.760, Test Loss: 0.468, Test Acc: 0.758\n",
      "Epoch: 031, Train Loss: 0.498, Train Acc: 0.760, Test Loss: 0.494, Test Acc: 0.767\n",
      "Epoch: 032, Train Loss: 0.500, Train Acc: 0.757, Test Loss: 0.490, Test Acc: 0.762\n",
      "Epoch: 033, Train Loss: 0.502, Train Acc: 0.763, Test Loss: 0.459, Test Acc: 0.753\n",
      "Epoch: 034, Train Loss: 0.497, Train Acc: 0.760, Test Loss: 0.485, Test Acc: 0.758\n",
      "Epoch: 035, Train Loss: 0.495, Train Acc: 0.763, Test Loss: 0.457, Test Acc: 0.758\n",
      "Epoch: 036, Train Loss: 0.498, Train Acc: 0.763, Test Loss: 0.447, Test Acc: 0.749\n",
      "Epoch: 037, Train Loss: 0.495, Train Acc: 0.763, Test Loss: 0.475, Test Acc: 0.753\n",
      "Epoch: 038, Train Loss: 0.496, Train Acc: 0.767, Test Loss: 0.456, Test Acc: 0.749\n",
      "Epoch: 039, Train Loss: 0.500, Train Acc: 0.762, Test Loss: 0.450, Test Acc: 0.753\n",
      "Epoch: 040, Train Loss: 0.501, Train Acc: 0.763, Test Loss: 0.478, Test Acc: 0.744\n",
      "Epoch: 041, Train Loss: 0.501, Train Acc: 0.760, Test Loss: 0.498, Test Acc: 0.767\n",
      "Epoch: 042, Train Loss: 0.507, Train Acc: 0.757, Test Loss: 0.413, Test Acc: 0.735\n",
      "Epoch: 043, Train Loss: 0.503, Train Acc: 0.755, Test Loss: 0.498, Test Acc: 0.762\n",
      "Epoch: 044, Train Loss: 0.495, Train Acc: 0.756, Test Loss: 0.448, Test Acc: 0.758\n",
      "Epoch: 045, Train Loss: 0.496, Train Acc: 0.762, Test Loss: 0.456, Test Acc: 0.758\n",
      "Epoch: 046, Train Loss: 0.499, Train Acc: 0.761, Test Loss: 0.498, Test Acc: 0.762\n",
      "Epoch: 047, Train Loss: 0.494, Train Acc: 0.764, Test Loss: 0.462, Test Acc: 0.762\n",
      "Epoch: 048, Train Loss: 0.495, Train Acc: 0.758, Test Loss: 0.509, Test Acc: 0.767\n",
      "Epoch: 049, Train Loss: 0.497, Train Acc: 0.765, Test Loss: 0.449, Test Acc: 0.744\n",
      "RUN:8,Test Acc:0.7444\n",
      "Epoch: 001, Train Loss: 0.686, Train Acc: 0.601, Test Loss: 0.601, Test Acc: 0.596\n",
      "Epoch: 002, Train Loss: 0.598, Train Acc: 0.738, Test Loss: 0.594, Test Acc: 0.758\n",
      "Epoch: 003, Train Loss: 0.574, Train Acc: 0.738, Test Loss: 0.564, Test Acc: 0.762\n",
      "Epoch: 004, Train Loss: 0.562, Train Acc: 0.730, Test Loss: 0.551, Test Acc: 0.767\n",
      "Epoch: 005, Train Loss: 0.549, Train Acc: 0.737, Test Loss: 0.544, Test Acc: 0.771\n",
      "Epoch: 006, Train Loss: 0.541, Train Acc: 0.734, Test Loss: 0.529, Test Acc: 0.780\n",
      "Epoch: 007, Train Loss: 0.536, Train Acc: 0.745, Test Loss: 0.506, Test Acc: 0.798\n",
      "Epoch: 008, Train Loss: 0.529, Train Acc: 0.739, Test Loss: 0.503, Test Acc: 0.789\n",
      "Epoch: 009, Train Loss: 0.525, Train Acc: 0.746, Test Loss: 0.486, Test Acc: 0.789\n",
      "Epoch: 010, Train Loss: 0.526, Train Acc: 0.753, Test Loss: 0.480, Test Acc: 0.789\n",
      "Epoch: 011, Train Loss: 0.518, Train Acc: 0.746, Test Loss: 0.490, Test Acc: 0.785\n",
      "Epoch: 012, Train Loss: 0.514, Train Acc: 0.749, Test Loss: 0.474, Test Acc: 0.780\n",
      "Epoch: 013, Train Loss: 0.512, Train Acc: 0.751, Test Loss: 0.475, Test Acc: 0.785\n",
      "Epoch: 014, Train Loss: 0.512, Train Acc: 0.748, Test Loss: 0.475, Test Acc: 0.789\n",
      "Epoch: 015, Train Loss: 0.510, Train Acc: 0.753, Test Loss: 0.474, Test Acc: 0.785\n",
      "Epoch: 016, Train Loss: 0.513, Train Acc: 0.757, Test Loss: 0.482, Test Acc: 0.780\n",
      "Epoch: 017, Train Loss: 0.515, Train Acc: 0.748, Test Loss: 0.473, Test Acc: 0.785\n",
      "Epoch: 018, Train Loss: 0.512, Train Acc: 0.755, Test Loss: 0.475, Test Acc: 0.789\n",
      "Epoch: 019, Train Loss: 0.512, Train Acc: 0.758, Test Loss: 0.486, Test Acc: 0.771\n",
      "Epoch: 020, Train Loss: 0.512, Train Acc: 0.747, Test Loss: 0.482, Test Acc: 0.789\n",
      "Epoch: 021, Train Loss: 0.509, Train Acc: 0.756, Test Loss: 0.480, Test Acc: 0.794\n",
      "Epoch: 022, Train Loss: 0.507, Train Acc: 0.760, Test Loss: 0.475, Test Acc: 0.780\n",
      "Epoch: 023, Train Loss: 0.508, Train Acc: 0.757, Test Loss: 0.471, Test Acc: 0.785\n",
      "Epoch: 024, Train Loss: 0.506, Train Acc: 0.757, Test Loss: 0.466, Test Acc: 0.785\n",
      "Epoch: 025, Train Loss: 0.508, Train Acc: 0.755, Test Loss: 0.476, Test Acc: 0.767\n",
      "Epoch: 026, Train Loss: 0.509, Train Acc: 0.755, Test Loss: 0.487, Test Acc: 0.776\n",
      "Epoch: 027, Train Loss: 0.515, Train Acc: 0.745, Test Loss: 0.484, Test Acc: 0.789\n",
      "Epoch: 028, Train Loss: 0.507, Train Acc: 0.757, Test Loss: 0.470, Test Acc: 0.785\n",
      "Epoch: 029, Train Loss: 0.505, Train Acc: 0.757, Test Loss: 0.470, Test Acc: 0.789\n",
      "Epoch: 030, Train Loss: 0.505, Train Acc: 0.757, Test Loss: 0.465, Test Acc: 0.789\n",
      "Epoch: 031, Train Loss: 0.505, Train Acc: 0.751, Test Loss: 0.475, Test Acc: 0.780\n",
      "Epoch: 032, Train Loss: 0.510, Train Acc: 0.751, Test Loss: 0.469, Test Acc: 0.785\n",
      "Epoch: 033, Train Loss: 0.502, Train Acc: 0.748, Test Loss: 0.468, Test Acc: 0.789\n",
      "Epoch: 034, Train Loss: 0.502, Train Acc: 0.755, Test Loss: 0.462, Test Acc: 0.785\n",
      "Epoch: 035, Train Loss: 0.504, Train Acc: 0.752, Test Loss: 0.466, Test Acc: 0.785\n",
      "Epoch: 036, Train Loss: 0.504, Train Acc: 0.753, Test Loss: 0.462, Test Acc: 0.789\n",
      "Epoch: 037, Train Loss: 0.504, Train Acc: 0.757, Test Loss: 0.468, Test Acc: 0.780\n",
      "Epoch: 038, Train Loss: 0.508, Train Acc: 0.752, Test Loss: 0.457, Test Acc: 0.803\n",
      "Epoch: 039, Train Loss: 0.510, Train Acc: 0.760, Test Loss: 0.474, Test Acc: 0.780\n",
      "Epoch: 040, Train Loss: 0.501, Train Acc: 0.751, Test Loss: 0.468, Test Acc: 0.789\n",
      "Epoch: 041, Train Loss: 0.502, Train Acc: 0.756, Test Loss: 0.464, Test Acc: 0.794\n",
      "Epoch: 042, Train Loss: 0.502, Train Acc: 0.755, Test Loss: 0.462, Test Acc: 0.785\n",
      "Epoch: 043, Train Loss: 0.502, Train Acc: 0.755, Test Loss: 0.470, Test Acc: 0.794\n",
      "Epoch: 044, Train Loss: 0.499, Train Acc: 0.755, Test Loss: 0.465, Test Acc: 0.794\n",
      "Epoch: 045, Train Loss: 0.500, Train Acc: 0.757, Test Loss: 0.463, Test Acc: 0.789\n",
      "Epoch: 046, Train Loss: 0.502, Train Acc: 0.756, Test Loss: 0.480, Test Acc: 0.776\n",
      "Epoch: 047, Train Loss: 0.507, Train Acc: 0.752, Test Loss: 0.466, Test Acc: 0.785\n",
      "Epoch: 048, Train Loss: 0.501, Train Acc: 0.756, Test Loss: 0.474, Test Acc: 0.780\n",
      "Epoch: 049, Train Loss: 0.501, Train Acc: 0.762, Test Loss: 0.466, Test Acc: 0.794\n",
      "RUN:9,Test Acc:0.7937\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    k = 0\n",
    "    nG = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        #print(data.x.size(), data.edge_index.size(),data.batch.size(), k)\n",
    "        data\n",
    "        nG += data.num_graphs\n",
    "        optimizer.zero_grad()\n",
    "        out= model(data.x, data.edge_index, data.batch) # data.batch  torch.Size([783])\n",
    "        loss = F.nll_loss(out, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        loss_all += data.y.size(0) * loss.item()\n",
    "        optimizer.step()\n",
    "        k = k + 1\n",
    "    #print(\"Training graphs per epoch\", nG)\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(pred, data.y.view(-1))\n",
    "        correct += pred.max(dim=1)[1].eq(data.y.view(-1)).sum().item()\n",
    "\n",
    "    return loss, correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = start_patience = 50\n",
    "for i in range(10):\n",
    "    dataset = dataset.shuffle()\n",
    "    train_dataset = dataset[:890]\n",
    "    test_dataset = dataset[890:]\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = Net(dataset.num_features, dataset.num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    for epoch in range(1, 50):\n",
    "        train_loss = train(epoch)\n",
    "        _, train_acc = test(train_loader)\n",
    "        test_loss, test_acc = test(test_loader)\n",
    "        print('Epoch: {:03d}, '\n",
    "              'Train Loss: {:.3f}, Train Acc: {:.3f}, '\n",
    "              'Test Loss: {:.3f}, Test Acc: {:.3f}'.format(epoch, train_loss,\n",
    "                                                           train_acc,\n",
    "                                                            test_loss,\n",
    "                                                           test_acc))\n",
    "    print(f'RUN:{i},Test Acc:{test_acc:.4f}')\n",
    "    resultados.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "28d17cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7814)\n",
      "tensor(0.0531)\n"
     ]
    }
   ],
   "source": [
    "res= torch.Tensor(resultados)\n",
    "print(torch.mean(res))\n",
    "print(torch.std(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "addaf0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 144], x=[40, 3], y=[1], batch=[40], ptr=[2])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset[2:], batch_size=1, shuffle=False)\n",
    "sample = next(iter(test_loader))\n",
    "#sample.batch =torch.tensor(1)\n",
    "print(sample)\n",
    "print(sample.y)\n",
    "out = model(sample.x,sample.edge_index, sample.batch)  # Perform a single forward pass.\n",
    "pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "print(pred)\n",
    "correct = 0\n",
    "correct += int((pred[0] == sample[0].y).sum())  # Check against ground-truth labels.\n",
    "print(\"Accuracy: \",(correct/1)*100)#Batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da05ae93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 144], x=[40, 3], y=[1], batch=[40], ptr=[2])\n",
      "40\n",
      "<Layout with 40 vertices and 3 dimensions>\n",
      "[(0, 23), (0, 27), (0, 28), (1, 2), (1, 3), (1, 4), (1, 30), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5), (3, 32), (4, 5), (5, 8), (5, 32), (6, 7), (6, 8), (6, 31), (6, 32), (7, 8), (7, 31), (8, 26), (9, 10), (9, 24), (9, 25), (9, 26), (10, 11), (10, 24), (11, 12), (11, 33), (12, 33), (12, 36), (13, 14), (13, 33), (13, 36), (14, 15), (14, 36), (15, 16), (15, 38), (16, 17), (16, 38), (17, 38), (17, 39), (18, 19), (18, 35), (18, 39), (19, 20), (19, 35), (20, 21), (20, 35), (21, 22), (21, 34), (21, 37), (22, 34), (22, 37), (23, 27), (23, 28), (24, 25), (24, 26), (25, 26), (27, 28), (27, 29), (27, 30), (28, 29), (28, 30), (29, 30), (31, 32), (33, 36), (34, 37), (35, 39), (38, 39)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import *\n",
    "#loader =  DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "grafo_init = sample\n",
    "print(grafo_init)\n",
    "A = to_networkx(grafo_init, to_undirected=True)\n",
    "l=[]\n",
    "for a in A.nodes:\n",
    "    l.append(a)\n",
    "ed= []\n",
    "for e in A.edges:\n",
    "    ed.append(e)\n",
    "import igraph as ig\n",
    "import chart_studio.plotly\n",
    "Edges= ed\n",
    "G=ig.Graph(Edges, directed=False)\n",
    "labels= l\n",
    "#groups = A.node_attr_dict_factory\n",
    "N = len(A.nodes)\n",
    "print(N)\n",
    "layt=G.layout('kk', dim=3)\n",
    "print(layt)\n",
    "Xn=[layt[k][0] for k in range(N)]# x-coordinates of nodes\n",
    "Yn=[layt[k][1] for k in range(N)]# y-coordinates\n",
    "Zn=[layt[k][2] for k in range(N)]# z-coordinates\n",
    "Xe=[]\n",
    "Ye=[]\n",
    "Ze=[]\n",
    "print(Edges)\n",
    "for e in Edges:\n",
    "    Xe+=[layt[e[0]][0],layt[e[1]][0], None]# x-coordinates of edge ends\n",
    "    Ye+=[layt[e[0]][1],layt[e[1]][1], None]\n",
    "    Ze+=[layt[e[0]][2],layt[e[1]][2], None]\n",
    "nx.draw(A)\n",
    "node_adjacencies = []\n",
    "node_text = []\n",
    "for node, adjacencies in enumerate(A.nodes()):\n",
    "    #print(adjacencies,critical_nodes)\n",
    "    if adjacencies in critical_nodes :\n",
    "        node_adjacencies.append('rgb(256,0,0)')\n",
    "    else:\n",
    "        node_adjacencies.append('rgb(0,0,0)')\n",
    "    #node_text.append('# of connections: '+str(len(adjacencies[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2570a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chart_studio import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1=go.Scatter3d(x=Xe,\n",
    "               y=Ye,\n",
    "               z=Ze,\n",
    "               mode='lines',\n",
    "               line=dict(color='rgb(125,125,125)', width=1),\n",
    "               hoverinfo='none'\n",
    "               )\n",
    "\n",
    "trace2=go.Scatter3d(x=Xn,\n",
    "               y=Yn,\n",
    "               z=Zn,\n",
    "               mode='markers',\n",
    "               name='actors',\n",
    "               marker=dict(symbol='circle',\n",
    "                             size=6,\n",
    "                             #color='#ff7f0e',\n",
    "                             colorscale='Viridis',\n",
    "                             line=dict(color='rgb(50,50,50)', width=0.5)\n",
    "                             ),\n",
    "               text=labels,\n",
    "               hoverinfo='text'\n",
    "               )\n",
    "trace2.marker.color = node_adjacencies\n",
    "#print(trace2)\n",
    "axis=dict(showbackground=False,\n",
    "          showline=False,\n",
    "          zeroline=False,\n",
    "          showgrid=False,\n",
    "          showticklabels=False,\n",
    "          title=''\n",
    "          )\n",
    "\n",
    "layout = go.Layout(\n",
    "         width=1000,\n",
    "         height=1000,\n",
    "         showlegend=False,\n",
    "         scene=dict(\n",
    "             xaxis=dict(axis),\n",
    "             yaxis=dict(axis),\n",
    "             zaxis=dict(axis),\n",
    "        ),\n",
    "     margin=dict(\n",
    "        t=100\n",
    "    ),\n",
    "    hovermode='closest',    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8ccae49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "hoverinfo": "none",
         "line": {
          "color": "rgb(125,125,125)",
          "width": 1
         },
         "mode": "lines",
         "type": "scatter3d",
         "x": [
          -0.8070447833252102,
          -0.869353339422124,
          null,
          -0.8070447833252102,
          -0.5550518587596115,
          null,
          -0.8070447833252102,
          -0.751790669317679,
          null,
          -0.2869099108651412,
          -0.2492850694024043,
          null,
          -0.2869099108651412,
          0.003194388269609994,
          null,
          -0.2869099108651412,
          -0.19973367625304858,
          null,
          -0.2869099108651412,
          -0.46366564530046833,
          null,
          -0.2492850694024043,
          0.003194388269609994,
          null,
          -0.2492850694024043,
          -0.19973367625304858,
          null,
          -0.2492850694024043,
          0.05140307295412916,
          null,
          0.003194388269609994,
          -0.19973367625304858,
          null,
          0.003194388269609994,
          0.05140307295412916,
          null,
          0.003194388269609994,
          0.32030980308391244,
          null,
          -0.19973367625304858,
          0.05140307295412916,
          null,
          0.05140307295412916,
          0.308778716744253,
          null,
          0.05140307295412916,
          0.32030980308391244,
          null,
          0.5233786089000426,
          0.6566994272293745,
          null,
          0.5233786089000426,
          0.308778716744253,
          null,
          0.5233786089000426,
          0.6460732249830471,
          null,
          0.5233786089000426,
          0.32030980308391244,
          null,
          0.6566994272293745,
          0.308778716744253,
          null,
          0.6566994272293745,
          0.6460732249830471,
          null,
          0.308778716744253,
          0.29914644268335594,
          null,
          0.4657004646555994,
          0.3615152749983518,
          null,
          0.4657004646555994,
          0.20356649576475006,
          null,
          0.4657004646555994,
          0.34077717548820635,
          null,
          0.4657004646555994,
          0.29914644268335594,
          null,
          0.3615152749983518,
          0.3842443923474905,
          null,
          0.3615152749983518,
          0.20356649576475006,
          null,
          0.3842443923474905,
          0.5359553090456766,
          null,
          0.3842443923474905,
          0.30813683764454247,
          null,
          0.5359553090456766,
          0.30813683764454247,
          null,
          0.5359553090456766,
          0.44787371784445323,
          null,
          0.21888637410952688,
          0.3581957342544879,
          null,
          0.21888637410952688,
          0.30813683764454247,
          null,
          0.21888637410952688,
          0.44787371784445323,
          null,
          0.3581957342544879,
          0.3832889414848931,
          null,
          0.3581957342544879,
          0.44787371784445323,
          null,
          0.3832889414848931,
          0.5383620103214027,
          null,
          0.3832889414848931,
          0.3344864071123659,
          null,
          0.5383620103214027,
          0.4888928384274308,
          null,
          0.5383620103214027,
          0.3344864071123659,
          null,
          0.4888928384274308,
          0.3344864071123659,
          null,
          0.4888928384274308,
          0.2846562254039355,
          null,
          0.3678509809107188,
          0.21882246626422974,
          null,
          0.3678509809107188,
          0.12203037267231784,
          null,
          0.3678509809107188,
          0.2846562254039355,
          null,
          0.21882246626422974,
          -0.04854580699135162,
          null,
          0.21882246626422974,
          0.12203037267231784,
          null,
          -0.04854580699135162,
          -0.25096915080789967,
          null,
          -0.04854580699135162,
          0.12203037267231784,
          null,
          -0.25096915080789967,
          -0.5205275838327373,
          null,
          -0.25096915080789967,
          -0.2512095743863335,
          null,
          -0.25096915080789967,
          -0.393540167108645,
          null,
          -0.5205275838327373,
          -0.2512095743863335,
          null,
          -0.5205275838327373,
          -0.393540167108645,
          null,
          -0.869353339422124,
          -0.5550518587596115,
          null,
          -0.869353339422124,
          -0.751790669317679,
          null,
          0.20356649576475006,
          0.34077717548820635,
          null,
          0.20356649576475006,
          0.29914644268335594,
          null,
          0.34077717548820635,
          0.29914644268335594,
          null,
          -0.5550518587596115,
          -0.751790669317679,
          null,
          -0.5550518587596115,
          -0.48704569469144027,
          null,
          -0.5550518587596115,
          -0.46366564530046833,
          null,
          -0.751790669317679,
          -0.48704569469144027,
          null,
          -0.751790669317679,
          -0.46366564530046833,
          null,
          -0.48704569469144027,
          -0.46366564530046833,
          null,
          0.6460732249830471,
          0.32030980308391244,
          null,
          0.30813683764454247,
          0.44787371784445323,
          null,
          -0.2512095743863335,
          -0.393540167108645,
          null,
          0.12203037267231784,
          0.2846562254039355,
          null,
          0.3344864071123659,
          0.2846562254039355,
          null
         ],
         "y": [
          0.3993800505896674,
          0.11888522073782429,
          null,
          0.3993800505896674,
          0.20920763766928527,
          null,
          0.3993800505896674,
          0.28526583842512204,
          null,
          0.05034902986135763,
          0.03652316038543035,
          null,
          0.05034902986135763,
          0.017129160746906152,
          null,
          0.05034902986135763,
          -0.21227755843151552,
          null,
          0.05034902986135763,
          0.1896004296919303,
          null,
          0.03652316038543035,
          0.017129160746906152,
          null,
          0.03652316038543035,
          -0.21227755843151552,
          null,
          0.03652316038543035,
          -0.1316312855687863,
          null,
          0.017129160746906152,
          -0.21227755843151552,
          null,
          0.017129160746906152,
          -0.1316312855687863,
          null,
          0.017129160746906152,
          0.030077991390861453,
          null,
          -0.21227755843151552,
          -0.1316312855687863,
          null,
          -0.1316312855687863,
          -0.2276153676016854,
          null,
          -0.1316312855687863,
          0.030077991390861453,
          null,
          -0.005214740594449314,
          -0.27667799969286905,
          null,
          -0.005214740594449314,
          -0.2276153676016854,
          null,
          -0.005214740594449314,
          -0.08196549558009411,
          null,
          -0.005214740594449314,
          0.030077991390861453,
          null,
          -0.27667799969286905,
          -0.2276153676016854,
          null,
          -0.27667799969286905,
          -0.08196549558009411,
          null,
          -0.2276153676016854,
          -0.3530505265105978,
          null,
          -0.40821113053000224,
          -0.42059013399627276,
          null,
          -0.40821113053000224,
          -0.44372515461253165,
          null,
          -0.40821113053000224,
          -0.6611936895176564,
          null,
          -0.40821113053000224,
          -0.3530505265105978,
          null,
          -0.42059013399627276,
          -0.4155049174422634,
          null,
          -0.42059013399627276,
          -0.44372515461253165,
          null,
          -0.4155049174422634,
          -0.2998487857915494,
          null,
          -0.4155049174422634,
          -0.49135147366990717,
          null,
          -0.2998487857915494,
          -0.49135147366990717,
          null,
          -0.2998487857915494,
          -0.35663988737115787,
          null,
          -0.5465395256438597,
          -0.41424723912624445,
          null,
          -0.5465395256438597,
          -0.49135147366990717,
          null,
          -0.5465395256438597,
          -0.35663988737115787,
          null,
          -0.41424723912624445,
          -0.39509898631364554,
          null,
          -0.41424723912624445,
          -0.35663988737115787,
          null,
          -0.39509898631364554,
          -0.5492889822978466,
          null,
          -0.39509898631364554,
          -0.30559963735293033,
          null,
          -0.5492889822978466,
          -0.44455630280130687,
          null,
          -0.5492889822978466,
          -0.30559963735293033,
          null,
          -0.44455630280130687,
          -0.30559963735293033,
          null,
          -0.44455630280130687,
          -0.1776723910209659,
          null,
          0.09398766154470008,
          0.14704007782320902,
          null,
          0.09398766154470008,
          -0.08453342560481342,
          null,
          0.09398766154470008,
          -0.1776723910209659,
          null,
          0.14704007782320902,
          -0.040211815380110705,
          null,
          0.14704007782320902,
          -0.08453342560481342,
          null,
          -0.040211815380110705,
          -0.04100932634625198,
          null,
          -0.040211815380110705,
          -0.08453342560481342,
          null,
          -0.04100932634625198,
          -0.12721350684913893,
          null,
          -0.04100932634625198,
          -0.11426174188776443,
          null,
          -0.04100932634625198,
          0.15059027580565046,
          null,
          -0.12721350684913893,
          -0.11426174188776443,
          null,
          -0.12721350684913893,
          0.15059027580565046,
          null,
          0.11888522073782429,
          0.20920763766928527,
          null,
          0.11888522073782429,
          0.28526583842512204,
          null,
          -0.44372515461253165,
          -0.6611936895176564,
          null,
          -0.44372515461253165,
          -0.3530505265105978,
          null,
          -0.6611936895176564,
          -0.3530505265105978,
          null,
          0.20920763766928527,
          0.28526583842512204,
          null,
          0.20920763766928527,
          0.48098246231211605,
          null,
          0.20920763766928527,
          0.1896004296919303,
          null,
          0.28526583842512204,
          0.48098246231211605,
          null,
          0.28526583842512204,
          0.1896004296919303,
          null,
          0.48098246231211605,
          0.1896004296919303,
          null,
          -0.08196549558009411,
          0.030077991390861453,
          null,
          -0.49135147366990717,
          -0.35663988737115787,
          null,
          -0.11426174188776443,
          0.15059027580565046,
          null,
          -0.08453342560481342,
          -0.1776723910209659,
          null,
          -0.30559963735293033,
          -0.1776723910209659,
          null
         ],
         "z": [
          -2.788162457015658,
          -2.7525296089368245,
          null,
          -2.788162457015658,
          -2.638683843513665,
          null,
          -2.788162457015658,
          -2.4706484329497638,
          null,
          -2.0352033052402914,
          -1.6944002055570462,
          null,
          -2.0352033052402914,
          -1.8599638265070546,
          null,
          -2.0352033052402914,
          -1.824780616506346,
          null,
          -2.0352033052402914,
          -2.3043655207647706,
          null,
          -1.6944002055570462,
          -1.8599638265070546,
          null,
          -1.6944002055570462,
          -1.824780616506346,
          null,
          -1.6944002055570462,
          -1.5768436928151157,
          null,
          -1.8599638265070546,
          -1.824780616506346,
          null,
          -1.8599638265070546,
          -1.5768436928151157,
          null,
          -1.8599638265070546,
          -1.7837735546185336,
          null,
          -1.824780616506346,
          -1.5768436928151157,
          null,
          -1.5768436928151157,
          -1.3156168581682304,
          null,
          -1.5768436928151157,
          -1.7837735546185336,
          null,
          -1.4945943626689944,
          -1.4903137057402747,
          null,
          -1.4945943626689944,
          -1.3156168581682304,
          null,
          -1.4945943626689944,
          -1.782223346930268,
          null,
          -1.4945943626689944,
          -1.7837735546185336,
          null,
          -1.4903137057402747,
          -1.3156168581682304,
          null,
          -1.4903137057402747,
          -1.782223346930268,
          null,
          -1.3156168581682304,
          -0.9677337442504306,
          null,
          -0.6636449919903264,
          -0.3294038746949407,
          null,
          -0.6636449919903264,
          -0.6450222371687941,
          null,
          -0.6636449919903264,
          -0.8471172448240873,
          null,
          -0.6636449919903264,
          -0.9677337442504306,
          null,
          -0.3294038746949407,
          0.013404262168507717,
          null,
          -0.3294038746949407,
          -0.6450222371687941,
          null,
          0.013404262168507717,
          0.30105513065829437,
          null,
          0.013404262168507717,
          0.3372444316968079,
          null,
          0.30105513065829437,
          0.3372444316968079,
          null,
          0.30105513065829437,
          0.6265792451999955,
          null,
          0.6621768594939337,
          0.9495271511050499,
          null,
          0.6621768594939337,
          0.3372444316968079,
          null,
          0.6621768594939337,
          0.6265792451999955,
          null,
          0.9495271511050499,
          1.2899431278229325,
          null,
          0.9495271511050499,
          0.6265792451999955,
          null,
          1.2899431278229325,
          1.5444387400707882,
          null,
          1.2899431278229325,
          1.6141446882312491,
          null,
          1.5444387400707882,
          1.8599020548608345,
          null,
          1.5444387400707882,
          1.6141446882312491,
          null,
          1.8599020548608345,
          1.6141446882312491,
          null,
          1.8599020548608345,
          1.9294581157702133,
          null,
          2.1262668101736435,
          2.426527301427887,
          null,
          2.1262668101736435,
          2.2146157964557216,
          null,
          2.1262668101736435,
          1.9294581157702133,
          null,
          2.426527301427887,
          2.500933766156351,
          null,
          2.426527301427887,
          2.2146157964557216,
          null,
          2.500933766156351,
          2.779002343555806,
          null,
          2.500933766156351,
          2.2146157964557216,
          null,
          2.779002343555806,
          2.953067308819474,
          null,
          2.779002343555806,
          3.1059817301052277,
          null,
          2.779002343555806,
          3.0118377119659,
          null,
          2.953067308819474,
          3.1059817301052277,
          null,
          2.953067308819474,
          3.0118377119659,
          null,
          -2.7525296089368245,
          -2.638683843513665,
          null,
          -2.7525296089368245,
          -2.4706484329497638,
          null,
          -0.6450222371687941,
          -0.8471172448240873,
          null,
          -0.6450222371687941,
          -0.9677337442504306,
          null,
          -0.8471172448240873,
          -0.9677337442504306,
          null,
          -2.638683843513665,
          -2.4706484329497638,
          null,
          -2.638683843513665,
          -2.465582324265053,
          null,
          -2.638683843513665,
          -2.3043655207647706,
          null,
          -2.4706484329497638,
          -2.465582324265053,
          null,
          -2.4706484329497638,
          -2.3043655207647706,
          null,
          -2.465582324265053,
          -2.3043655207647706,
          null,
          -1.782223346930268,
          -1.7837735546185336,
          null,
          0.3372444316968079,
          0.6265792451999955,
          null,
          3.1059817301052277,
          3.0118377119659,
          null,
          2.2146157964557216,
          1.9294581157702133,
          null,
          1.6141446882312491,
          1.9294581157702133,
          null
         ]
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": [
           "rgb(256,0,0)",
           "rgb(0,0,0)",
           "rgb(256,0,0)",
           "rgb(256,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(256,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(256,0,0)",
           "rgb(256,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)",
           "rgb(0,0,0)"
          ],
          "colorscale": [
           [
            0,
            "#440154"
           ],
           [
            0.1111111111111111,
            "#482878"
           ],
           [
            0.2222222222222222,
            "#3e4989"
           ],
           [
            0.3333333333333333,
            "#31688e"
           ],
           [
            0.4444444444444444,
            "#26828e"
           ],
           [
            0.5555555555555556,
            "#1f9e89"
           ],
           [
            0.6666666666666666,
            "#35b779"
           ],
           [
            0.7777777777777778,
            "#6ece58"
           ],
           [
            0.8888888888888888,
            "#b5de2b"
           ],
           [
            1,
            "#fde725"
           ]
          ],
          "line": {
           "color": "rgb(50,50,50)",
           "width": 0.5
          },
          "size": 6,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "actors",
         "text": [
          "0",
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39"
         ],
         "type": "scatter3d",
         "x": [
          -0.8070447833252102,
          -0.2869099108651412,
          -0.2492850694024043,
          0.003194388269609994,
          -0.19973367625304858,
          0.05140307295412916,
          0.5233786089000426,
          0.6566994272293745,
          0.308778716744253,
          0.4657004646555994,
          0.3615152749983518,
          0.3842443923474905,
          0.5359553090456766,
          0.21888637410952688,
          0.3581957342544879,
          0.3832889414848931,
          0.5383620103214027,
          0.4888928384274308,
          0.3678509809107188,
          0.21882246626422974,
          -0.04854580699135162,
          -0.25096915080789967,
          -0.5205275838327373,
          -0.869353339422124,
          0.20356649576475006,
          0.34077717548820635,
          0.29914644268335594,
          -0.5550518587596115,
          -0.751790669317679,
          -0.48704569469144027,
          -0.46366564530046833,
          0.6460732249830471,
          0.32030980308391244,
          0.30813683764454247,
          -0.2512095743863335,
          0.12203037267231784,
          0.44787371784445323,
          -0.393540167108645,
          0.3344864071123659,
          0.2846562254039355
         ],
         "y": [
          0.3993800505896674,
          0.05034902986135763,
          0.03652316038543035,
          0.017129160746906152,
          -0.21227755843151552,
          -0.1316312855687863,
          -0.005214740594449314,
          -0.27667799969286905,
          -0.2276153676016854,
          -0.40821113053000224,
          -0.42059013399627276,
          -0.4155049174422634,
          -0.2998487857915494,
          -0.5465395256438597,
          -0.41424723912624445,
          -0.39509898631364554,
          -0.5492889822978466,
          -0.44455630280130687,
          0.09398766154470008,
          0.14704007782320902,
          -0.040211815380110705,
          -0.04100932634625198,
          -0.12721350684913893,
          0.11888522073782429,
          -0.44372515461253165,
          -0.6611936895176564,
          -0.3530505265105978,
          0.20920763766928527,
          0.28526583842512204,
          0.48098246231211605,
          0.1896004296919303,
          -0.08196549558009411,
          0.030077991390861453,
          -0.49135147366990717,
          -0.11426174188776443,
          -0.08453342560481342,
          -0.35663988737115787,
          0.15059027580565046,
          -0.30559963735293033,
          -0.1776723910209659
         ],
         "z": [
          -2.788162457015658,
          -2.0352033052402914,
          -1.6944002055570462,
          -1.8599638265070546,
          -1.824780616506346,
          -1.5768436928151157,
          -1.4945943626689944,
          -1.4903137057402747,
          -1.3156168581682304,
          -0.6636449919903264,
          -0.3294038746949407,
          0.013404262168507717,
          0.30105513065829437,
          0.6621768594939337,
          0.9495271511050499,
          1.2899431278229325,
          1.5444387400707882,
          1.8599020548608345,
          2.1262668101736435,
          2.426527301427887,
          2.500933766156351,
          2.779002343555806,
          2.953067308819474,
          -2.7525296089368245,
          -0.6450222371687941,
          -0.8471172448240873,
          -0.9677337442504306,
          -2.638683843513665,
          -2.4706484329497638,
          -2.465582324265053,
          -2.3043655207647706,
          -1.782223346930268,
          -1.7837735546185336,
          0.3372444316968079,
          3.1059817301052277,
          2.2146157964557216,
          0.6265792451999955,
          3.0118377119659,
          1.6141446882312491,
          1.9294581157702133
         ]
        }
       ],
       "layout": {
        "height": 1000,
        "hovermode": "closest",
        "margin": {
         "t": 100
        },
        "scene": {
         "xaxis": {
          "showbackground": false,
          "showgrid": false,
          "showline": false,
          "showticklabels": false,
          "title": {
           "text": ""
          },
          "zeroline": false
         },
         "yaxis": {
          "showbackground": false,
          "showgrid": false,
          "showline": false,
          "showticklabels": false,
          "title": {
           "text": ""
          },
          "zeroline": false
         },
         "zaxis": {
          "showbackground": false,
          "showgrid": false,
          "showline": false,
          "showticklabels": false,
          "title": {
           "text": ""
          },
          "zeroline": false
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1000
       }
      },
      "text/html": [
       "<div>                            <div id=\"8d3275ee-7353-4718-88ad-10c336c38db5\" class=\"plotly-graph-div\" style=\"height:1000px; width:1000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8d3275ee-7353-4718-88ad-10c336c38db5\")) {                    Plotly.newPlot(                        \"8d3275ee-7353-4718-88ad-10c336c38db5\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"rgb(125,125,125)\",\"width\":1},\"mode\":\"lines\",\"x\":[-0.8070447833252102,-0.869353339422124,null,-0.8070447833252102,-0.5550518587596115,null,-0.8070447833252102,-0.751790669317679,null,-0.2869099108651412,-0.2492850694024043,null,-0.2869099108651412,0.003194388269609994,null,-0.2869099108651412,-0.19973367625304858,null,-0.2869099108651412,-0.46366564530046833,null,-0.2492850694024043,0.003194388269609994,null,-0.2492850694024043,-0.19973367625304858,null,-0.2492850694024043,0.05140307295412916,null,0.003194388269609994,-0.19973367625304858,null,0.003194388269609994,0.05140307295412916,null,0.003194388269609994,0.32030980308391244,null,-0.19973367625304858,0.05140307295412916,null,0.05140307295412916,0.308778716744253,null,0.05140307295412916,0.32030980308391244,null,0.5233786089000426,0.6566994272293745,null,0.5233786089000426,0.308778716744253,null,0.5233786089000426,0.6460732249830471,null,0.5233786089000426,0.32030980308391244,null,0.6566994272293745,0.308778716744253,null,0.6566994272293745,0.6460732249830471,null,0.308778716744253,0.29914644268335594,null,0.4657004646555994,0.3615152749983518,null,0.4657004646555994,0.20356649576475006,null,0.4657004646555994,0.34077717548820635,null,0.4657004646555994,0.29914644268335594,null,0.3615152749983518,0.3842443923474905,null,0.3615152749983518,0.20356649576475006,null,0.3842443923474905,0.5359553090456766,null,0.3842443923474905,0.30813683764454247,null,0.5359553090456766,0.30813683764454247,null,0.5359553090456766,0.44787371784445323,null,0.21888637410952688,0.3581957342544879,null,0.21888637410952688,0.30813683764454247,null,0.21888637410952688,0.44787371784445323,null,0.3581957342544879,0.3832889414848931,null,0.3581957342544879,0.44787371784445323,null,0.3832889414848931,0.5383620103214027,null,0.3832889414848931,0.3344864071123659,null,0.5383620103214027,0.4888928384274308,null,0.5383620103214027,0.3344864071123659,null,0.4888928384274308,0.3344864071123659,null,0.4888928384274308,0.2846562254039355,null,0.3678509809107188,0.21882246626422974,null,0.3678509809107188,0.12203037267231784,null,0.3678509809107188,0.2846562254039355,null,0.21882246626422974,-0.04854580699135162,null,0.21882246626422974,0.12203037267231784,null,-0.04854580699135162,-0.25096915080789967,null,-0.04854580699135162,0.12203037267231784,null,-0.25096915080789967,-0.5205275838327373,null,-0.25096915080789967,-0.2512095743863335,null,-0.25096915080789967,-0.393540167108645,null,-0.5205275838327373,-0.2512095743863335,null,-0.5205275838327373,-0.393540167108645,null,-0.869353339422124,-0.5550518587596115,null,-0.869353339422124,-0.751790669317679,null,0.20356649576475006,0.34077717548820635,null,0.20356649576475006,0.29914644268335594,null,0.34077717548820635,0.29914644268335594,null,-0.5550518587596115,-0.751790669317679,null,-0.5550518587596115,-0.48704569469144027,null,-0.5550518587596115,-0.46366564530046833,null,-0.751790669317679,-0.48704569469144027,null,-0.751790669317679,-0.46366564530046833,null,-0.48704569469144027,-0.46366564530046833,null,0.6460732249830471,0.32030980308391244,null,0.30813683764454247,0.44787371784445323,null,-0.2512095743863335,-0.393540167108645,null,0.12203037267231784,0.2846562254039355,null,0.3344864071123659,0.2846562254039355,null],\"y\":[0.3993800505896674,0.11888522073782429,null,0.3993800505896674,0.20920763766928527,null,0.3993800505896674,0.28526583842512204,null,0.05034902986135763,0.03652316038543035,null,0.05034902986135763,0.017129160746906152,null,0.05034902986135763,-0.21227755843151552,null,0.05034902986135763,0.1896004296919303,null,0.03652316038543035,0.017129160746906152,null,0.03652316038543035,-0.21227755843151552,null,0.03652316038543035,-0.1316312855687863,null,0.017129160746906152,-0.21227755843151552,null,0.017129160746906152,-0.1316312855687863,null,0.017129160746906152,0.030077991390861453,null,-0.21227755843151552,-0.1316312855687863,null,-0.1316312855687863,-0.2276153676016854,null,-0.1316312855687863,0.030077991390861453,null,-0.005214740594449314,-0.27667799969286905,null,-0.005214740594449314,-0.2276153676016854,null,-0.005214740594449314,-0.08196549558009411,null,-0.005214740594449314,0.030077991390861453,null,-0.27667799969286905,-0.2276153676016854,null,-0.27667799969286905,-0.08196549558009411,null,-0.2276153676016854,-0.3530505265105978,null,-0.40821113053000224,-0.42059013399627276,null,-0.40821113053000224,-0.44372515461253165,null,-0.40821113053000224,-0.6611936895176564,null,-0.40821113053000224,-0.3530505265105978,null,-0.42059013399627276,-0.4155049174422634,null,-0.42059013399627276,-0.44372515461253165,null,-0.4155049174422634,-0.2998487857915494,null,-0.4155049174422634,-0.49135147366990717,null,-0.2998487857915494,-0.49135147366990717,null,-0.2998487857915494,-0.35663988737115787,null,-0.5465395256438597,-0.41424723912624445,null,-0.5465395256438597,-0.49135147366990717,null,-0.5465395256438597,-0.35663988737115787,null,-0.41424723912624445,-0.39509898631364554,null,-0.41424723912624445,-0.35663988737115787,null,-0.39509898631364554,-0.5492889822978466,null,-0.39509898631364554,-0.30559963735293033,null,-0.5492889822978466,-0.44455630280130687,null,-0.5492889822978466,-0.30559963735293033,null,-0.44455630280130687,-0.30559963735293033,null,-0.44455630280130687,-0.1776723910209659,null,0.09398766154470008,0.14704007782320902,null,0.09398766154470008,-0.08453342560481342,null,0.09398766154470008,-0.1776723910209659,null,0.14704007782320902,-0.040211815380110705,null,0.14704007782320902,-0.08453342560481342,null,-0.040211815380110705,-0.04100932634625198,null,-0.040211815380110705,-0.08453342560481342,null,-0.04100932634625198,-0.12721350684913893,null,-0.04100932634625198,-0.11426174188776443,null,-0.04100932634625198,0.15059027580565046,null,-0.12721350684913893,-0.11426174188776443,null,-0.12721350684913893,0.15059027580565046,null,0.11888522073782429,0.20920763766928527,null,0.11888522073782429,0.28526583842512204,null,-0.44372515461253165,-0.6611936895176564,null,-0.44372515461253165,-0.3530505265105978,null,-0.6611936895176564,-0.3530505265105978,null,0.20920763766928527,0.28526583842512204,null,0.20920763766928527,0.48098246231211605,null,0.20920763766928527,0.1896004296919303,null,0.28526583842512204,0.48098246231211605,null,0.28526583842512204,0.1896004296919303,null,0.48098246231211605,0.1896004296919303,null,-0.08196549558009411,0.030077991390861453,null,-0.49135147366990717,-0.35663988737115787,null,-0.11426174188776443,0.15059027580565046,null,-0.08453342560481342,-0.1776723910209659,null,-0.30559963735293033,-0.1776723910209659,null],\"z\":[-2.788162457015658,-2.7525296089368245,null,-2.788162457015658,-2.638683843513665,null,-2.788162457015658,-2.4706484329497638,null,-2.0352033052402914,-1.6944002055570462,null,-2.0352033052402914,-1.8599638265070546,null,-2.0352033052402914,-1.824780616506346,null,-2.0352033052402914,-2.3043655207647706,null,-1.6944002055570462,-1.8599638265070546,null,-1.6944002055570462,-1.824780616506346,null,-1.6944002055570462,-1.5768436928151157,null,-1.8599638265070546,-1.824780616506346,null,-1.8599638265070546,-1.5768436928151157,null,-1.8599638265070546,-1.7837735546185336,null,-1.824780616506346,-1.5768436928151157,null,-1.5768436928151157,-1.3156168581682304,null,-1.5768436928151157,-1.7837735546185336,null,-1.4945943626689944,-1.4903137057402747,null,-1.4945943626689944,-1.3156168581682304,null,-1.4945943626689944,-1.782223346930268,null,-1.4945943626689944,-1.7837735546185336,null,-1.4903137057402747,-1.3156168581682304,null,-1.4903137057402747,-1.782223346930268,null,-1.3156168581682304,-0.9677337442504306,null,-0.6636449919903264,-0.3294038746949407,null,-0.6636449919903264,-0.6450222371687941,null,-0.6636449919903264,-0.8471172448240873,null,-0.6636449919903264,-0.9677337442504306,null,-0.3294038746949407,0.013404262168507717,null,-0.3294038746949407,-0.6450222371687941,null,0.013404262168507717,0.30105513065829437,null,0.013404262168507717,0.3372444316968079,null,0.30105513065829437,0.3372444316968079,null,0.30105513065829437,0.6265792451999955,null,0.6621768594939337,0.9495271511050499,null,0.6621768594939337,0.3372444316968079,null,0.6621768594939337,0.6265792451999955,null,0.9495271511050499,1.2899431278229325,null,0.9495271511050499,0.6265792451999955,null,1.2899431278229325,1.5444387400707882,null,1.2899431278229325,1.6141446882312491,null,1.5444387400707882,1.8599020548608345,null,1.5444387400707882,1.6141446882312491,null,1.8599020548608345,1.6141446882312491,null,1.8599020548608345,1.9294581157702133,null,2.1262668101736435,2.426527301427887,null,2.1262668101736435,2.2146157964557216,null,2.1262668101736435,1.9294581157702133,null,2.426527301427887,2.500933766156351,null,2.426527301427887,2.2146157964557216,null,2.500933766156351,2.779002343555806,null,2.500933766156351,2.2146157964557216,null,2.779002343555806,2.953067308819474,null,2.779002343555806,3.1059817301052277,null,2.779002343555806,3.0118377119659,null,2.953067308819474,3.1059817301052277,null,2.953067308819474,3.0118377119659,null,-2.7525296089368245,-2.638683843513665,null,-2.7525296089368245,-2.4706484329497638,null,-0.6450222371687941,-0.8471172448240873,null,-0.6450222371687941,-0.9677337442504306,null,-0.8471172448240873,-0.9677337442504306,null,-2.638683843513665,-2.4706484329497638,null,-2.638683843513665,-2.465582324265053,null,-2.638683843513665,-2.3043655207647706,null,-2.4706484329497638,-2.465582324265053,null,-2.4706484329497638,-2.3043655207647706,null,-2.465582324265053,-2.3043655207647706,null,-1.782223346930268,-1.7837735546185336,null,0.3372444316968079,0.6265792451999955,null,3.1059817301052277,3.0118377119659,null,2.2146157964557216,1.9294581157702133,null,1.6141446882312491,1.9294581157702133,null],\"type\":\"scatter3d\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":[\"rgb(256,0,0)\",\"rgb(0,0,0)\",\"rgb(256,0,0)\",\"rgb(256,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(256,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(256,0,0)\",\"rgb(256,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\",\"rgb(0,0,0)\"],\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"line\":{\"color\":\"rgb(50,50,50)\",\"width\":0.5},\"size\":6,\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"actors\",\"text\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\"],\"x\":[-0.8070447833252102,-0.2869099108651412,-0.2492850694024043,0.003194388269609994,-0.19973367625304858,0.05140307295412916,0.5233786089000426,0.6566994272293745,0.308778716744253,0.4657004646555994,0.3615152749983518,0.3842443923474905,0.5359553090456766,0.21888637410952688,0.3581957342544879,0.3832889414848931,0.5383620103214027,0.4888928384274308,0.3678509809107188,0.21882246626422974,-0.04854580699135162,-0.25096915080789967,-0.5205275838327373,-0.869353339422124,0.20356649576475006,0.34077717548820635,0.29914644268335594,-0.5550518587596115,-0.751790669317679,-0.48704569469144027,-0.46366564530046833,0.6460732249830471,0.32030980308391244,0.30813683764454247,-0.2512095743863335,0.12203037267231784,0.44787371784445323,-0.393540167108645,0.3344864071123659,0.2846562254039355],\"y\":[0.3993800505896674,0.05034902986135763,0.03652316038543035,0.017129160746906152,-0.21227755843151552,-0.1316312855687863,-0.005214740594449314,-0.27667799969286905,-0.2276153676016854,-0.40821113053000224,-0.42059013399627276,-0.4155049174422634,-0.2998487857915494,-0.5465395256438597,-0.41424723912624445,-0.39509898631364554,-0.5492889822978466,-0.44455630280130687,0.09398766154470008,0.14704007782320902,-0.040211815380110705,-0.04100932634625198,-0.12721350684913893,0.11888522073782429,-0.44372515461253165,-0.6611936895176564,-0.3530505265105978,0.20920763766928527,0.28526583842512204,0.48098246231211605,0.1896004296919303,-0.08196549558009411,0.030077991390861453,-0.49135147366990717,-0.11426174188776443,-0.08453342560481342,-0.35663988737115787,0.15059027580565046,-0.30559963735293033,-0.1776723910209659],\"z\":[-2.788162457015658,-2.0352033052402914,-1.6944002055570462,-1.8599638265070546,-1.824780616506346,-1.5768436928151157,-1.4945943626689944,-1.4903137057402747,-1.3156168581682304,-0.6636449919903264,-0.3294038746949407,0.013404262168507717,0.30105513065829437,0.6621768594939337,0.9495271511050499,1.2899431278229325,1.5444387400707882,1.8599020548608345,2.1262668101736435,2.426527301427887,2.500933766156351,2.779002343555806,2.953067308819474,-2.7525296089368245,-0.6450222371687941,-0.8471172448240873,-0.9677337442504306,-2.638683843513665,-2.4706484329497638,-2.465582324265053,-2.3043655207647706,-1.782223346930268,-1.7837735546185336,0.3372444316968079,3.1059817301052277,2.2146157964557216,0.6265792451999955,3.0118377119659,1.6141446882312491,1.9294581157702133],\"type\":\"scatter3d\"}],                        {\"height\":1000,\"hovermode\":\"closest\",\"margin\":{\"t\":100},\"scene\":{\"xaxis\":{\"showbackground\":false,\"showgrid\":false,\"showline\":false,\"showticklabels\":false,\"title\":{\"text\":\"\"},\"zeroline\":false},\"yaxis\":{\"showbackground\":false,\"showgrid\":false,\"showline\":false,\"showticklabels\":false,\"title\":{\"text\":\"\"},\"zeroline\":false},\"zaxis\":{\"showbackground\":false,\"showgrid\":false,\"showline\":false,\"showticklabels\":false,\"title\":{\"text\":\"\"},\"zeroline\":false}},\"showlegend\":false,\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"width\":1000},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8d3275ee-7353-4718-88ad-10c336c38db5');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import plotly.graph_objs as go\n",
    "from  plotly.offline import plot\n",
    "import chart_studio.plotly as py\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot\n",
    "init_notebook_mode(connected='true')\n",
    "data=[trace1, trace2]\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='Les-Miserables')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
